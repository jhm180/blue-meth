{
 "metadata": {
  "name": "Rapnet Price Curve Generator - Backup Copy before Depth Change"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###################\n",
      "##### LOAD ACTIVE LISTINGS FROM SQL DATABASE & DEFINE SOME GLOBAL VARIABLES\n",
      "###################\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import MySQLdb\n",
      "c = MySQLdb.connect('localhost', 'root', '3lihu_r007', 'rapnet_listings')\n",
      "import pandas.io.sql as psql\n",
      "import matplotlib.pyplot as plt\n",
      "import pylab as pl\n",
      "from scipy.optimize import curve_fit\n",
      "from matplotlib.backends.backend_pdf import PdfPages\n",
      "\n",
      "df = psql.read_frame(\"\"\"select l.LotNum, l.Owner, convert(l.Price, decimal(10,4)) as PricePerCarat, l.Shape, convert(l.Carat, decimal(10,6)) as Carat, l.Color, l.Clarity, \n",
      "l.CutGrade, convert(l.PctRap, decimal(10,6)) as PctRap, l.Cert, convert(l.Depth, decimal(10,6)) as Depth, convert(l.TableWidth, decimal(10,6)) as TableWidth, l.Girdle, \n",
      "l.Culet, l.Polish, l.Sym, l.Fluor, l.Meas, l.RapnetComment, l.NumStones, l.CertNum, l.StockNum, l.Make, l.Date, l.City,\n",
      "l.State, l.Country, l.Image from active_listing l where l.Cert like 'GIA' \n",
      "and not l.Color is null and l.Color <> \"\"\n",
      "and (l.Color like 'D' or l.color like 'E' or l.color like 'F' or l.color like 'G' or l.color like 'H' or l.color like 'I' or l.color like 'J'\\\n",
      " or l.color like 'K' or l.color like 'L' or l.color like 'M')\n",
      "and (l.Clarity like 'IF' or l.Clarity like 'VVS1' or l.Clarity like 'VVS2' or l.Clarity like 'VS1' or l.Clarity like 'VS2' or l.Clarity like 'SI1' \\\n",
      " or l.Clarity like 'SI2' or l.Clarity like 'SI3' or l.Clarity like 'I1' or l.Clarity like 'I2' or l.Clarity like 'I3')\n",
      "and not l.Clarity is null and l.Clarity <> \"\"\n",
      "and not l.Polish is null and l.Polish <> ''\n",
      "and not l.Sym is null and l.Sym <> ''\n",
      "and not l.Fluor is null and l.Fluor <> ''\n",
      "and not l.Price is null and l.Price <> ''\"\"\", c, index_col = 'LotNum')\n",
      "df['TotalPrice'] = df['PricePerCarat'] * df['Carat'] #l.Price represents price per carat\n",
      "\n",
      "all_countries = ['USA', 'Canada', 'United Kingdom', 'Hong Kong', 'India', 'Belgium', 'Israel', 'Sri Lanka', 'Germany', \\\n",
      "            'Thailand', 'UAE', 'China', 'South Africa', 'New Zealand', 'Australia', 'France', 'Singapore', 'Italy', 'Uzbekistan', 'Uganda'] \n",
      "usa_only = ['USA']\n",
      "\n",
      "colors = ['D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M']\n",
      "clars = ['IF', 'VVS1', 'VVS2', 'VS1', 'VS2', 'SI1', 'SI2', 'SI3', 'I1', 'I2', 'I3']\n",
      "clars_plot = ['IF', 'VVS1', 'VVS2', 'VS1', 'VS2', 'SI1', 'SI2', 'I1', 'I2']\n",
      "coffee_pot_colors = ['F', 'G', 'H', 'I', 'J']\n",
      "coffee_pot_clars = ['VS1', 'VS2', 'SI1', 'SI2']\n",
      "\n",
      "fluor_faint = ['Faint ', 'Faint Blue', 'Slight', 'Very Slight ', 'Slight Blue', 'Very Slight Blue'] #Do NOT delete spaces at end of items in this list\n",
      "fluor_none = ['None '] #Do NOT delete spaces at end of items in this list\n",
      "fluor_medium = ['Medium ', 'Medium Blue', 'Medium Yellow'] #Do NOT delete spaces at end of items in this list\n",
      "fluor_strong = ['Strong ', 'Strong Blue', 'Very Strong Blue', 'Very Strong '] #Do NOT delete spaces at end of items in this list\n",
      "\n",
      "clar_line_colors = {'IF' : 'r' , 'VVS1' : 'g', 'VVS2' : 'b', 'VS1' :'c', 'VS2' : 'm', 'SI1': 'y', 'SI2': 'k', 'I1': 'r', 'I2' : 'g'}\n",
      "color_line_colors = {'D' : 'r' , 'E' : 'g', 'F' : 'b', 'G' :'c', 'H' : 'm', 'I' : 'y', 'J': 'k', 'K': 'r', 'L' : 'g', 'M' : 'b'}\n",
      "\n",
      "print len(df)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "138750\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/pandas/io/sql.py:44: Warning: Incorrect decimal value: '' for column '' at row -1\n",
        "  cur.execute(sql)\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###################\n",
      "##### EMBIGGEN DF - ADD NEW COLUMN WITH A KEY, LOAD RAP PRICE LIST, THEN ADD NEW COLUMN AND POUPLATE COLUMN WITH RAP PRICE USING KEY \n",
      "###################\n",
      "\n",
      "df['RapPriceKey'] = 0\n",
      "df['RapShapeKey'] = 0\n",
      "#Create a new column that will be used as a key when looking up listed rap price\n",
      "def rap_price_key(wt):\n",
      "    if wt >= 0.01 and wt <= 0.03:\n",
      "        return 0.01\n",
      "    elif wt >= 0.04 and wt <= 0.07:\n",
      "        return 0.07\n",
      "    elif wt >= 0.08 and wt <= 0.14:\n",
      "        return 0.08\n",
      "    elif wt >= 0.15 and wt <= 0.17:\n",
      "        return 0.15\n",
      "    elif wt >= 0.18 and wt <= 0.22:\n",
      "        return 0.18\n",
      "    elif wt >= 0.23 and wt <= 0.29:\n",
      "        return 0.23    \n",
      "    elif wt >= 0.30 and wt <= 0.39:\n",
      "        return 0.30\n",
      "    elif wt >= 0.40 and wt <= 0.49:\n",
      "        return 0.40\n",
      "    elif wt >= 0.50 and wt <= 0.69:\n",
      "        return 0.50\n",
      "    elif 0.70 <= wt and wt <= 0.89:\n",
      "        return 0.70\n",
      "    elif 0.90 <= wt and wt <= 0.99:\n",
      "        return 0.90\n",
      "    elif 1.00 <= wt and wt <= 1.49:\n",
      "        return 1.00\n",
      "    elif 1.50 <= wt and wt <= 1.99:\n",
      "        return 1.50\n",
      "    elif 2.00 <= wt and wt <= 2.99:\n",
      "        return 2.00\n",
      "    elif 3.00 <= wt and wt <= 3.99:\n",
      "        return 3.00        \n",
      "    elif 4.00 <= wt and wt <= 4.99:\n",
      "        return 4.00        \n",
      "    elif 5.00 <= wt and wt <= 9.99:\n",
      "        return 5.00\n",
      "    elif 10.00 <= wt:\n",
      "        return 10.00\n",
      "    else:\n",
      "        return -999999.0\n",
      "\n",
      "def rap_shape_key(shape):\n",
      "    if shape == 'Round':\n",
      "        return 'BR'\n",
      "    else:\n",
      "        return 'PS'\n",
      "\n",
      "df['RapPriceKey'] = df['Carat'].apply(rap_price_key)\n",
      "\n",
      "df['RapShapeKey'] = df['Shape'].apply(rap_shape_key)    \n",
      "    \n",
      "df['RapPricePerCarat'] = 0\n",
      "\n",
      "#import rappaport price list\n",
      "df_rap_price_list =  pd.read_csv('/home/oliver/Dropbox/whitepine/Rapnet Price List.csv', sep=',', header=0,\\\n",
      "names = ['Shape','Clarity','Color','MinCarat','MaxCarat','PricePerCar','Date'], index_col=[0,2,1,3])\n",
      "\n",
      "groups = []\n",
      "# split into groups, where each row in a subgroup has the same Color, Clarity, and RapPriceKey\n",
      "for (shape, color, clarity, rapPriceKey), group in df.groupby(['RapShapeKey','Color','Clarity','RapPriceKey']):\n",
      "    # using boolean indexing to select the matching price per carat from the df_rap_price_list\n",
      "    # df_rap_price_list.index is a multiindex; map() is a way of applying a function to each item in a sequence \n",
      "    # (in this case, each multiindex object in the df_rap_price_list frame)\n",
      "    # lambda idx: ... is a shorthand way of defining a function; could also do:\n",
      "    ppc = df_rap_price_list[df_rap_price_list.index.map(lambda idx: idx[0] == shape and idx[1] == color and idx[2] == clarity and idx[3] == rapPriceKey)]\n",
      "    if len(ppc):\n",
      "        px = ppc['PricePerCar'].iloc[0]\n",
      "        group['RapPricePerCarat'] = px\n",
      "    else:\n",
      "        group['RapPricePerCarat'] = -999999\n",
      "    groups.append(group) # add each subgroup to a python list\n",
      "\n",
      "# re-merge all the subgroups back into a single dataframe\n",
      "# generally a good idea to not overwrite the original df object here, so you can play with intermediate results without losing\n",
      "# the initial df, but in this case we already know it's what we want\n",
      "df = pd.concat(groups)\n",
      "\n",
      "df['ExactPctRap'] = (df['PricePerCarat']-df['RapPricePerCarat'])/df['RapPricePerCarat']\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ratio(measurement):\n",
      "    measurementx = (measurement.replace('-','x'))\n",
      "    dims = (measurementx.split('x'))\n",
      "    side1 = float(dims[0])\n",
      "    side2 = float(dims[1])\n",
      "    if side1 == 0 or side2 == 0:\n",
      "        return 8\n",
      "    else:\n",
      "        return side1/side2\n",
      "    \n",
      "df['Ratio'] = df['Meas'].apply(ratio)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###################\n",
      "##### EMBIGGEN DF - CALCULATE A 'Cut Grade' FOR NON-ROUND STONES\n",
      "###################\n",
      "\n",
      "def princess_cut_grade(dataframe):\n",
      "    cutgrade = dataframe['CutGrade']\n",
      "    shape = dataframe['Shape']\n",
      "    table = dataframe['TableWidth']\n",
      "    depth = dataframe['Depth']\n",
      "    sym = dataframe['Sym']\n",
      "    polish = dataframe['Polish']\n",
      "    ratio = dataframe['Ratio']\n",
      "    if shape != 'Princess':\n",
      "        return cutgrade\n",
      "    elif 68 <= table <= 75 and 68 <= depth <=73 and sym in ['Excellent','Very Good'] and polish in ['Excellent','Very Good'] and ratio <= 1.025:\n",
      "        return 'Excellent'\n",
      "    elif 64 <= table <= 79 and 66 <= depth <=74.9 and sym in ['Excellent','Very Good', 'Good'] and polish in ['Excellent','Very Good', 'Good'] and ratio <= 1.05:\n",
      "        return 'Very Good'\n",
      "    elif 60 <= table <= 83 and 64 <= depth <=77 and sym in ['Excellent','Very Good', 'Good'] and polish in ['Excellent','Very Good', 'Good'] and ratio <= 1.075:\n",
      "        return 'Good'\n",
      "    else:\n",
      "        return 'Fair'\n",
      "    \n",
      "df['CutGrade'] = df.apply(princess_cut_grade, axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###################\n",
      "##### FITS POLYNOMIALS TO TOTAL PRICE DATA (X = CARAT WEIGHT, Y = TOTAL PRICE) AND EXPORTS THE FIT PARAMETERS TO EXCEL \n",
      "###################\n",
      "\n",
      "r01 = np.linspace(0.00, 0.03, 50)\n",
      "r04 = np.linspace(0.04, 0.07, 50)\n",
      "r08 = np.linspace(0.08, 0.14, 50)\n",
      "r15 = np.linspace(0.15, 0.17, 50)\n",
      "r18 = np.linspace(0.18, 0.22, 50)\n",
      "r23 = np.linspace(0.23, 0.29, 50)\n",
      "r30 = np.linspace(0.30, 0.39, 50)\n",
      "r40 = np.linspace(0.40, 0.49, 50)\n",
      "r50 = np.linspace(0.50, 0.59, 50)\n",
      "r60 = np.linspace(0.60, 0.69, 50)\n",
      "r70 = np.linspace(0.70, 0.79, 50)\n",
      "r80 = np.linspace(0.80, 0.89, 50)\n",
      "r90 = np.linspace(0.90, 0.99, 50)\n",
      "rc1 = np.linspace(1.00, 1.49, 50)\n",
      "rcr = np.linspace(1.50, 1.99, 50)\n",
      "rc2 = np.linspace(2.00, 2.99, 50)\n",
      "rc3 = np.linspace(3.00, 3.99, 50)\n",
      "rc4 = np.linspace(4.00, 4.99, 50)\n",
      "rc5 = np.linspace(5.00, 9.99, 50)\n",
      "rct = np.linspace(10.00, 29.99, 50)\n",
      "\n",
      "rc_bins = [r01, r04, r08, r15, r18, r23, r30, r40, r50, r60, r70, r80, r90, rc1, rcr, rc2, rc3, rc4, rc5, rct]\n",
      "\n",
      "carat_bins = [ \\\n",
      "              [0.00, 0.04, 0.01, 0.03, 0.01, 1, 'r01', r01],\\\n",
      "              [0.04, 0.08, 0.04, 0.07, 0.04, 1, 'r04', r04],\\\n",
      "              [0.08, 0.15, 0.08, 0.14, 0.08, 1, 'r08', r08],\\\n",
      "              [0.15, 0.18, 0.15, 0.17, 0.15, 1, 'r15', r15],\\\n",
      "              [0.18, 0.23, 0.18, 0.22, 0.18, 1, 'r18', r18],\\\n",
      "              [0.23, 0.30, 0.23, 0.29, 0.23, 1, 'r23', r23],\\\n",
      "              [0.30, 0.40, 0.30, 0.39, 0.30, 1, 'r30', r30],\\\n",
      "              [0.40, 0.50, 0.40, 0.49, 0.40, 1, 'r40', r40],\\\n",
      "              [0.50, 0.60, 0.50, 0.59, 0.50, 1, 'r50', r50],\\\n",
      "              [0.60, 0.70, 0.60, 0.69, 0.50, 1, 'r60', r60],\\\n",
      "              [0.70, 0.80, 0.70, 0.79, 0.70, 1, 'r70', r70],\\\n",
      "              [0.80, 0.90, 0.80, 0.89, 0.70, 1, 'r80', r80],\\\n",
      "              [0.90, 1.00, 0.90, 0.99, 0.90, 1, 'r90', r90],\\\n",
      "              [1.00, 1.50, 1.00, 1.49, 1.00, 2, 'rc1', rc1],\\\n",
      "              [1.50, 2.00, 1.50, 1.99, 1.50, 2, 'rcr', rcr],\\\n",
      "              [2.00, 3.00, 2.00, 2.99, 2.00, 2, 'rc2', rc2],\\\n",
      "              [3.00, 4.00, 3.00, 3.99, 3.00, 2, 'rc3', rc3],\\\n",
      "              [4.00, 5.00, 4.00, 4.99, 4.00, 2, 'rc4', rc4],\\\n",
      "              [5.00, 10.00, 5.00, 9.99, 5.00, 2, 'rc5', rc5],\\\n",
      "              [10.00, 30.00, 10.00, 29.99, 10.00, 2, 'rct', rct]\\\n",
      "              ]\n",
      "\n",
      "shapes = [ \\\n",
      "            ['Princess', ['Excellent', 'Very Good', 'Good'],  ['Excellent', 'Very Good'],  ['Very Good'], 'PS', usa_only, 'PR'], \\\n",
      "            ['Round', ['Excellent'],  ['Excellent'],  ['Excellent'], 'BR', all_countries, 'RB'] \\\n",
      "            ]\n",
      "\n",
      "line_colors = ['r', 'g', 'b', 'c', 'm', 'y', 'k', 'r', 'g', 'b', 'c', 'm', 'y', 'k', 'r', 'g', 'b', 'c', 'm', 'y']\n",
      "\n",
      "output = {\\\n",
      "            'Shape' : [], \\\n",
      "            'Color' : [], \\\n",
      "            'Clarity' : [], \\\n",
      "            'CurveKey' : [], \\\n",
      "            'CurveRangeMin' : [], \\\n",
      "            'CurveRangeMax' : [], \\\n",
      "            'PolyDegree' : [], \\\n",
      "            'Px2' : [], \\\n",
      "            'Px1' : [], \\\n",
      "            'Px0' : [], \\\n",
      "            'StdDev' : [], \\\n",
      "            'NumStones': [] \\\n",
      "            }\n",
      "\n",
      "def price_curve_genarator_all():\n",
      "    #initiate pdf doc to save figures into\n",
      "    pp = matplotlib.backends.backend_pdf.PdfPages('/home/oliver/Dropbox/whitepine/price_curves.pdf')\n",
      "    \n",
      "    for z in range(len(shapes)):\n",
      "        shape = shapes[z][0]\n",
      "        cutgrade = shapes[z][1]\n",
      "        polish = shapes[z][2]\n",
      "        sym = shapes[z][3]\n",
      "        rap_shape_key = shapes[z][4]\n",
      "        location = shapes[z][5]\n",
      "        shape_key = shapes[z][6]\n",
      "        \n",
      "        #loop through colors and clarties\n",
      "        for k in colors:\n",
      "            color = k\n",
      "            for l in clars:\n",
      "                clar = l\n",
      "                \n",
      "                #create a smaller dataframe with a single combination of color and clarity \n",
      "                df_temp = df[ \\\n",
      "                            (df['Shape'] == shape) \\\n",
      "                            & (df['Carat'] >= 0.23) \\\n",
      "                            & (df['Carat'] < 3.5) \\\n",
      "                            & (df['Color'] == color) \\\n",
      "                            & (df['Clarity'] == clar) \\\n",
      "                            & (df['Country'].isin(location)) \\\n",
      "                            & (df['CutGrade'].isin(cutgrade)) \\\n",
      "                            & (df['Polish'].isin(polish)) \\\n",
      "                            & (df['Sym'].isin(sym)) \\\n",
      "                            & (df['Fluor'].isin(fluor_none)) \\\n",
      "                            ]\n",
      "                \n",
      "                #loop through carat bins that have a bunch of preset parameters\n",
      "                for i in range(len(carat_bins)):\n",
      "                    fxn_min = carat_bins[i][0]\n",
      "                    fxn_max = carat_bins[i][1]\n",
      "                    plot_min = carat_bins[i][2]\n",
      "                    plot_max = carat_bins[i][3]\n",
      "                    rap_price_key = carat_bins[i][4]\n",
      "                    degree = carat_bins[i][5]\n",
      "                    curve_key = carat_bins[i][6]\n",
      "                    plot_linspace = carat_bins[i][7]\n",
      "                    fxn_plus_min = carat_bins[i][1]\n",
      "                    fxn_plus_max = carat_bins[i][1]+.5\n",
      "                    \n",
      "                    \n",
      "                    #break up color/clarity dataframe into smaller chunks based on carat weight\n",
      "                    df_fxn_range_pre = df_temp[(df_temp['Carat'] >= fxn_min) & (df_temp['Carat'] < fxn_max)]\n",
      "                    \n",
      "                    #get cheapest two stones that weigh more than the current weight bin, append them to the smaller color/clarity dataframe\n",
      "                    df_fxn_range_plus_pre = df_temp[(df_temp['Carat'] >= fxn_plus_min) & (df_temp['Carat'] < fxn_plus_max)]\n",
      "                    df_fxn_range_plus = df_fxn_range_plus_pre.sort(['TotalPrice'],ascending=True)\n",
      "                    df_fxn_range = pd.concat([df_fxn_range_pre, df_fxn_range_plus[:2]])\n",
      "                    df_plot_range = df_temp[(df_temp['Carat'] >= plot_min) & (df_temp['Carat'] < plot_max)]\n",
      "                    \n",
      "                    \n",
      "                    #exception handling for certain criteria... exclude small and large stones, exclude lesser clarities, exclude empty categories\n",
      "                    #exclude categories with only a few stones (minimum stone limits set here are arbitrary)\n",
      "                    #create dummy entries in the output dictionary for the exlcluded categories\n",
      "                    if ( \\\n",
      "                        plot_min < .23 \\\n",
      "                        or plot_max >= 3.00 \\\n",
      "                        or clar == 'SI3' \\\n",
      "                        or clar == 'I2' \\\n",
      "                        or clar == 'I3' \\\n",
      "                        or len(df_temp) == 0 \\\n",
      "                        or (len(df_fxn_range) <= 4 and degree ==1) \\\n",
      "                        or (len(df_fxn_range) <= 9 and degree ==2) \\\n",
      "                        or len(df_fxn_range) == 0\n",
      "                        or len(df_plot_range) == 0\n",
      "                        ):\n",
      "                        \n",
      "                        output['Shape'].append(shape_key)\n",
      "                        output['Color'].append(color)\n",
      "                        output['Clarity'].append(clar)\n",
      "                        output['CurveKey'].append(curve_key)\n",
      "                        output['CurveRangeMin'].append(plot_min)\n",
      "                        output['CurveRangeMax'].append(plot_max)\n",
      "                        output['PolyDegree'].append(-999999)\n",
      "                        output['Px2'].append(-999999)\n",
      "                        output['Px1'].append(-999999)\n",
      "                        output['Px0'].append(-999999)\n",
      "                        output['StdDev'].append(-999999)\n",
      "                        output['NumStones'].append(len(df_plot_range))\n",
      "                        \n",
      "                    else:\n",
      "                        #calculate fit parameters for best fit polynomial curve \n",
      "                        fit_params = np.poly1d(np.polyfit(df_fxn_range['Carat'],df_fxn_range['TotalPrice'], degree, full=False))\n",
      "    \n",
      "                        #Calculate the standard deviation of list prices versus model projected prices in terms of pct rap (i.e., % difference of model price and listed price from rap list price)\n",
      "                        total = 0\n",
      "                        for m in range(len(df_plot_range)):\n",
      "                            total += ((np.polyval(fit_params, df_plot_range['Carat'].iloc[m]) - df_plot_range['TotalPrice'].iloc[m])/np.polyval(fit_params, df_plot_range['Carat'].iloc[m]))**2\n",
      "                        curve_shift = sqrt(total / len(df_plot_range))\n",
      "                     \n",
      "                        #Calculate a residual value - the % difference between predicted price and list price\n",
      "                        df_plot_range['Residual'] = (df_plot_range['TotalPrice']-np.polyval(fit_params, df_plot_range['Carat']))/df_plot_range['TotalPrice']\n",
      "                        \n",
      "                        #Store fit parameters in a dictionary\n",
      "                        if degree == 1:\n",
      "                            output['Shape'].append(shape_key)\n",
      "                            output['Color'].append(color)\n",
      "                            output['Clarity'].append(clar)\n",
      "                            output['CurveKey'].append(curve_key)\n",
      "                            output['CurveRangeMin'].append(plot_min)\n",
      "                            output['CurveRangeMax'].append(plot_max)\n",
      "                            output['PolyDegree'].append(degree)\n",
      "                            output['Px2'].append(0)\n",
      "                            output['Px1'].append(fit_params[1])\n",
      "                            output['Px0'].append(fit_params[0])\n",
      "                            output['StdDev'].append(curve_shift)\n",
      "                            output['NumStones'].append(len(df_plot_range))\n",
      "                        elif degree == 2:\n",
      "                            output['Shape'].append(shape_key)\n",
      "                            output['Color'].append(color)\n",
      "                            output['Clarity'].append(clar)\n",
      "                            output['CurveKey'].append(curve_key)\n",
      "                            output['CurveRangeMin'].append(plot_min)\n",
      "                            output['CurveRangeMax'].append(plot_max)                        \n",
      "                            output['PolyDegree'].append(degree)\n",
      "                            output['Px2'].append(fit_params[2])\n",
      "                            output['Px1'].append(fit_params[1])\n",
      "                            output['Px0'].append(fit_params[0])\n",
      "                            output['StdDev'].append(curve_shift)\n",
      "                            output['NumStones'].append(len(df_plot_range))\n",
      "                        else:\n",
      "                            output['Shape'].append(shape_key)\n",
      "                            output['Color'].append(color)\n",
      "                            output['Clarity'].append(clar)\n",
      "                            output['CurveKey'].append(curve_key)\n",
      "                            output['CurveRangeMin'].append(plot_min)\n",
      "                            output['CurveRangeMax'].append(plot_max)\n",
      "                            output['PolyDegree'].append(-999999)\n",
      "                            output['Px2'].append(-999999)\n",
      "                            output['Px1'].append(-999999)\n",
      "                            output['Px0'].append(-999999)\n",
      "                            output['StdDev'].append(-999999)\n",
      "                            output['NumStones'].append(len(df_plot_range))\n",
      "                        \n",
      "                        #load rap price for color/clarity/weight combination\n",
      "                        #rap_price = df_rap_price_list['PricePerCar'].ix[rap_shape_key].ix[color].ix[clar].ix[rap_price_key]\n",
      "                        \n",
      "                        #plot best fit curves, best fit curve less the stdev calc, & scatter of price v weight\n",
      "                        plt.subplot(2,1,1)\n",
      "                        plt.plot(rc_bins[i], np.polyval(fit_params, plot_linspace), color = line_colors[i])\n",
      "                        plt.plot(rc_bins[i], (np.polyval(fit_params, plot_linspace) - np.polyval(fit_params, plot_linspace)*curve_shift), '--', color=line_colors[i])\n",
      "                        plt.scatter(df_plot_range['Carat'], df_plot_range['TotalPrice'], color=line_colors[i], alpha=.7)\n",
      "    \n",
      "                        #calculate a curve that will display on the residual chart showing the difference between the model price and the price of a stone 1 stdev away from the model price\n",
      "                        curve_shift_resid = -(np.polyval(fit_params, plot_linspace) - np.polyval(fit_params, plot_linspace)*(1-curve_shift))/np.polyval(fit_params, plot_linspace)\n",
      "                        \n",
      "                        #plot residuals\n",
      "                        plt.subplot(2,1,2)\n",
      "                        plt.plot(plot_linspace, curve_shift_resid, '--', color=line_colors[i])\n",
      "                        plt.scatter(df_plot_range['Carat'],df_plot_range['Residual'],color=line_colors[i],alpha=.7)\n",
      "                        plt.axhline(linewidth=1, color='k')\n",
      "    \n",
      "                    \n",
      "                #set plot limits - exception handling for empty dataframes\n",
      "                if len(df_temp) == 0:\n",
      "                    ymin = 0\n",
      "                    ymax = 10000\n",
      "                else:\n",
      "                    ymin = min(df_temp['TotalPrice'])\n",
      "                    ymax = max(df_temp['TotalPrice'])*1.2\n",
      "                \n",
      "                #label and format plots\n",
      "                rcParams['figure.figsize'] = 9, 9                \n",
      "                if clar in ['SI3', 'I1', 'I2', 'I3']:\n",
      "                    pass\n",
      "                else: \n",
      "                    plt.subplot(2,1,1)\n",
      "                    plt.title(shape+'- 0.30 - 2.99 carat - '+color+' - '+clar, fontsize = 16)\n",
      "                    plt.ylabel('Total Price of Stone', fontsize = 16)\n",
      "                    plt.ylim(ymin, ymax)\n",
      "                    #plt.ylim(0,10000)\n",
      "                    plt.annotate(\"N = %s stones\" %(len(df_temp)), xy=(1, 0), xycoords='axes fraction', fontsize=16, xytext=(-5, 5), textcoords='offset points', ha='right', va='bottom')\n",
      "                    plt.xlim(0.23,3.00)\n",
      "                    \n",
      "                    plt.subplot(2,1,2)\n",
      "                    plt.title('Residuals', fontsize = 16)\n",
      "                    plt.ylabel('% Diff Btwn Actual and Model Price', fontsize = 16)\n",
      "                    plt.xlabel('Carat Weight', fontsize = 16)\n",
      "                    plt.ylim(-.5,.5) \n",
      "                    plt.xlim(0.23,3.00)\n",
      "                        \n",
      "                plt.savefig(pp, format='pdf') #save figure to pdf\n",
      "                plt.clf() #clear the figure for next iteration  \n",
      "    \n",
      "    pp.close() #close pdf\n",
      "    \n",
      "    #create a dataframe that contains the curve fit parameters \n",
      "    arrays = [output['Shape'], output['Color'], output['Clarity'], output['CurveKey'], output['CurveRangeMin']]\n",
      "    tuples = zip(*arrays)\n",
      "    index = pd.MultiIndex.from_tuples(tuples)\n",
      "    \n",
      "    output2 = {}\n",
      "    output2 = { \\\n",
      "                'CurveRangeMax' : output['CurveRangeMax'], \\\n",
      "                'PolyDegree' : output['PolyDegree'], \\\n",
      "                'Px2': output['Px2'], \\\n",
      "                'Px1': output['Px1'], \\\n",
      "                'Px0' : output['Px0'], \\\n",
      "                'StdDev': output['StdDev'], \\\n",
      "                'NumStones': output['NumStones'] \\\n",
      "                }\n",
      "    \n",
      "    df_output = pd.DataFrame(output2, index = index, columns = ['PolyDegree', 'Px2', 'Px1', 'Px0', 'StdDev', 'NumStones'] )\n",
      "    \n",
      "    #df_output.to_excel('/home/oliver/Dropbox/whitepine/price_curve_params.csv')\n",
      "        \n",
      "    return df_output\n",
      "    \n",
      "df_price_curves = price_curve_genarator_all()                \n",
      "                    \n",
      "                    \n",
      "                        \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##################\n",
      "##### GO OVER PRICE PARAMETERS AND THROW OUT MISSHAPEN CURVES - NEEDS TO BE UPDATED USING GROUPBY METHODS TO IMPROVE PERFORMANCE\n",
      "###################\n",
      "\n",
      "for i in range(len(df_price_curves)):\n",
      "    if (df_price_curves['PolyDegree'].iloc[i] == 1) and (df_price_curves['Px1'].iloc[i] < 0):\n",
      "        df_price_curves['PolyDegree'].iloc[i] = 1\n",
      "        df_price_curves['Px2'].iloc[i] = -999999\n",
      "        df_price_curves['Px1'].iloc[i] = -999999\n",
      "        df_price_curves['Px0'].iloc[i] = -999999\n",
      "        df_price_curves['StdDev'].iloc[i] = -999999\n",
      "    elif (df_price_curves['PolyDegree'].iloc[i] == 2) and (df_price_curves['Px1'].iloc[i] > 80000):\n",
      "        df_price_curves['PolyDegree'].iloc[i] = 2\n",
      "        df_price_curves['Px2'].iloc[i] = -999999\n",
      "        df_price_curves['Px1'].iloc[i] = -999999\n",
      "        df_price_curves['Px0'].iloc[i] = -999999\n",
      "        df_price_curves['StdDev'].iloc[i] = -999999\n",
      "\n",
      "f = open(\"/home/oliver/Dropbox/whitepine/price_curve_params.csv\", \"w\")\n",
      "f.truncate()\n",
      "f.close()\n",
      "df_price_curves.to_csv('/home/oliver/Dropbox/whitepine/price_curve_params.csv')\n",
      "#df_price_curves.to_excel('/home/oliver/Dropbox/whitepine/price_curve_params.xlsx', sheet_name = \"sheet1\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###################\n",
      "#####  EMBIGGEN DF - ADD NEW COLUMN CONTAINING PRICE CURVE KEYS\n",
      "###################\n",
      "\n",
      "df['PriceCurveKey'] = 0\n",
      "\n",
      "def g(wt):\n",
      "    if wt >= 0.01 and wt <= 0.03:\n",
      "        return 'r01'\n",
      "    elif wt >= 0.04 and wt <= 0.07:\n",
      "        return 'r04'\n",
      "    elif wt >= 0.08 and wt <= 0.14:\n",
      "        return 'r08'\n",
      "    elif wt >= 0.15 and wt <= 0.17:\n",
      "        return 'r15'\n",
      "    elif wt >= 0.18 and wt <= 0.22:\n",
      "        return 'r18'\n",
      "    elif wt >= 0.23 and wt <= 0.29:\n",
      "        return 'r23'   \n",
      "    elif wt >= 0.30 and wt <= 0.39:\n",
      "        return 'r30'\n",
      "    elif wt >= 0.40 and wt <= 0.49:\n",
      "        return 'r40'\n",
      "    elif wt >= 0.50 and wt <= 0.59:\n",
      "        return 'r50'\n",
      "    elif 0.60 <= wt and wt <= 0.69:\n",
      "        return 'r60'\n",
      "    elif 0.70 <= wt and wt <= 0.79:\n",
      "        return 'r70'\n",
      "    elif 0.80 <= wt and wt <= 0.89:\n",
      "        return 'r80'\n",
      "    elif 0.90 <= wt and wt <= 0.99:\n",
      "        return 'r90'\n",
      "    elif 1.00 <= wt and wt <= 1.49:\n",
      "        return 'rc1'\n",
      "    elif 1.50 <= wt and wt <= 1.99:\n",
      "        return 'rcr'\n",
      "    elif 2.00 <= wt and wt <= 2.99:\n",
      "        return 'rc2'\n",
      "    elif 3.00 <= wt and wt <= 3.99:\n",
      "        return 'rc3'       \n",
      "    elif 4.00 <= wt and wt <= 4.99:\n",
      "        return 'rc4'       \n",
      "    elif 5.00 <= wt and wt <= 9.99:\n",
      "        return 'rc5'\n",
      "    elif 10.00 <= wt:\n",
      "        return 'rct'\n",
      "    else:\n",
      "        return -999999.0\n",
      "\n",
      "df['PriceCurveKey'] = df['Carat'].apply(g)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###################\n",
      "##### EMBIGGEN DF - ADD NEW COLUMNS CONTAINING MODEL PARAMETERS\n",
      "###################\n",
      "\n",
      "groups = []\n",
      "# split into groups, where each row in a subgroup has the same Color, Clarity, and RapPriceKey\n",
      "for (shape, color, clarity, priceCurveKey), group in df.groupby(['Shape','Color','Clarity','PriceCurveKey']):\n",
      "    px = df_price_curves[df_price_curves.index.map(lambda idx: idx[0] == shape and idx[1] == color and idx[2] == clarity and idx[3] == priceCurveKey)]\n",
      "    if len(px):\n",
      "        group['PolyDegree'] = px['PolyDegree'].iloc[0]\n",
      "        group['Px2'] = px['Px2'].iloc[0]\n",
      "        group['Px1'] = px['Px1'].iloc[0]\n",
      "        group['Px0'] = px['Px0'].iloc[0]\n",
      "        group['StdDev'] = px['StdDev'].iloc[0]\n",
      "    else: \n",
      "        group['PolyDegree'] = px['PolyDegree']\n",
      "        group['Px2'] = -999999\n",
      "        group['Px1'] = -999999\n",
      "        group['Px0'] = -999999\n",
      "        group['StdDev'] = -999999\n",
      "    groups.append(group) # add each subgroup to a python list\n",
      "\n",
      "df = pd.concat(groups)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##########################################################################\n",
      "### DISCOUNT CALCULATION - GROUPED COLOR/CLAR VERSION - OUTPUTS RAP STYLE TABLES\n",
      "##########################################################################\n",
      "fluor_faint = ['Faint ', 'Faint Blue', 'Slight', 'Very Slight ', 'Slight Blue', 'Very Slight Blue'] #Do NOT delete spaces at end of items in this list\n",
      "fluor_none = ['None '] #Do NOT delete spaces at end of items in this list\n",
      "\n",
      "\n",
      "clars_avg = ['IF_avg', 'VVS1_avg', 'VVS2_avg', 'VS1_avg', 'VS2_avg', 'SI1_avg', 'SI2_avg', 'SI3_avg', 'I1_avg', 'I2_avg','I3_avg','Blank_Col_avg']\n",
      "clars_med = ['IF_med', 'VVS1_med', 'VVS2_med', 'VS1_med', 'VS2_med', 'SI1_med', 'SI2_med', 'SI3_med', 'I1_med', 'I2_med','I3_med','Blank_Col_med']\n",
      "clars_std = ['IF_std', 'VVS1_std', 'VVS2_std', 'VS1_std', 'VS2_std', 'SI1_std', 'SI2_std', 'SI3_std', 'I1_std', 'I2_std','I3_std','Blank_Col_std']\n",
      "clars_num = ['IF_num', 'VVS1_num', 'VVS2_num', 'VS1_num', 'VS2_num', 'SI1_num', 'SI2_num', 'SI3_num', 'I1_num', 'I2_num','I3_num']\n",
      "clars_blnk = ['IF', 'VVS1', 'VVS2', 'VS1', 'VS2', 'SI1', 'SI2', 'SI3', 'I1', 'I2', 'I3', 'Blank_Col']\n",
      "\n",
      "clars_tot = clars_avg + clars_med + clars_std + clars_num\n",
      "\n",
      "usa_only = ['USA']\n",
      "\n",
      "discount_groups = [ [['D'], ['IF', 'VVS1', 'VVS2']], \\\n",
      "                    [['E', 'F'], ['IF', 'VVS1', 'VVS2']], \\\n",
      "                    [['G', 'H', 'I', 'J'], ['IF', 'VVS1', 'VVS2']], \\\n",
      "                    [['D'], ['VS1', 'VS2', 'SI1', 'SI2']], \\\n",
      "                    [['E', 'F', 'G', 'H', 'I', 'J'], ['VS1', 'VS2', 'SI1', 'SI2']], \\\n",
      "                    [['K', 'L'], ['IF', 'VVS1', 'VVS2', 'VS1', 'VS2', 'SI1', 'SI2']]\\\n",
      "                    ]\n",
      "\n",
      "ex = ['Excellent']\n",
      "vg = ['Very Good']\n",
      "gd = ['Good']\n",
      "fr = ['Fair']\n",
      "\n",
      "vg_plus = ['Excellent', 'Very Good']\n",
      "gd_plus = ['Excellent', 'Very Good', 'Good']\n",
      "fr_plus = ['Excellent', 'Very Good', 'Good', 'Fair']\n",
      "tot = ['Excellent', 'Very Good', 'Good', 'Fair']\n",
      "\n",
      "# TAG , CUT , polish, sym, fluor\n",
      "\n",
      "discounts = [ \\\n",
      "            ['EX_EX_EX_NO_CPBOOST', ex, ex, ex, fluor_none, usa_only, 'Round', 'RB'], \\\n",
      "            ['EX_EX_EX_NO', ex, ex, ex, fluor_none, all_countries, 'Round', 'RB'], \\\n",
      "            ['EX_EX_EX_FNT', ex, ex, ex, fluor_faint, all_countries, 'Round', 'RB'], \\\n",
      "            ['EX_EX_EX_MED', ex, ex, ex, fluor_medium, all_countries, 'Round', 'RB'], \\\n",
      "            ['EX_EX_EX_STRONG', ex, ex, ex, fluor_strong, all_countries, 'Round', 'RB'], \\\n",
      "            ['VG_VGPLUS_VGPLUS_NO', vg, vg_plus, vg_plus, fluor_none, all_countries, 'Round', 'RB'], \\\n",
      "            ['VG_VGPLUS_VGPLUS_FNT', vg, vg_plus, vg_plus, fluor_faint, all_countries, 'Round', 'RB'], \\\n",
      "            ['VG_VGPLUS_VGPLUS_MED', vg, vg_plus, vg_plus, fluor_medium, all_countries, 'Round', 'RB'], \\\n",
      "            ['VG_VGPLUS_VGPLUS_STRONG', vg, vg_plus, vg_plus, fluor_strong, all_countries, 'Round', 'RB'], \\\n",
      "            ['GD_GDPLUS_GDPLUS_NO', gd, gd_plus, gd_plus, fluor_none, all_countries, 'Round', 'RB'], \\\n",
      "            ['GD_GDPLUS_GDPLUS_FNT', gd, gd_plus, gd_plus, fluor_faint, all_countries, 'Round', 'RB'], \\\n",
      "            ['GD_GDPLUS_GDPLUS_MED', gd, gd_plus, gd_plus, fluor_medium, all_countries, 'Round', 'RB'], \\\n",
      "            ['GD_GDPLUS_GDPLUS_STRONG', gd, gd_plus, gd_plus, fluor_strong, all_countries, 'Round', 'RB'], \\\n",
      "            ['FR_FRPLUS_FRPLUS_NO', fr, fr_plus, fr_plus, fluor_none, all_countries, 'Round', 'RB'], \\\n",
      "            ['FR_FRPLUS_FRPLUS_FNT', fr, fr_plus, fr_plus, fluor_faint, all_countries, 'Round', 'RB'], \\\n",
      "            ['FR_VGPLUS_FRPLUS_MED', fr, fr_plus, fr_plus, fluor_medium, all_countries, 'Round', 'RB'], \\\n",
      "            ['FR_FRPLUS_FRPLUS_STRONG', fr, fr_plus, fr_plus, fluor_strong, all_countries, 'Round', 'RB'], \\\n",
      "            #['EX_VG_EX_NO', ex, vg, ex, fluor_none, all_countries, 'Round'], \\\n",
      "            #['EX_EX_VG_NO', ex, ex, vg, fluor_none, all_countries, 'Round'], \\\n",
      "            #['EX_VG_VG_NO', ex, vg, vg, fluor_none, all_countries, 'Round'] \\\n",
      "            ['ANY_VGPLUS_VG_NO', gd_plus, vg_plus, vg, fluor_none, usa_only, 'Princess', 'PR'], \\\n",
      "            ['ANY_VGPLUS_VG_FNT', gd_plus, vg_plus, vg, fluor_faint, usa_only, 'Princess', 'PR'], \\\n",
      "            ['ANY_EX_EX_NO', gd_plus, ex, ex, fluor_none, usa_only, 'Princess', 'PR'], \\\n",
      "            ['ANY_EX_EX_FNT', gd_plus, ex, ex, fluor_faint, usa_only, 'Princess', 'PR'], \\\n",
      "            ['ANY_GDPLUS_GD_NO', gd_plus, gd_plus, gd, fluor_none, usa_only, 'Princess', 'PR'], \\\n",
      "            ['ANY_GDPLUS_GD_FNT', gd_plus, gd_plus, gd, fluor_faint, usa_only, 'Princess', 'PR'] \\\n",
      "            ]\n",
      "\n",
      "f = open(\"/home/oliver/Dropbox/whitepine/discounts_tables1.csv\", \"w\")\n",
      "f.truncate()\n",
      "f.close()\n",
      "\n",
      "discount_bins = [ \\\n",
      "                 [0.23, 1.00], \\\n",
      "                 [1.00, 1.50], \\\n",
      "                 [1.50, 2.99], \\\n",
      "                 ]\n",
      "\n",
      "df['PredictedPrice'] = df['Carat']**2 * df['Px2'] +  df['Carat'] * df['Px1'] + df['Px0']\n",
      "df['PredictedPricePerCarat'] = df['PredictedPrice'] / df['Carat']\n",
      "df['PredictedPctRap'] = (df['PredictedPricePerCarat'] - df['RapPricePerCarat']) / df['RapPricePerCarat']\n",
      "\n",
      "discount_output = { 'Tag' : [], 'Avg Discount': [], 'Median Discount' : [], 'Discount Stdev' : [], 'Num Stones' : [] }\n",
      "\n",
      "for p in range(len(discount_bins)):\n",
      "    min_carat = discount_bins[p][0]\n",
      "    max_carat = discount_bins[p][1]\n",
      "    for i in range(len(discounts)):\n",
      "        df_discount = pd.DataFrame(0, index=colors, columns=clars_tot, dtype=np.float64) \n",
      "        df_avg_discount = pd.DataFrame(0, index=colors, columns=clars_blnk, dtype=np.float64) \n",
      "        df_med_discount = pd.DataFrame(0, index=colors, columns=clars_blnk, dtype=np.float64) \n",
      "        df_std_discount = pd.DataFrame(0, index=colors, columns=clars_blnk, dtype=np.float64)     \n",
      "        df_number_of_stones = pd.DataFrame(0, index=colors, columns=clars, dtype=np.float64) \n",
      "    \n",
      "        for m in range(len(discount_groups)):\n",
      "            color = discount_groups[m][0]\n",
      "            clar = discount_groups[m][1]\n",
      "            tag = discounts[i][0]\n",
      "            cut = discounts[i][1]\n",
      "            polish = discounts[i][2]\n",
      "            sym = discounts[i][3]\n",
      "            fluor = discounts[i][4]\n",
      "            location = discounts[i][5]\n",
      "            shape = discounts[i][6]\n",
      "            shape_tag = discounts[i][7]\n",
      "            \n",
      "            df_temp = df[ \\\n",
      "                (df['Carat'] >= min_carat) \\\n",
      "                & (df['Carat'] < max_carat) \\\n",
      "                & (df['Shape'] == shape)\n",
      "                & (df['Color'].isin(color)) \\\n",
      "                & (df['Clarity'].isin(clar)) \\\n",
      "                & (df['Country'].isin(location)) \\\n",
      "                & (df['CutGrade'].isin(cut)) \\\n",
      "                & (df['Polish'].isin(polish)) \\\n",
      "                & (df['Sym'].isin(sym)) \\\n",
      "                & (df['Fluor'].isin(fluor)) \\\n",
      "                & (df['Px2'] != -999999)\\\n",
      "                ] #\n",
      "            \n",
      "            avg_discount = mean(df_temp['ExactPctRap'] - df_temp['PredictedPctRap'])   \n",
      "            med_discount = median(df_temp['ExactPctRap'] - df_temp['PredictedPctRap'])\n",
      "            std_discount = std(df_temp['ExactPctRap'] - df_temp['PredictedPctRap'])\n",
      "            num_stones = len(df_temp)\n",
      "            \n",
      "            if len(df_temp) == 0:\n",
      "                for j in discount_groups[m][0]:\n",
      "                    for k in discount_groups[m][1]:\n",
      "                        df_number_of_stones.ix[j,k] = 0\n",
      "                        df_avg_discount.ix[j,k] = -999999\n",
      "                        df_med_discount.ix[j,k] = -999999\n",
      "                        df_std_discount.ix[j,k] = -999999\n",
      "                        discount_output['Tag'].append(\"%s_%sct_%sct_%s_%s_%s\" %(shape_tag,min_carat,max_carat,j,k,tag))\n",
      "                        discount_output['Avg Discount'].append(-999999)\n",
      "                        discount_output['Median Discount'].append(-999999) \n",
      "                        discount_output['Discount Stdev'].append(-999999)\n",
      "                        discount_output['Num Stones'].append(0)                   \n",
      "            \n",
      "            elif len(df_temp) <= 7:\n",
      "                for j in discount_groups[m][0]:\n",
      "                    for k in discount_groups[m][1]:\n",
      "                        df_number_of_stones.ix[j,k] = len(df_temp)\n",
      "                        df_avg_discount.ix[j,k] = -999999\n",
      "                        df_med_discount.ix[j,k] = -999999\n",
      "                        df_std_discount.ix[j,k] = -999999\n",
      "                        discount_output['Tag'].append(\"%s_%sct_%sct_%s_%s_%s\" %(shape_tag,min_carat,max_carat,j,k,tag))\n",
      "                        discount_output['Avg Discount'].append(-999999)\n",
      "                        discount_output['Median Discount'].append(-999999)\n",
      "                        discount_output['Discount Stdev'].append(-999999)\n",
      "                        discount_output['Num Stones'].append(len(df_temp))\n",
      "                        \n",
      "            else:    \n",
      "                for j in discount_groups[m][0]:\n",
      "                    for k in discount_groups[m][1]:\n",
      "                        df_number_of_stones.ix[j,k] = num_stones\n",
      "                        df_avg_discount.ix[j,k] = avg_discount\n",
      "                        df_med_discount.ix[j,k] = med_discount\n",
      "                        df_std_discount.ix[j,k] = std_discount                \n",
      "                        discount_output['Tag'].append(\"%s_%sct_%sct_%s_%s_%s\" %(shape_tag,min_carat,max_carat,j,k,tag))\n",
      "                        discount_output['Avg Discount'].append(avg_discount)\n",
      "                        discount_output['Median Discount'].append(med_discount)         \n",
      "                        discount_output['Discount Stdev'].append(std_discount)     \n",
      "                        discount_output['Num Stones'].append(len(df_temp))\n",
      "           \n",
      "        #name column headers of each indiviidual dataframe and combine them into a single large dataframe that can be ouput into excel\n",
      "        df_avg_discount.columns = clars_avg \n",
      "        df_med_discount.columns = clars_med\n",
      "        df_std_discount.columns = clars_std\n",
      "        df_number_of_stones.columns = clars_num\n",
      "    \n",
      "        for z in clars_avg: \n",
      "            df_discount[z] =  df_avg_discount[z]\n",
      "        for z in clars_med: \n",
      "            df_discount[z] =  df_med_discount[z]\n",
      "        for z in clars_std: \n",
      "            df_discount[z] =  df_std_discount[z]\n",
      "        for z in clars_num: \n",
      "            df_discount[z] =  df_number_of_stones[z]\n",
      "            \n",
      "        df_discount['Blank_Col_avg'] = colors\n",
      "        df_discount['Blank_Col_med'] = colors\n",
      "        df_discount['Blank_Col_std'] = colors    \n",
      "        \n",
      "        pd.DataFrame([\"\", \"%s ct-%s ct-%s-%s\" %(min_carat,max_carat,shape, tag)]).to_csv('/home/oliver/Dropbox/whitepine/discounts_tables1.csv', mode = 'a', header=False)\n",
      "        pd.DataFrame(clars_tot).T.to_csv('/home/oliver/Dropbox/whitepine/discounts_tables1.csv', mode = 'a', header=False)\n",
      "        df_discount.to_csv('/home/oliver/Dropbox/whitepine/discounts_tables1.csv', mode = 'a', header=False)\n",
      "\n",
      "arrays = [discount_output['Tag']]\n",
      "tuples = zip(*arrays)\n",
      "index = pd.MultiIndex.from_tuples(tuples)        \n",
      "        \n",
      "df_discount_output = pd.DataFrame(discount_output, index=index)\n",
      "\n",
      "g = open(\"/home/oliver/Dropbox/whitepine/discounts_list.csv\", \"w\")\n",
      "g.truncate()\n",
      "g.close()\n",
      "\n",
      "df_discount_output.to_csv('/home/oliver/Dropbox/whitepine/discounts_list.csv')\n",
      "#df_discount_output.to_excel('/home/oliver/Dropbox/whitepine/discounts_list.xlsx', sheet_name = 'sheet1', index_label = \"Discount Tag\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#df.to_excel('/home/oliver/Dropbox/whitepine/active_listing.xlxs', sheet_name = 'sheet1')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 942
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_grouped = df[df['Shape'] == 'Princess']\n",
      "\n",
      "df_grouped1 = df_grouped.groupby(['Sym','Polish'])\n",
      "\n",
      "df_grouped1.size()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "Sym        Polish        \n",
        "Excellent  Excellent         1139\n",
        "           Good                 9\n",
        "           Very Good          186\n",
        "Fair       Excellent           12\n",
        "           Fair                 4\n",
        "           Good               118\n",
        "           Very Good           70\n",
        "Good       Excellent          892\n",
        "           Good              1239\n",
        "           Good-Very Good       1\n",
        "           Very Good         2468\n",
        "Poor       Fair                 1\n",
        "           Good                 1\n",
        "Very Good  Excellent         4215\n",
        "           Fair                 1\n",
        "           Good               239\n",
        "           Very Good         2900\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_grope = df.groupby('Shape')\n",
      "\n",
      "df_grope.size()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 62,
       "text": [
        "Shape\n",
        "Asscher              1982\n",
        "Baguette               45\n",
        "Briolette               1\n",
        "Bullets                 2\n",
        "Calf                    1\n",
        "Cushion               471\n",
        "Cushion Modified     9387\n",
        "Emerald              6065\n",
        "European Cut          101\n",
        "Flanders                2\n",
        "Half Moon               3\n",
        "Heart                2308\n",
        "Hexagonal               3\n",
        "Kite                   10\n",
        "Lozenge                 1\n",
        "Marquise             3806\n",
        "Octagonal               7\n",
        "Old Miner              27\n",
        "Other                  29\n",
        "Oval                 2858\n",
        "Pear                 5931\n",
        "Princess            13495\n",
        "Radiant              3721\n",
        "Rose                   14\n",
        "Round               87770\n",
        "Shield                 40\n",
        "Sq. Emerald           180\n",
        "Square                  8\n",
        "Square Radiant        252\n",
        "Star                    1\n",
        "Tapered Baguette        5\n",
        "Trapezoid               5\n",
        "Triangular             56\n",
        "Trilliant             163\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}