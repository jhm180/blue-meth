{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "###################################################\n",
      "###### IMPORT LIBRARIESx`\n",
      "###################################################\n",
      "\n",
      "import pandas as pd\n",
      "from os import path\n",
      "import glob\n",
      "import re\n",
      "from datetime import datetime,date,timedelta\n",
      "from pandas.io.parsers import read_csv\n",
      "import numpy as np\n",
      "from itertools import repeat\n",
      "import sys\n",
      "import traceback\n",
      "import gc\n",
      "from pandas.io.pytables import HDFStore\n",
      "import shutil\n",
      "from scipy import stats\n",
      "\n",
      "###################################################\n",
      "###### DEFINE GROUPS AND SET KEY VALUES\n",
      "###################################################\n",
      "\n",
      "carat_bins = [\n",
      "              ['GIA', 'Round', 0.23, 0.29, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.23, 0.29, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.23, 0.29, 'Good'], \\\n",
      "             ]\n",
      "\n",
      "\n",
      "groups = [\n",
      "            ['H','VS1','H Color','VS1 Clarity'],\\\n",
      "            ['H','VS2','H Color','VS2 Clarity'],\\\n",
      "            ['H','SI1','H Color','SI1 Clarity'],\\\n",
      "            ['H','SI2','H Color','SI2 Clarity'],\\\n",
      "        ]\n",
      "\n",
      "gd_plus = ['Excellent', 'Very Good', 'Good']\n",
      "fluor_faint = ['Faint ', 'Faint Blue', 'Slight', 'Very Slight ', 'Slight Blue', 'Very Slight Blue'] #Do NOT delete spaces at end of items in this list\n",
      "fluor_none = ['None '] #Do NOT delete spaces at end of items in this list\n",
      "fluor_medium = ['Medium ', 'Medium Blue', 'Medium Yellow'] #Do NOT delete spaces at end of items in this list\n",
      "fluor_strong = ['Strong ', 'Strong Blue', 'Very Strong Blue', 'Very Strong ']\n",
      "\n",
      "fluors = [fluor_none, fluor_faint, fluor_medium, fluor_strong]\n",
      "fluor_tags = ['None', 'Faint', 'Medium', 'Strong and VST']\n",
      "\n",
      "colors = ['D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M']\n",
      "clars = ['IF', 'VVS1', 'VVS2' 'VS1', 'VS2', 'SI1', 'SI2']\n",
      "\n",
      "start_time = datetime.now()\n",
      "last_step_end = datetime.now()\n",
      "sell_lag = 32 #Sets number of days something has been removed from rapnet before we consider it sold\n",
      "start_date = datetime(2013, 3, 3) #First day we started downloading market data \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "###################################################\n",
      "###### DEFINE SOME FUNCTIONS\n",
      "###################################################\n",
      "\n",
      "\n",
      "def get_first(grp):\n",
      "    grp.sort(columns='event_day', inplace=True, ascending = False)\n",
      "    return grp.iloc[-1]\n",
      "\n",
      "def get_last(grp):\n",
      "    grp.sort(columns='event_day', inplace=True, ascending = False)\n",
      "    return grp.iloc[0]\n",
      "\n",
      "def days_to_sell(row):\n",
      "    if row['event_type_first_event'] == 1 and row['event_type_last_event'] == 2 and row['event_day_last_event'] < (datetime.now()-timedelta(days=sell_lag)):\n",
      "        return (row['event_day_last_event'] - row['event_day_first_event']).days\n",
      "    else:\n",
      "        return np.nan\n",
      "\n",
      "def get_percentile(dframe):\n",
      "    for g in range(len(dframe)):\n",
      "        if dframe['event_type_first'].iloc[g] == 1 and dframe['event_type_last'].iloc[g] == 2 \\\n",
      "        and dframe['event_day_last'].iloc[g] < (datetime.now()-timedelta(days=sell_lag)):\n",
      "            sale_date = dframe['event_day_last'].iloc[g]\n",
      "            add_date = dframe['event_day_first'].iloc[g]\n",
      "            last_price = dframe['TotalPrice_last'].iloc[g]\n",
      "            df1 = dframe[(dframe['event_day_first'] < add_date) & (dframe['event_day_last'] < sale_date) & \\\n",
      "                         (dframe['event_type_last'].isin([1,3,4]))]\n",
      "            return stats.percentileofscore(df1['TotalPrice_last'],last_price)\n",
      "        else:\n",
      "            return np.nan\n",
      "\n",
      "\n",
      "###################################################\n",
      "###### LOAD DATA\n",
      "###################################################\n",
      "\n",
      "all_df, current_df, file_date = rl.load_cache()\n",
      "# all_df is the whole database, with the event types you see in the above cell\n",
      "# the index is a multiindex with levels ('event_type','Owner','CertNum,'event_day')\n",
      "#this gets the latest removals:\n",
      "#prev_removals = all_df.xs(rl.REMOVE, level='event_type').\n",
      "\n",
      "\n",
      "print 'Cache Loading Took | %s' %(datetime.now() - last_step_end)\n",
      "print 'Total Run Time | %s' %(datetime.now() - start_time)\n",
      "last_step_end = datetime.now()\n",
      "\n",
      "###################################################\n",
      "###### FILTER ALL DF DOWN TO WHAT WE'RE FOCUSED ON ---- \n",
      "###################################################\n",
      "\n",
      "filtered_df = all_df[(all_df['Carat'] >= 0.23) \\\n",
      "                     & (all_df['Carat'] <= 5.99) \\\n",
      "                     & (all_df['Cut Grade'].isin(gd_plus)) \\\n",
      "                     & (all_df['Sym'].isin(gd_plus)) \\\n",
      "                     & (all_df['Polish'].isin(gd_plus)) \\\n",
      "                     & (all_df['Cert'] == 'GIA') \\\n",
      "                     & (all_df['Country'] == 'USA') \\\n",
      "                     #& (all_df['City'] == 'New York') \\\n",
      "                     #& (all_df['Color'] == 'G') \\\n",
      "                     #& (all_df['Clarity'] =='VS1') \\\n",
      "                     #& (all_df['Color'].isin(colors)) \\\n",
      "                     #& (all_df['Clarity'].isin(clars)) \\\n",
      "                     #& (all_df['Fluor'].isin(fluor_none)) \\\n",
      "                     ]\n",
      "\n",
      "filtered_df = filtered_df.reset_index()\n",
      "filtered_df['CertNum'] = filtered_df['CertNum'].str.replace('*', '')\n",
      "filtered_df = filtered_df.set_index(['Owner','CertNum'])\n",
      "filtered_df['TotalPrice'] = filtered_df['Price'] * filtered_df['Carat']\n",
      "filtered_df.sort(columns='event_day')\n",
      "\n",
      "\n",
      "print 'Filtering Took | %s' %(datetime.now() - last_step_end)\n",
      "print 'Total Run Time | %s' %(datetime.now() - start_time)\n",
      "last_step_end = datetime.now()\n",
      "\n",
      "###################################################\n",
      "###### GENERATE THE SELLS FILE\n",
      "###################################################\n",
      "\n",
      "sells = [] \n",
      "\n",
      "\n",
      "grouped = filtered_df.groupby(level=['Owner','CertNum'])\n",
      "last_entry = grouped.apply(get_last)\n",
      "last_entry = last_entry.drop(['LotNum','Shape','Carat','Color','Clarity','Cut Grade','Cert','Depth','Table','Girdle','Culet','Polish','Sym','Fluor','Meas','Comment','NumStones','StockNum','Make','Date','City','State','Country','Image'], axis=1)\n",
      "first_entry = grouped.apply(get_first)\n",
      "joined = first_entry.join(last_entry, lsuffix='_first_event', rsuffix='_last_event')\n",
      "\n",
      "print 'Grouping and Joining Took | %s' %(datetime.now() - last_step_end)\n",
      "print 'Total Run Time | %s' %(datetime.now() - start_time)\n",
      "last_step_end = datetime.now()\n",
      "\n",
      "\n",
      "joined['days_to_sell'] = joined.apply(days_to_sell, axis = 1)\n",
      "#df_temp['PercentileActive'] = np.nan\n",
      "#df_temp['PercentileAll'] = np.nan\n",
      "#df_temp['InventoryUponSale'] = np.nan\n",
      "\n",
      "sells = joined[np.isfinite(joined['days_to_sell'])]\n",
      "\n",
      "print 'Days to Sell Took | %s' %(datetime.now() - last_step_end)\n",
      "print 'Total Run Time | %s' %(datetime.now() - start_time)\n",
      "last_step_end = datetime.now()\n",
      "\n",
      "print 'Grouping and Joining Took | %s' %(datetime.now() - last_step_end)\n",
      "print 'Total Run Time | %s' %(datetime.now() - start_time)\n",
      "last_step_end = datetime.now()\n",
      "\n",
      "\n",
      "\n",
      "print 'Filtered Length | %s' %(len(filtered_df))\n",
      "print 'Grouped Length | %s' %(len(grouped))\n",
      "print 'Joined Length | %s' %(len(joined))\n",
      "print 'Sells Length | %s' %(len(sells))\n",
      "print 'First Event | %s' %(min(sells['event_day_first_event']))\n",
      "print 'Last Event | %s' %(max(sells['event_day_last_event']))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cache load took 0:00:17.648956\n",
        "Cache Loading Took | 0:00:17.673152\n",
        "Total Run Time | 0:00:17.673321\n",
        "Filtering Took | 0:00:03.700241"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Total Run Time | 0:00:21.374252\n",
        "Grouping and Joining Took | 0:03:04.873389"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Total Run Time | 0:03:26.248329\n",
        "Days to Sell Took | 0:00:03.590010"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Total Run Time | 0:03:29.838985\n",
        "Grouping and Joining Took | 0:00:00.000054\n",
        "Total Run Time | 0:03:29.839193\n",
        "Filtered Length | 781110\n",
        "Grouped Length | 162268"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Joined Length | 162268\n",
        "Sells Length | 110982\n",
        "First Event | 2013-03-03 00:00:00"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Last Event | 2014-01-17 00:00:00"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from datetime import datetime,date,timedelta\n",
      "\n",
      "print len(sells)\n",
      "\n",
      "sells['weight_tag'] = np.nan\n",
      "\n",
      "def weight_tag(carat):\n",
      "    if carat >= 0.23 and carat <= 0.29:\n",
      "        return 'r023'\n",
      "    elif carat >= 0.30 and carat <= 0.34:\n",
      "        return 'r030'\n",
      "    elif carat >= 0.35 and carat <= 0.39:\n",
      "        return 'r035'\n",
      "    elif carat >= 0.40 and carat <= 0.44:\n",
      "        return 'r040'\n",
      "    elif carat >= 0.45 and carat <= 0.49:\n",
      "        return 'r045'\n",
      "    elif carat >= 0.50 and carat <= 0.54:\n",
      "        return 'r050'\n",
      "    elif carat >= 0.55 and carat <= 0.59:\n",
      "        return 'r055'\n",
      "    elif carat >= 0.60 and carat <= 0.64:\n",
      "        return 'r060'\n",
      "    elif carat >= 0.65 and carat <= 0.69:\n",
      "        return 'r065'\n",
      "    elif carat >= 0.70 and carat <= 0.74:\n",
      "        return 'r070'\n",
      "    elif carat >= 0.75 and carat <= 0.79:\n",
      "        return 'r075'\n",
      "    elif carat >= 0.80 and carat <= 0.84:\n",
      "        return 'r080'\n",
      "    elif carat >= 0.85 and carat <= 0.89:\n",
      "        return 'r085'\n",
      "    elif carat >= 0.90 and carat <= 0.94:\n",
      "        return 'r090'\n",
      "    elif carat >= 0.95 and carat <= 0.99:\n",
      "        return 'r095'\n",
      "    elif carat == 1.00:\n",
      "        return 'r100'\n",
      "    elif carat == 1.01:\n",
      "        return 'r101'\n",
      "    elif carat == 1.02:\n",
      "        return 'r102'\n",
      "    elif carat == 1.03:\n",
      "        return 'r103'\n",
      "    elif carat == 1.04:\n",
      "        return 'r104'\n",
      "    elif carat >= 1.05 and carat <= 1.09:\n",
      "        return 'r105'\n",
      "    elif carat >= 1.10 and carat <= 1.19:\n",
      "        return 'r110'\n",
      "    elif carat >= 1.20 and carat <= 1.29:\n",
      "        return 'r120'\n",
      "    elif carat >= 1.30 and carat <= 1.39:\n",
      "        return 'r130'\n",
      "    elif carat >= 1.40 and carat <= 1.49:\n",
      "        return 'r140'\n",
      "    elif carat >= 1.50 and carat <= 1.74:\n",
      "        return 'r150'\n",
      "    elif carat >= 1.75 and carat <= 1.99:\n",
      "        return 'r175'\n",
      "    elif carat >= 2.00 and carat <= 2.24:\n",
      "        return 'r200'\n",
      "    elif carat >= 2.25 and carat <= 2.49:\n",
      "        return 'r225'\n",
      "    else:\n",
      "        pass\n",
      "\n",
      "    \n",
      "now = datetime.now()\n",
      "\n",
      "sells['weight_tag'] = sells['Carat'].apply(weight_tag)\n",
      "\n",
      "print datetime.now() - now\n",
      "\n",
      "carat_bins = [\n",
      "              ['GIA', 'Round', 0.23, 0.29, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.30, 0.34, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.35, 0.39, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.40, 0.44, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.45, 0.49, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.50, 0.54, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.55, 0.59, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.60, 0.64, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.65, 0.69, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.70, 0.74, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.75, 0.79, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.80, 0.84, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.85, 0.89, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.90, 0.94, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.95, 0.99, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.00, 1.00, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.01, 1.01, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.02, 1.02, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.03, 1.03, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.04, 1.04, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.05, 1.09, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.10, 1.14, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.15, 1.19, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.20, 1.24, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.25, 1.29, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.30, 1.34, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.35, 1.39, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.40, 1.44, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.45, 1.49, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.50, 1.59, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.60, 1.74, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.75, 1.99, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 2.00, 2.24, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 2.25, 2.49, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.23, 0.29, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.30, 0.34, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.35, 0.39, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.40, 0.44, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.45, 0.49, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.50, 0.54, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.55, 0.59, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.60, 0.64, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.65, 0.69, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.70, 0.74, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.75, 0.79, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.80, 0.84, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.85, 0.89, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.90, 0.94, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.95, 0.99, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.00, 1.00, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.01, 1.01, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.02, 1.02, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.03, 1.03, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.04, 1.04, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.05, 1.09, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.10, 1.14, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.15, 1.19, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.20, 1.24, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.25, 1.29, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.30, 1.34, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.35, 1.39, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.40, 1.44, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.45, 1.49, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.50, 1.59, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.60, 1.74, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.75, 1.99, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 2.00, 2.24, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 2.25, 2.49, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.23, 0.29, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.30, 0.34, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.35, 0.39, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.40, 0.44, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.45, 0.49, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.50, 0.54, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.55, 0.59, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.60, 0.64, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.65, 0.69, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.70, 0.74, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.75, 0.79, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.80, 0.84, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.85, 0.89, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.90, 0.94, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.95, 0.99, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.00, 1.00, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.01, 1.01, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.02, 1.02, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.03, 1.03, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.04, 1.04, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.05, 1.09, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.10, 1.14, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.15, 1.19, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.20, 1.24, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.25, 1.29, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.30, 1.34, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.35, 1.39, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.40, 1.44, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.45, 1.49, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.50, 1.59, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.60, 1.74, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.75, 1.99, 'Good'], \\\n",
      "              ['GIA', 'Round', 2.00, 2.24, 'Good'], \\\n",
      "              ['GIA', 'Round', 2.25, 2.49, 'Good'], \\\n",
      "             ]\n",
      "\n",
      "\n",
      "groups = [\n",
      "            ['D','IF','D Color','IF Clarity'],\\\n",
      "            ['D','VVS1','D Color','VVS1 Clarity'],\\\n",
      "            ['D','VVS2','D Color','VVS2 Clarity'],\\\n",
      "            ['D','VS1','D Color','VS1 Clarity'],\\\n",
      "            ['D','VS2','D Color','VS2 Clarity'],\\\n",
      "            ['D','SI1','D Color','SI1 Clarity'],\\\n",
      "            ['D','SI2','D Color','SI2 Clarity'],\\\n",
      "            ['E','IF','E Color','IF Clarity'],\\\n",
      "            ['E','VVS1','E Color','VVS1 Clarity'],\\\n",
      "            ['E','VVS2','E Color','VVS2 Clarity'],\\\n",
      "            ['E','VS1','E Color','VS1 Clarity'],\\\n",
      "            ['E','VS2','E Color','VS2 Clarity'],\\\n",
      "            ['E','SI1','E Color','SI1 Clarity'],\\\n",
      "            ['E','SI2','E Color','SI2 Clarity'],\\\n",
      "            ['F','IF','F Color','IF Clarity'],\\\n",
      "            ['F','VVS1','F Color','VVS1 Clarity'],\\\n",
      "            ['F','VVS2','F Color','VVS2 Clarity'],\\\n",
      "            ['F','VS1','F Color','VS1 Clarity'],\\\n",
      "            ['F','VS2','F Color','VS2 Clarity'],\\\n",
      "            ['F','SI1','F Color','SI1 Clarity'],\\\n",
      "            ['F','SI2','F Color','SI2 Clarity'],\\\n",
      "            ['G','IF','G Color','IF Clarity'],\\\n",
      "            ['G','VVS1','G Color','VVS1 Clarity'],\\\n",
      "            ['G','VVS2','G Color','VVS2 Clarity'],\\\n",
      "            ['G','VS1','G Color','VS1 Clarity'],\\\n",
      "            ['G','VS2','G Color','VS2 Clarity'],\\\n",
      "            ['G','SI1','G Color','SI1 Clarity'],\\\n",
      "            ['G','SI2','G Color','SI2 Clarity'],\\\n",
      "            ['H','IF','H Color','IF Clarity'],\\\n",
      "            ['H','VVS1','H Color','VVS1 Clarity'],\\\n",
      "            ['H','VVS2','H Color','VVS2 Clarity'],\\\n",
      "            ['H','VS1','H Color','VS1 Clarity'],\\\n",
      "            ['H','VS2','H Color','VS2 Clarity'],\\\n",
      "            ['H','SI1','H Color','SI1 Clarity'],\\\n",
      "            ['H','SI2','H Color','SI2 Clarity'],\\\n",
      "            ['I','IF','I Color','IF Clarity'],\\\n",
      "            ['I','VVS1','I Color','VVS1 Clarity'],\\\n",
      "            ['I','VVS2','I Color','VVS2 Clarity'],\\\n",
      "            ['I','VS1','I Color','VS1 Clarity'],\\\n",
      "            ['I','VS2','I Color','VS2 Clarity'],\\\n",
      "            ['I','SI1','I Color','SI1 Clarity'],\\\n",
      "            ['I','SI2','I Color','SI2 Clarity'],\\\n",
      "            ['J','IF','J Color','IF Clarity'],\\\n",
      "            ['J','VVS1','J Color','VVS1 Clarity'],\\\n",
      "            ['J','VVS2','J Color','VVS2 Clarity'],\\\n",
      "            ['J','VS1','J Color','VS1 Clarity'],\\\n",
      "            ['J','VS2','J Color','VS2 Clarity'],\\\n",
      "            ['J','SI1','J Color','SI1 Clarity'],\\\n",
      "            ['J','SI2','J Color','SI2 Clarity']\\\n",
      "        ]\n",
      "\n",
      "sells_late = sells[sells['event_day_first_event'] > date(2013,3,3)]\n",
      "\n",
      "sells_late_NYC = sells[(sells['event_day_first_event'] > date(2013,3,3))&(sells['City'] == 'New York')]\n",
      "\n",
      "print len(sells_late)\n",
      "print len(sells_late_NYC)\n",
      "\n",
      "\"\"\" \n",
      "for a in range(len(carat_bins)):\n",
      "    cert = carat_bins[a][0]\n",
      "    shape = carat_bins[a][1]\n",
      "    wghtmin = carat_bins[a][2]\n",
      "    wghtmax = carat_bins[a][3]\n",
      "    cut = carat_bins[a][4]\n",
      "    for b in range(len(groups)):\n",
      "        color = groups[b][0]\n",
      "        clar = groups[b][1]\n",
      "        colortag = groups[b][2]\n",
      "        clartag = groups[b][3]\n",
      "        \n",
      "        for c in range(len(fluors)):\n",
      "            fluor = fluors[c]\n",
      "        \n",
      "            df_temp = sells_late[\\\n",
      "                                 (sells_late['Cert'] == cert)\\\n",
      "                                 & (sells_late['Shape'] == shape)\\\n",
      "                                 & (sells_late['Carat'] >= wghtmin)\\\n",
      "                                 & (sells_late['Carat'] <= wghtmax)\\\n",
      "                                 & (sells_late['Cut Grade'] == cut)\\\n",
      "                                 & (sells_late['Color'] == color)\\\n",
      "                                 & (sells_late['Clarity'] == clar)\\\n",
      "                                 & (sells_late['Fluor'].isin(fluor_none))\\\n",
      "                                 #& (sells_late[''] == )\\\n",
      "                                 ]\n",
      "\"\"\"\n",
      "\n",
      "#create a df with the baseline dates\n",
      "#create a df with the penaltoies: color, clar, cut?, fluor\n",
      "#"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "108938\n",
        "0:00:00.203489"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "86977"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "40058\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 77,
       "text": [
        "\" \\nfor a in range(len(carat_bins)):\\n    cert = carat_bins[a][0]\\n    shape = carat_bins[a][1]\\n    wghtmin = carat_bins[a][2]\\n    wghtmax = carat_bins[a][3]\\n    cut = carat_bins[a][4]\\n    for b in range(len(groups)):\\n        color = groups[b][0]\\n        clar = groups[b][1]\\n        colortag = groups[b][2]\\n        clartag = groups[b][3]\\n        \\n        for c in range(len(fluors)):\\n            fluor = fluors[c]\\n        \\n            df_temp = sells_late[                                 (sells_late['Cert'] == cert)                                 & (sells_late['Shape'] == shape)                                 & (sells_late['Carat'] >= wghtmin)                                 & (sells_late['Carat'] <= wghtmax)                                 & (sells_late['Cut Grade'] == cut)                                 & (sells_late['Color'] == color)                                 & (sells_late['Clarity'] == clar)                                 & (sells_late['Fluor'].isin(fluor_none))                                 #& (sells_late[''] == )                                 ]\\n\""
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##########################################################################\n",
      "### DISCOUNT CALCULATION - GROUPED COLOR/CLAR VERSION - OUTPUTS RAP STYLE TABLES\n",
      "##########################################################################\n",
      "\n",
      "##Formatting/defining column headers for the Discount Tables Output\n",
      "clars_avg = ['IF_avg', 'VVS1_avg', 'VVS2_avg', 'VS1_avg', 'VS2_avg', 'SI1_avg', 'SI2_avg', 'SI3_avg', 'I1_avg', 'I2_avg','I3_avg','Blank_Col_avg']\n",
      "clars_med = ['IF_med', 'VVS1_med', 'VVS2_med', 'VS1_med', 'VS2_med', 'SI1_med', 'SI2_med', 'SI3_med', 'I1_med', 'I2_med','I3_med','Blank_Col_med']\n",
      "clars_std = ['IF_std', 'VVS1_std', 'VVS2_std', 'VS1_std', 'VS2_std', 'SI1_std', 'SI2_std', 'SI3_std', 'I1_std', 'I2_std','I3_std','Blank_Col_std']\n",
      "clars_num = ['IF_num', 'VVS1_num', 'VVS2_num', 'VS1_num', 'VS2_num', 'SI1_num', 'SI2_num', 'SI3_num', 'I1_num', 'I2_num','I3_num']\n",
      "clars_blnk = ['IF', 'VVS1', 'VVS2', 'VS1', 'VS2', 'SI1', 'SI2', 'SI3', 'I1', 'I2', 'I3', 'Blank_Col']\n",
      "clars_tot = clars_avg + clars_med + clars_std + clars_num\n",
      "\n",
      "##Formatting/defining the dictionary that will eventually be converted to dataframe for the Discounts List output\n",
      "discount_output = { 'Tag' : [], 'RB Avg Discount': [], 'RB Median Discount' : [], 'RB Discount Stdev' : [], 'Num Stones' : [], \\\n",
      "                         'PR DepthDiff Coefficient' : [], 'PR Sym Rank Coefficient' : [], \\\n",
      "                         'PR DepthDiff T-Stat' : [], 'PR Sym Rank T-Stat' : []}\n",
      "\n",
      "##Variable definitinos\n",
      "usa_only = ['USA']\n",
      "ex = ['Excellent']\n",
      "vg = ['Very Good']\n",
      "gd = ['Good']\n",
      "fr = ['Fair']\n",
      "vg_plus = ['Excellent', 'Very Good']\n",
      "gd_plus = ['Excellent', 'Very Good', 'Good']\n",
      "fr_plus = ['Excellent', 'Very Good', 'Good', 'Fair']\n",
      "tot = ['Excellent', 'Very Good', 'Good', 'Fair']\n",
      "\n",
      "### The arrays discount_groups, discounts, and discount_bins are VERY IMPORTANT conceptually\n",
      "### We don't have enough data to look at each color/clarity/cut/fluor/weight combination individually, so we break them down by:\n",
      "### 3 main weight groups (up to .99 carats, 1-1.49 carats, 1.5 carts and up\n",
      "### Mixes of color/clarity combinations... for example D color and IF through VVS2 clarities are binned\n",
      "### Cut Grade & Fluor are the last groupings\n",
      "discount_groups = [ [['D'], ['IF', 'VVS1', 'VVS2']], \\\n",
      "                    [['E', 'F'], ['IF', 'VVS1', 'VVS2']], \\\n",
      "                    [['G', 'H', 'I', 'J'], ['IF', 'VVS1', 'VVS2']], \\\n",
      "                    [['D'], ['VS1', 'VS2', 'SI1', 'SI2']], \\\n",
      "                    [['E', 'F'], ['VS1', 'VS2']], \\\n",
      "                    [['G', 'H', 'I', 'J'], ['VS1', 'VS2']], \\\n",
      "                    [['E', 'F'], ['SI1', 'SI2']], \\\n",
      "                    [['G', 'H', 'I', 'J'], ['SI1', 'SI2']], \\\n",
      "                    [['K', 'L'], ['IF', 'VVS1', 'VVS2', 'VS1', 'VS2', 'SI1', 'SI2']]\\\n",
      "                    ]\n",
      "\n",
      "discounts = [ \\\n",
      "            ['EX_EX_EX_NO_CPBOOST', ex, ex, ex, fluor_none, usa_only, 'Round', 'RB'], \\\n",
      "            ['EX_EX_EX_NO', ex, ex, ex, fluor_none, all_countries, 'Round', 'RB'], \\\n",
      "            ['EX_EX_EX_FNT', ex, ex, ex, fluor_faint, all_countries, 'Round', 'RB'], \\\n",
      "            ['EX_EX_EX_MED', ex, ex, ex, fluor_medium, all_countries, 'Round', 'RB'], \\\n",
      "            ['EX_EX_EX_STRONG', ex, ex, ex, fluor_strong, all_countries, 'Round', 'RB'], \\\n",
      "            ['VG_VGPLUS_VGPLUS_NO', vg, vg_plus, vg_plus, fluor_none, all_countries, 'Round', 'RB'], \\\n",
      "            ['VG_VGPLUS_VGPLUS_FNT', vg, vg_plus, vg_plus, fluor_faint, all_countries, 'Round', 'RB'], \\\n",
      "            ['VG_VGPLUS_VGPLUS_MED', vg, vg_plus, vg_plus, fluor_medium, all_countries, 'Round', 'RB'], \\\n",
      "            ['VG_VGPLUS_VGPLUS_STRONG', vg, vg_plus, vg_plus, fluor_strong, all_countries, 'Round', 'RB'], \\\n",
      "            ['GD_GDPLUS_GDPLUS_NO', gd, gd_plus, gd_plus, fluor_none, all_countries, 'Round', 'RB'], \\\n",
      "            ['GD_GDPLUS_GDPLUS_FNT', gd, gd_plus, gd_plus, fluor_faint, all_countries, 'Round', 'RB'], \\\n",
      "            ['GD_GDPLUS_GDPLUS_MED', gd, gd_plus, gd_plus, fluor_medium, all_countries, 'Round', 'RB'], \\\n",
      "            ['GD_GDPLUS_GDPLUS_STRONG', gd, gd_plus, gd_plus, fluor_strong, all_countries, 'Round', 'RB'], \\\n",
      "            ['FR_FRPLUS_FRPLUS_NO', fr, fr_plus, fr_plus, fluor_none, all_countries, 'Round', 'RB'], \\\n",
      "            ['FR_FRPLUS_FRPLUS_FNT', fr, fr_plus, fr_plus, fluor_faint, all_countries, 'Round', 'RB'], \\\n",
      "            ['FR_VGPLUS_FRPLUS_MED', fr, fr_plus, fr_plus, fluor_medium, all_countries, 'Round', 'RB'], \\\n",
      "            ['FR_FRPLUS_FRPLUS_STRONG', fr, fr_plus, fr_plus, fluor_strong, all_countries, 'Round', 'RB'], \\\n",
      "            #['EX_VG_EX_NO', ex, vg, ex, fluor_none, all_countries, 'Round'], \\\n",
      "            #['EX_EX_VG_NO', ex, ex, vg, fluor_none, all_countries, 'Round'], \\\n",
      "            #['EX_VG_VG_NO', ex, vg, vg, fluor_none, all_countries, 'Round'] \\\n",
      "            #['ANY_VGPLUS_VG_NO', gd_plus, vg_plus, vg, fluor_none, usa_only, 'Princess', 'PR'], \\\n",
      "            #['ANY_VGPLUS_VG_FNT', gd_plus, vg_plus, vg, fluor_faint, usa_only, 'Princess', 'PR'], \\\n",
      "            #['ANY_EX_EX_NO', gd_plus, ex, ex, fluor_none, usa_only, 'Princess', 'PR'], \\\n",
      "            #['ANY_EX_EX_FNT', gd_plus, ex, ex, fluor_faint, usa_only, 'Princess', 'PR'], \\\n",
      "            ['ANY_GDPLUS_GD_NO', [\"Good\", \"Very Good\"], gd_plus, gd_plus, fluor_none, usa_only, 'Princess', 'PR'], \\\n",
      "            ]\n",
      "\n",
      "##3 weight bins for discounts\n",
      "discount_bins = [ \\\n",
      "                 [0.23, 1.00], \\\n",
      "                 [1.00, 1.50], \\\n",
      "                 [1.50, 2.99], \\\n",
      "                 ]\n",
      "\n",
      "\n",
      "##Clear file containing Discounts Tables output\n",
      "f = open(\"/home/oliver/Dropbox/whitepine/discounts_tables1.csv\", \"w\")\n",
      "f.truncate()\n",
      "f.close()\n",
      "\n",
      "##Generate model price for each stone - model price assumes a stone with base price parameters\n",
      "##In rounds, base price is XXX, no fluorescence\n",
      "\n",
      "\n",
      "df['PredictedPrice'] = df['Carat']**2 * df['Px2'] +  df['Carat'] * df['Px1'] + df['Px0']\n",
      "df['PredictedPricePerCarat'] = df['PredictedPrice'] / df['Carat']\n",
      "df['PredictedPctRap'] = (df['PredictedPricePerCarat'] - df['RapPricePerCarat']) / df['RapPricePerCarat']\n",
      "\n",
      "###In order to sanity check the methodology, I run the group that was used to generate the model price through the discount calculator\n",
      "###The discount calculator takes the difference between model price and actual price\n",
      "###Since model price is based on actual price, the difference between model price and actual price should be \n",
      "### minimal when caculated across a large sample of stones that were used to generate the model\n",
      "\n",
      "##A series of loops through our discounts defined above to load all the parameters that go into a group\n",
      "for p in range(len(discount_bins)):\n",
      "    min_carat = discount_bins[p][0]\n",
      "    max_carat = discount_bins[p][1]\n",
      "    \n",
      "    for i in range(len(discounts)):\n",
      "        df_discount = pd.DataFrame(0, index=colors, columns=clars_tot, dtype=np.float64) \n",
      "        df_avg_discount = pd.DataFrame(0, index=colors, columns=clars_blnk, dtype=np.float64) \n",
      "        df_med_discount = pd.DataFrame(0, index=colors, columns=clars_blnk, dtype=np.float64) \n",
      "        df_std_discount = pd.DataFrame(0, index=colors, columns=clars_blnk, dtype=np.float64)     \n",
      "        df_number_of_stones = pd.DataFrame(0, index=colors, columns=clars, dtype=np.float64) \n",
      "    \n",
      "        for m in range(len(discount_groups)):\n",
      "            color = discount_groups[m][0]\n",
      "            clar = discount_groups[m][1]\n",
      "            tag = discounts[i][0]\n",
      "            cut = discounts[i][1]\n",
      "            polish = discounts[i][2]\n",
      "            sym = discounts[i][3]\n",
      "            fluor = discounts[i][4]\n",
      "            location = discounts[i][5]\n",
      "            shape = discounts[i][6]\n",
      "            shape_tag = discounts[i][7]\n",
      "            \n",
      "            ## boolean filtering to get the final discount group\n",
      "            df_temp = df[ \\\n",
      "                (df['Carat'] >= min_carat) \\\n",
      "                & (df['Carat'] < max_carat) \\\n",
      "                & (df['Shape'] == shape)\n",
      "                & (df['Color'].isin(color)) \\\n",
      "                & (df['Clarity'].isin(clar)) \\\n",
      "                & (df['Country'].isin(location)) \\\n",
      "                & (df['CutGrade'].isin(cut)) \\\n",
      "                & (df['Polish'].isin(polish)) \\\n",
      "                & (df['Sym'].isin(sym)) \\\n",
      "                & (df['Fluor'].isin(fluor)) \\\n",
      "                & (df['Px2'] != -999999)\\\n",
      "                ] #\n",
      "            \n",
      "            ## calculate the discounts\n",
      "            avg_discount = mean(df_temp['ExactPctRap'] - df_temp['PredictedPctRap'])   \n",
      "            med_discount = median(df_temp['ExactPctRap'] - df_temp['PredictedPctRap'])\n",
      "            std_discount = std(df_temp['ExactPctRap'] - df_temp['PredictedPctRap'])\n",
      "            num_stones = len(df_temp)\n",
      "\n",
      "            ## Append discounts to output dictionary\n",
      "            if shape == 'Round':            \n",
      "                if len(df_temp) == 0:\n",
      "                    for j in discount_groups[m][0]:\n",
      "                        for k in discount_groups[m][1]:\n",
      "                            df_number_of_stones.ix[j,k] = 0\n",
      "                            df_avg_discount.ix[j,k] = -999999\n",
      "                            df_med_discount.ix[j,k] = -999999\n",
      "                            df_std_discount.ix[j,k] = -999999\n",
      "                            discount_output['Tag'].append(\"%s_%sct_%sct_%s_%s_%s\" %(shape_tag,min_carat,max_carat,j,k,tag))\n",
      "                            discount_output['RB Avg Discount'].append(-999999)\n",
      "                            discount_output['RB Median Discount'].append(-999999) \n",
      "                            discount_output['RB Discount Stdev'].append(-999999)\n",
      "                            discount_output['Num Stones'].append(0)                   \n",
      "                            #discount_output['PR Intercept Coefficient'].append(-999999)\n",
      "                            discount_output['PR DepthDiff Coefficient'].append(-999999)\n",
      "                            discount_output['PR Sym Rank Coefficient'].append(-999999)\n",
      "                            #discount_output['PR Intercept T-Stat'].append(-999999)\n",
      "                            discount_output['PR DepthDiff T-Stat'].append(-999999)\n",
      "                            discount_output['PR Sym Rank T-Stat'].append(-999999)                       \n",
      "                \n",
      "                elif len(df_temp) <= 7:\n",
      "                    for j in discount_groups[m][0]:\n",
      "                        for k in discount_groups[m][1]:\n",
      "                            df_number_of_stones.ix[j,k] = len(df_temp)\n",
      "                            df_avg_discount.ix[j,k] = -999999\n",
      "                            df_med_discount.ix[j,k] = -999999\n",
      "                            df_std_discount.ix[j,k] = -999999\n",
      "                            discount_output['Tag'].append(\"%s_%sct_%sct_%s_%s_%s\" %(shape_tag,min_carat,max_carat,j,k,tag))\n",
      "                            discount_output['RB Avg Discount'].append(-999999)\n",
      "                            discount_output['RB Median Discount'].append(-999999)\n",
      "                            discount_output['RB Discount Stdev'].append(-999999)\n",
      "                            discount_output['Num Stones'].append(len(df_temp))\n",
      "                            #discount_output['PR Intercept Coefficient'].append(-999999)\n",
      "                            discount_output['PR DepthDiff Coefficient'].append(-999999)\n",
      "                            discount_output['PR Sym Rank Coefficient'].append(-999999)\n",
      "                            #discount_output['PR Intercept T-Stat'].append(-999999)\n",
      "                            discount_output['PR DepthDiff T-Stat'].append(-999999)\n",
      "                            discount_output['PR Sym Rank T-Stat'].append(-999999)                       \n",
      "                            \n",
      "                else:    \n",
      "                    for j in discount_groups[m][0]:\n",
      "                        for k in discount_groups[m][1]:\n",
      "                            df_number_of_stones.ix[j,k] = num_stones\n",
      "                            df_avg_discount.ix[j,k] = avg_discount\n",
      "                            df_med_discount.ix[j,k] = med_discount\n",
      "                            df_std_discount.ix[j,k] = std_discount                \n",
      "                            discount_output['Tag'].append(\"%s_%sct_%sct_%s_%s_%s\" %(shape_tag,min_carat,max_carat,j,k,tag))\n",
      "                            discount_output['RB Avg Discount'].append(avg_discount)\n",
      "                            discount_output['RB Median Discount'].append(med_discount)         \n",
      "                            discount_output['RB Discount Stdev'].append(std_discount)     \n",
      "                            discount_output['Num Stones'].append(len(df_temp))\n",
      "                            #discount_output['PR Intercept Coefficient'].append(-999999)\n",
      "                            discount_output['PR DepthDiff Coefficient'].append(-999999)\n",
      "                            discount_output['PR Sym Rank Coefficient'].append(-999999)\n",
      "                            #discount_output['PR Intercept T-Stat'].append(-999999)\n",
      "                            discount_output['PR DepthDiff T-Stat'].append(-999999)\n",
      "                            discount_output['PR Sym Rank T-Stat'].append(-999999)                       \n",
      "\n",
      "            elif shape == 'Princess':               \n",
      "                if len(df_temp) == 0:\n",
      "                    for j in discount_groups[m][0]:\n",
      "                        for k in discount_groups[m][1]:\n",
      "                            df_number_of_stones.ix[j,k] = 0\n",
      "                            discount_output['Tag'].append(\"%s_%sct_%sct_%s_%s_%s\" %(shape_tag,min_carat,max_carat,j,k,tag))\n",
      "                            discount_output['RB Avg Discount'].append(-999999)\n",
      "                            discount_output['RB Median Discount'].append(-999999) \n",
      "                            discount_output['RB Discount Stdev'].append(-999999)                            \n",
      "                            #discount_output['PR Intercept Coefficient'].append(-999999)\n",
      "                            discount_output['PR DepthDiff Coefficient'].append(-999999)\n",
      "                            discount_output['PR Sym Rank Coefficient'].append(-999999)\n",
      "                            discount_output['Num Stones'].append(0)\n",
      "                            #discount_output['PR Intercept T-Stat'].append(-999999)\n",
      "                            discount_output['PR DepthDiff T-Stat'].append(-999999)\n",
      "                            discount_output['PR Sym Rank T-Stat'].append(-999999)\n",
      "                \n",
      "                elif len(df_temp) <= 12:\n",
      "                    for j in discount_groups[m][0]:\n",
      "                        for k in discount_groups[m][1]:\n",
      "                            df_number_of_stones.ix[j,k] = len(df_temp)\n",
      "                            discount_output['Tag'].append(\"%s_%sct_%sct_%s_%s_%s\" %(shape_tag,min_carat,max_carat,j,k,tag))\n",
      "                            discount_output['RB Avg Discount'].append(-999999)\n",
      "                            discount_output['RB Median Discount'].append(-999999) \n",
      "                            discount_output['RB Discount Stdev'].append(-999999)                            \n",
      "                            #discount_output['PR Intercept Coefficient'].append(-999999)\n",
      "                            discount_output['PR DepthDiff Coefficient'].append(-999999)\n",
      "                            discount_output['PR Sym Rank Coefficient'].append(-999999)\n",
      "                            discount_output['Num Stones'].append(len(df_temp))\n",
      "                            #discount_output['PR Intercept T-Stat'].append(-999999)\n",
      "                            discount_output['PR DepthDiff T-Stat'].append(-999999)\n",
      "                            discount_output['PR Sym Rank T-Stat'].append(-999999)                       \n",
      "\n",
      "                ## The discounts for princess cuts are different than Rounds\n",
      "                ## In Rounds, I determined cut grade and fluorescence to be primary price drivers after you \n",
      "                ## control for color, clarity, and size\n",
      "                ## In Princess cuts, I ran regressions and discovered the stone side length ratio and depth were the most statistically \n",
      "                ## price predictors after you control for color, clarity, and size\n",
      "                ## The discounts for princesses are generated by a multivariate linear model where the inputs are \n",
      "                ## ratio and depth and the output is a discount (i.e., % difference) from the model price\n",
      "                else:            \n",
      "                    df_regress_temp = df_temp[(df_temp['PredictedPercentDiff'] <= 0.1) & (df_temp['Carat'] >= .4)]\n",
      "                    df_princess_regression = pd.DataFrame([df_regress_temp['PredictedPercentDiff'],df_regress_temp['DepthDiff'],df_regress_temp['SymRank']]).transpose()\n",
      "                    reg_results = pd.ols(y=df_princess_regression['PredictedPercentDiff'], \\\n",
      "                                         x=df_princess_regression.drop(['PredictedPercentDiff'], axis=1),\\\n",
      "                                         intercept=False)\n",
      "                    for j in discount_groups[m][0]:\n",
      "                        for k in discount_groups[m][1]:\n",
      "                            df_number_of_stones.ix[j,k] = len(df_temp)\n",
      "                            discount_output['Tag'].append(\"%s_%sct_%sct_%s_%s_%s\" %(shape_tag,min_carat,max_carat,j,k,tag))\n",
      "                            discount_output['RB Avg Discount'].append(-999999)\n",
      "                            discount_output['RB Median Discount'].append(-999999) \n",
      "                            discount_output['RB Discount Stdev'].append(-999999)                            \n",
      "                            #discount_output['PR Intercept Coefficient'].append(reg_results.beta['intercept'])\n",
      "                            discount_output['PR DepthDiff Coefficient'].append(reg_results.beta['DepthDiff'])\n",
      "                            discount_output['PR Sym Rank Coefficient'].append(reg_results.beta['SymRank'])\n",
      "                            discount_output['Num Stones'].append(len(df_temp))\n",
      "                            #discount_output['PR Intercept T-Stat'].append(reg_results.t_stat['intercept'])\n",
      "                            discount_output['PR DepthDiff T-Stat'].append(reg_results.t_stat['DepthDiff'])\n",
      "                            discount_output['PR Sym Rank T-Stat'].append(reg_results.t_stat['SymRank'])  \n",
      "                \n",
      "                \n",
      "        ## This is for the Discounts Tables ouput, which is a visual aid for sanity checking data... just formatting stuff\n",
      "        ## Probably not the most efficient way to do this, but I wrote it early on when my skillz were lacking\n",
      "        ## Not computationally intensive and only used for testing purposes, so not really worth investing time into fixing \n",
      "        ## Name column headers of each individual dataframe and combine them into a single large dataframe that can be ouput into excel\n",
      "\n",
      "\"\"\"\n",
      "        df_avg_discount.columns = clars_avg \n",
      "        df_med_discount.columns = clars_med\n",
      "        df_std_discount.columns = clars_std\n",
      "        df_number_of_stones.columns = clars_num\n",
      "    \n",
      "        for z in clars_avg: \n",
      "            df_discount[z] =  df_avg_discount[z]\n",
      "        for z in clars_med: \n",
      "            df_discount[z] =  df_med_discount[z]\n",
      "        for z in clars_std: \n",
      "            df_discount[z] =  df_std_discount[z]\n",
      "        for z in clars_num: \n",
      "            df_discount[z] =  df_number_of_stones[z]\n",
      "            \n",
      "        df_discount['Blank_Col_avg'] = colors\n",
      "        df_discount['Blank_Col_med'] = colors\n",
      "        df_discount['Blank_Col_std'] = colors    \n",
      "        \n",
      "        #pd.DataFrame([\"\", \"%s ct-%s ct-%s-%s\" %(min_carat,max_carat,shape, tag)]).to_csv('/home/oliver/Dropbox/whitepine/discounts_tables1.csv', mode = 'a', header=False)\n",
      "        #pd.DataFrame(clars_tot).T.to_csv('/home/oliver/Dropbox/whitepine/discounts_tables1.csv', mode = 'a', header=False)\n",
      "        #df_discount.to_csv('/home/oliver/Dropbox/whitepine/discounts_tables1.csv', mode = 'a', header=False)\n",
      "\"\"\"\n",
      "\n",
      "## Create index for discount list dataframe and then create the dataframe... methodology taken from pandas docs\n",
      "arrays = [discount_output['Tag']]\n",
      "tuples = zip(*arrays)\n",
      "index = pd.MultiIndex.from_tuples(tuples)        \n",
      "df_discount_output = pd.DataFrame(discount_output, index=index,  columns=['RB Avg Discount', 'RB Median Discount', 'RB Discount Stdev', \\\n",
      "                         'PR DepthDiff Coefficient', 'PR Sym Rank Coefficient', \\\n",
      "                         'PR DepthDiff T-Stat', 'PR Sym Rank T-Stat', 'Num Stones'])\n",
      "\n",
      "## Write discounts_list output to file, clear file first --- mmethod discountinued for Excel output instead\n",
      "#g = open(\"/home/oliver/Dropbox/whitepine/discounts_list.csv\", \"w\")\n",
      "#g.truncate()\n",
      "#g.close()\n",
      "#df_discount_output.to_csv('/home/oliver/Dropbox/whitepine/discounts_list.csv')\n",
      "\n",
      "## Write output to excel, including a specially formatted column to make it readable by the DVT in excel\n",
      "df_discount_output.to_excel(writer, 'DISCOUNTS LIST')\n",
      "temp = df_rap_price_list.reset_index()\n",
      "temp.columns = ['Shape','Color','Clarity','Min Wght','Max Wght','Price','Date']\n",
      "temp['Idx'] = temp.apply(lambda x: '%s_%s_%s_%s' %(x['Shape'], x['Color'], x['Clarity'], x['Min Wght']), axis=1)\n",
      "temp = temp.set_index(['Idx'])\n",
      "temp.to_excel(writer, 'RAP PRICE LIST')\n",
      "pd.DataFrame({}).to_excel(writer, 'sheet1') #inserting blank sheet in file - intentional\n",
      "writer.save()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Owner     CertNum   \n",
        "37425     2141919133      2\n",
        "71011     2151618811     19\n",
        "ASCNY     2156493772      7\n",
        "          S3G15375      NaN\n",
        "ATLANTIC  2131205753    NaN\n",
        "          2131205770    NaN\n",
        "AURA      1152532291     14\n",
        "AVO       1146246844     18\n",
        "          2156516904    NaN\n",
        "          5156030172    NaN\n",
        "          5156762194     74\n",
        "          5156816885    NaN\n",
        "BBUCUTT   1136258181     67\n",
        "BELGIUM   1152901423    NaN\n",
        "          1156173285     51\n",
        "          1156509147    NaN\n",
        "          2146477593      5\n",
        "          2146603519      5\n",
        "          2146611145      5\n",
        "          2146866350      5\n",
        "          2146872715      5\n",
        "          2146942739      5\n",
        "          2151500370    NaN\n",
        "          2151506779    NaN\n",
        "          2154402296      9\n",
        "          2154402405     77\n",
        "          2154402520     80\n",
        "          2154403172      7\n",
        "          2154403260    140\n",
        "          2154486760    NaN\n",
        "          2154969627     48\n",
        "          2154969881      9\n",
        "          2154970270      6\n",
        "          2154970661      9\n",
        "          2154970695      9\n",
        "          2154970704     16\n",
        "          2154970889      6\n",
        "          2154971326     15\n",
        "          2155381107     19\n",
        "          2155901717    NaN\n",
        "          2155901724    NaN\n",
        "          2156386357      2\n",
        "          2164230956    NaN\n",
        "          2164231717     17\n",
        "          2164440158      4\n",
        "          2164440261      4\n",
        "          6152402349     78\n",
        "          6152402371      9\n",
        "          6152402380     21\n",
        "          6152402507    114\n",
        "Name: days_to_sell, dtype: float64\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print sells['Carat'].head(50)\n",
      "print sells['weight_tag'].head(50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Owner    CertNum   \n",
        "100 DEM  10987725      0.70\n",
        "         1152613094    1.10\n",
        "         1156270296    0.47\n",
        "         1156376981    1.60\n",
        "         1156398782    0.40\n",
        "         1156533521    1.06\n",
        "         1156533522    1.52\n",
        "         1156566531    0.45\n",
        "         1156566532    0.62\n",
        "         1156568786    0.90\n",
        "         1156568789    1.23\n",
        "         1156569865    0.51\n",
        "         1156596560    0.66\n",
        "         1156659941    0.48\n",
        "         1156743946    0.65\n",
        "         1156769763    0.68\n",
        "         17428598      1.00\n",
        "         2131755468    0.32\n",
        "         2151225665    1.50\n",
        "         2151378502    0.41\n",
        "         2151389635    0.63\n",
        "         2151499671    1.51\n",
        "         2151517980    1.82\n",
        "         2151534594    0.72\n",
        "         2151534597    0.75\n",
        "         2151535543    0.73\n",
        "         2151535551    0.54\n",
        "         2151535567    1.07\n",
        "         2151545062    0.85\n",
        "         2151545438    0.61\n",
        "         2151566640    3.14\n",
        "         2151569860    0.37\n",
        "         2151569862    0.70\n",
        "         2151575529    0.40\n",
        "         2151578364    2.00\n",
        "         2151586684    0.81\n",
        "         2151588386    0.76\n",
        "         2151588392    0.54\n",
        "         2151589445    1.28\n",
        "         2151589468    0.89\n",
        "         2151606358    1.06\n",
        "         2151617320    1.08\n",
        "         2151634721    1.13\n",
        "         2151654809    1.05\n",
        "         2151656284    0.76\n",
        "         2151692586    0.70\n",
        "         2151697525    0.51\n",
        "         2151728218    1.00\n",
        "         2151738712    0.40\n",
        "         2151739090    1.03\n",
        "Name: Carat, dtype: float64\n",
        "Owner    CertNum   \n",
        "100 DEM  10987725      r070\n",
        "         1152613094    r110\n",
        "         1156270296    r045\n",
        "         1156376981    r150\n",
        "         1156398782    r040\n",
        "         1156533521    r105\n",
        "         1156533522    r150\n",
        "         1156566531    r045\n",
        "         1156566532    r060\n",
        "         1156568786    r090\n",
        "         1156568789    r120\n",
        "         1156569865    r050\n",
        "         1156596560    r065\n",
        "         1156659941    r045\n",
        "         1156743946    r065\n",
        "         1156769763    r065\n",
        "         17428598      r100\n",
        "         2131755468    r030\n",
        "         2151225665    r150\n",
        "         2151378502    r040\n",
        "         2151389635    r060\n",
        "         2151499671    r150\n",
        "         2151517980    r175\n",
        "         2151534594    r070\n",
        "         2151534597    r075\n",
        "         2151535543    r070\n",
        "         2151535551    r050\n",
        "         2151535567    r105\n",
        "         2151545062    r085\n",
        "         2151545438    r060\n",
        "         2151566640    None\n",
        "         2151569860    r035\n",
        "         2151569862    r070\n",
        "         2151575529    r040\n",
        "         2151578364    r200\n",
        "         2151586684    r080\n",
        "         2151588386    r075\n",
        "         2151588392    r050\n",
        "         2151589445    r120\n",
        "         2151589468    r085\n",
        "         2151606358    r105\n",
        "         2151617320    r105\n",
        "         2151634721    r110\n",
        "         2151654809    r105\n",
        "         2151656284    r075\n",
        "         2151692586    r070\n",
        "         2151697525    r050\n",
        "         2151728218    r100\n",
        "         2151738712    r040\n",
        "         2151739090    r103\n",
        "Name: weight_tag, dtype: object\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print all_df.iloc[-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LotNum                    50668347\n",
        "Shape             Cushion Modified\n",
        "Carat                         2.01\n",
        "Color                            F\n",
        "Clarity                        SI1\n",
        "Cut Grade                      NaN\n",
        "Price                         8324\n",
        "PctRap                       -0.25\n",
        "Cert                           GIA\n",
        "Depth                         67.6\n",
        "Table                           63\n",
        "Girdle       Medium-Slightly Thick\n",
        "Culet                         None\n",
        "Polish                   Excellent\n",
        "Sym                           Good\n",
        "Fluor                        None \n",
        "Meas                7.59x7.01x4.74\n",
        "Comment                        NaN\n",
        "NumStones                        1\n",
        "StockNum                     V8781\n",
        "Make                           NaN\n",
        "Date           2/3/2014 7:00:16 PM\n",
        "City                      New York\n",
        "State                     New York\n",
        "Country                        USA\n",
        "Image                          NaN\n",
        "Name: (2, yerudiam, 2156632990, 2014-02-05 00:00:00), dtype: object\n"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###################################################\n",
      "###### OLD CODE BELOW THIS CELL>>>> REFACTORING ABOVE!\n",
      "###################################################"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import rapnet_loader as rl\n",
      "# uncomment and run the following line to see the source for rapnet_loader\n",
      "#%load /home/oliver/ipynb/rapnet_loader.py\n",
      "\n",
      "#ADD = 1\n",
      "#REMOVE = 2\n",
      "#READD = 3\n",
      "#PRICE_CHANGE = 4\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "from os import path\n",
      "import glob\n",
      "import re\n",
      "from datetime import datetime,date,timedelta\n",
      "from pandas.io.parsers import read_csv\n",
      "import numpy as np\n",
      "from itertools import repeat\n",
      "import sys\n",
      "import traceback\n",
      "import gc\n",
      "from pandas.io.pytables import HDFStore\n",
      "import shutil\n",
      "\n",
      "ADD = 1\n",
      "REMOVE = 2\n",
      "READD = 3\n",
      "PRICE_CHANGE = 4\n",
      "\n",
      "DATA_PATH = '/home/oliver/rapnet_data'\n",
      "CACHE_PATH = '/home/oliver/rapnet_cache'\n",
      "COL_NAMES = ['LotNum', 'Owner', 'Shape', 'Carat', 'Color', 'Clarity', 'Cut Grade', 'Price', 'PctRap',\n",
      " 'Cert', 'Depth', 'Table', 'Girdle', 'Culet', 'Polish', 'Sym', 'Fluor', 'Meas', 'Comment',\n",
      " 'NumStones', 'CertNum', 'StockNum', 'Make', 'Date', 'City', 'State', 'Country', 'Image']\n",
      "\n",
      "def read_daily_file(file_date):\n",
      "    compression = None\n",
      "    daily_file = path.join(DATA_PATH, 'Rapnet_{0}_Main.csv'.format(file_date))\n",
      "    if not path.exists(daily_file):\n",
      "        daily_file = daily_file + '.gz'\n",
      "        compression = \"gzip\"\n",
      "    if not path.exists(daily_file):\n",
      "        return []\n",
      "    try:\n",
      "        return read_csv(daily_file, compression = compression, names = COL_NAMES, header = 0,\n",
      "                    #dtype = {'Owner':str, 'CertNum':str},\n",
      "                    engine = 'python')\n",
      "    except EOFError:\n",
      "        print 'bad file {0}; renaming'.format(daily_file)\n",
      "        shutil.move(daily_file, daily_file + '.bad')\n",
      "        return []\n",
      "\n",
      "# don't load fake cert nums\n",
      "bad_certs = { '123456789', '', '1234567890', '0' }\n",
      "\n",
      "def days_on_market(df):\n",
      "    # grp here is all rows matching the same (owner,certnum) key\n",
      "    # here we arrange by date\n",
      "    intervals = []\n",
      "    # the all_df frame is already sorted by date, so no need to re-sort here if it's the same df\n",
      "    #df.sortlevel(level='event_day', inplace=True)\n",
      "    grpd = df.groupby(level=['Owner','CertNum'])\n",
      "    t1 = datetime.now()\n",
      "    for grpname, vals in grpd:\n",
      "        # loop for each event_type/date entry in this stone's dataframe\n",
      "        # name is the original multiindex of the row prior to the groupby operation\n",
      "        for name, valseries in vals.iterrows(): \n",
      "            # looks back through all events for a given stone and generates\n",
      "            # a new row for each interval on the market, indexed by certnum and owner\n",
      "            # (the group name, or label\n",
      "            et = name[0]\n",
      "            #print et\n",
      "            if et == ADD or et == READD:\n",
      "                date_added = name[3] \n",
      "            elif et == REMOVE:\n",
      "                if date_added != None:\n",
      "                    date_removed = name[3]\n",
      "                    intervals.append([date_added, date_removed, grpname])\n",
      "                                    #index = pd.MultiIndex(levels = [grpname[0], grpname[1], date_removed])))\n",
      "\n",
      "    tuples = [iv[2] for iv in intervals]\n",
      "    return pd.DataFrame([iv[:2] for iv in intervals], index = pd.MultiIndex.from_tuples(tuples), columns = ['added','removed'])\n",
      "\n",
      "def filter_data(df):\n",
      "    indices = []\n",
      "    for k, grpdf in df.groupby(['Owner','CertNum']):\n",
      "        if len(grpdf) == 1:\n",
      "            indices.append(grpdf.index[0])\n",
      "        elif not k[1] in bad_certs:\n",
      "            # we were dropping a lot of dupes, so instead i'm\n",
      "            # just adding the one w/ the highest lot num\n",
      "            indices.append(grpdf.LotNum.idxmax())\n",
      "    nodupes = df.loc[indices]\n",
      "    #dupes = df.loc[df.index - indices]\n",
      "    if len(df) - len(nodupes) > 0:\n",
      "        print 'Filtering: dropped {0} of {1} rows'.format(len(df) - len(nodupes), len(df))\n",
      "    stones = nodupes[[c for c in COL_NAMES if not c in {'CertNum','Owner'}]]\n",
      "    stones.index = pd.MultiIndex.from_tuples([(owner, cert) for owner, cert in nodupes[['Owner','CertNum']].values],\n",
      "                                             names = ['Owner', 'CertNum'])\n",
      "    return stones\n",
      "\n",
      "def cache_records(records, active, file_date):  \n",
      "    now = datetime.now()\n",
      "    atts = {\n",
      "          'file_date': file_date,\n",
      "          'records': records,\n",
      "          'active':active\n",
      "        }\n",
      "    pd.Series(atts).to_pickle(path.join(CACHE_PATH, 'rapnet.pkl'))\n",
      "    print 'cache write took {0}'.format(datetime.now() - now)\n",
      "    #s = HDFStore(path.join(CACHE_PATH, 'rapnet.h5'), complevel=9, complib='blosc')\n",
      "    #s['records'] = records\n",
      "    #s['active'] = active\n",
      "    #s['attributes'] = pd.Series({'file_date':file_date})\n",
      "    \n",
      "def load_cache():\n",
      "    now = datetime.now()\n",
      "    #h5path = path.join(CACHE_PATH, 'rapnet.h5')\n",
      "    #if path.exists(h5path):\n",
      "    #    s = H5Store(h5path)\n",
      "    #    atts = s['attributes'].to_dict()\n",
      "    #    return s['records'], s['active'], atts['file_date']\n",
      "    pklpath = path.join(CACHE_PATH, 'rapnet.pkl')\n",
      "    if path.exists(pklpath):\n",
      "        s = pd.read_pickle(pklpath).to_dict()\n",
      "        print 'cache load took {0}'.format(datetime.now() - now)\n",
      "        return s['records'], s['active'], s['file_date']\n",
      "    return [], [], []\n",
      "\n",
      "def gen_file_dates(start_day):\n",
      "    oneday = timedelta(1)\n",
      "    today = datetime.today()\n",
      "    #today = datetime.strptime('20130304', '%Y%m%d')\n",
      "    cur_day = start_day\n",
      "    while cur_day <= today:\n",
      "        yield cur_day\n",
      "        cur_day = cur_day + oneday\n",
      "        \n",
      "def get_latest(grp):\n",
      "    grp.sortlevel(level='event_day', inplace=True, ascending = False)\n",
      "    return grp.iloc[0]\n",
      "\n",
      "def build_cache():\n",
      "    all_records, prev, prev_day = load_cache()\n",
      "    first_day = datetime(2013,3,3)\n",
      "    if prev_day:\n",
      "        first_day = datetime.strptime(prev_day, '%Y%m%d') + timedelta(1)\n",
      "        print 'build_cache starting after previous load date', prev_day\n",
      "    i = 0\n",
      "    def reindex(idx_day, idx_event, df):\n",
      "        df.index = pd.MultiIndex.from_tuples([(idx_event, owner, cert, idx_day) for owner, cert in df.index],\n",
      "                                             names = ['event_type','Owner','CertNum','event_day'])\n",
      "            \n",
      "    file_date = None\n",
      "    for cur_day in gen_file_dates(first_day):\n",
      "        file_date = cur_day.strftime('%Y%m%d')\n",
      "        now = datetime.now()\n",
      "        df = read_daily_file(file_date)\n",
      "        if len(df) == 0:\n",
      "            continue\n",
      "        print 'processing file for {0}...'.format(file_date),\n",
      "        active = filter_data(df)\n",
      "        if len(prev):\n",
      "            new_stones = active.loc[active.index - prev.index]\n",
      "            kept_stones = prev.loc[active.index & prev.index]\n",
      "            readds = []\n",
      "            if len(new_stones):           \n",
      "                # cross section of data - we only want things were previously \n",
      "                # removed, to see if any of the new_stones are actually re-adds\n",
      "                all_removals = []\n",
      "                try:\n",
      "                    all_removals = all_records.xs(REMOVE, level = 'event_type')\n",
      "                except KeyError:\n",
      "                    pass\n",
      "                if len(all_removals):\n",
      "                    prev_removals = all_removals.groupby(level=['Owner','CertNum']).apply(get_latest)\n",
      "                    if len(prev_removals):\n",
      "                        readds = new_stones.loc[new_stones.index & prev_removals.index]\n",
      "                        if len(readds):\n",
      "                            newonly = new_stones.index - readds.index\n",
      "                            if len(newonly):\n",
      "                                new_stones = new_stones.loc[newonly]\n",
      "                            else:\n",
      "                                new_stones = []\n",
      "\n",
      "            if len(new_stones):\n",
      "                reindex(cur_day, ADD, new_stones)\n",
      "                all_records = pd.concat([all_records, new_stones])\n",
      "\n",
      "            if len(readds):\n",
      "                reindex(cur_day, READD, readds)\n",
      "                all_records = pd.concat([all_records, readds])\n",
      "                \n",
      "            # join the stones not removed w/ the current load to see what's changed\n",
      "            joined_px = pd.merge(kept_stones, active, left_index = True, right_index = True)\n",
      "\n",
      "            # see if any prices have changed\n",
      "            px_changes = active.loc[joined_px[(joined_px.Price_x != joined_px.Price_y) & ~(np.isnan(joined_px.Price_y))].index]\n",
      "            if len(px_changes):\n",
      "                reindex(cur_day, PRICE_CHANGE, px_changes)\n",
      "                all_records = pd.concat([all_records, px_changes])\n",
      "\n",
      "            # see what's been removed\n",
      "            removals = prev.loc[prev.index - active.index]\n",
      "            if len(removals):\n",
      "                reindex(cur_day, REMOVE, removals)\n",
      "                all_records = pd.concat([all_records, removals])\n",
      "                \n",
      "            print '{0} new stones, {1} removals, {2} price changes, {3} readds'.format(\n",
      "                len(new_stones), len(removals), len(px_changes), len(readds))\n",
      "        else:\n",
      "            # create all_records w/ multiindex: event_date, event_type, certnum\n",
      "            all_records = active.copy()\n",
      "            reindex(cur_day, ADD, all_records)\n",
      "        cache_records(all_records, active, file_date)\n",
      "        prev = active\n",
      "        gc.collect()\n",
      "        print 'took {0}'.format(datetime.now() - now)\n",
      "    return all_records, prev, file_date\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "   build_cache()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print all_df.iloc[-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LotNum                  45277175\n",
        "Shape           Cushion Modified\n",
        "Carat                       4.47\n",
        "Color                          F\n",
        "Clarity                      VS2\n",
        "Cut Grade                    NaN\n",
        "Price                      24732\n",
        "PctRap                     -0.15\n",
        "Cert                         GIA\n",
        "Depth                       67.8\n",
        "Table                         57\n",
        "Girdle                Thin-Thick\n",
        "Culet                       None\n",
        "Polish                 Very Good\n",
        "Sym                         Good\n",
        "Fluor                      None \n",
        "Meas             10.34x8.75x5.93\n",
        "Comment         Canadian Product\n",
        "NumStones                      1\n",
        "StockNum                   V8182\n",
        "Make                         NaN\n",
        "Date         2/5/2014 5:40:33 PM\n",
        "City                    New York\n",
        "State                   New York\n",
        "Country                      USA\n",
        "Image                        NaN\n",
        "Name: (2, yerudiam, 5151422337, 2014-02-07 00:00:00), dtype: object\n"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_df, current_df, file_date = rl.load_cache()\n",
      "# all_df is the whole database, with the event types you see in the above cell\n",
      "# the index is a multiindex with levels ('event_type','Owner','CertNum,'event_day')\n",
      "\n",
      "#this gets the latest removals:\n",
      "#prev_removals = all_df.xs(rl.REMOVE, level='event_type').groupby(level=['Owner','CertNum']).apply(rl.get_latest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cache load took 0:00:16.992462\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gd_plus = ['Excellent', 'Very Good', 'Good']\n",
      "fluor_faint = ['Faint ', 'Faint Blue', 'Slight', 'Very Slight ', 'Slight Blue', 'Very Slight Blue'] #Do NOT delete spaces at end of items in this list\n",
      "fluor_none = ['None '] #Do NOT delete spaces at end of items in this list\n",
      "fluor_medium = ['Medium ', 'Medium Blue', 'Medium Yellow'] #Do NOT delete spaces at end of items in this list\n",
      "fluor_strong = ['Strong ', 'Strong Blue', 'Very Strong Blue', 'Very Strong ']\n",
      "\n",
      "\n",
      "colors = ['F', 'G', 'H', 'I']\n",
      "clars = ['VS1', 'VS2', 'SI1', 'SI2']\n",
      "\n",
      "filtered_df = all_df[(all_df['Carat'] >= 0.23) \\\n",
      "                     & (all_df['Carat'] <= 0.29) \\\n",
      "                     & (all_df['Cut Grade'].isin(gd_plus)) \\\n",
      "                     & (all_df['Sym'].isin(gd_plus)) \\\n",
      "                     & (all_df['Polish'].isin(gd_plus)) \\\n",
      "                     #& (all_df['Polish'].isin(gd_plus)) \\\n",
      "                     & (all_df['Cert'] == 'GIA') \\\n",
      "                     #& (all_df['City'] == 'New York') \\\n",
      "                     & (all_df['Country'] == 'USA') \\\n",
      "                     #& (all_df['Color'] == 'G') \\\n",
      "                     #& (all_df['Clarity'] =='VS1') \\\n",
      "                     #& (all_df['Color'].isin(colors)) \\\n",
      "                     #& (all_df['Clarity'].isin(clars)) \\\n",
      "                     #& (all_df['Fluor'].isin(fluor_none)) \\\n",
      "                     ]\n",
      "\n",
      "filtered_df = filtered_df.reset_index()\n",
      "filtered_df['CertNum'] = filtered_df['CertNum'].str.replace('*', '')\n",
      "filtered_df = filtered_df.set_index(['Owner','CertNum'])\n",
      "\n",
      "filtered_df['TotalPrice'] = filtered_df['Price'] * filtered_df['Carat']\n",
      "\n",
      "print len(filtered_df)\n",
      "print filtered_df.index.names\n",
      "print filtered_df.columns.names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "40012\n",
        "['Owner', 'CertNum']\n",
        "[None]\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "temps = all_df[(all_df['Carat'] >= 0.75) \\\n",
      "                     & (all_df['Carat'] <= 0.79) \\\n",
      "                     & (all_df['Cut Grade'] == 'Excellent') \\\n",
      "                     & (all_df['Sym'].isin(gd_plus)) \\\n",
      "                     & (all_df['Polish'].isin(gd_plus)) \\\n",
      "                     & (all_df['Cert'] == 'GIA') \\\n",
      "                     & (all_df['Country'] == 'USA') \\\n",
      "                     & (all_df['Color'] == 'H') \\\n",
      "                     & (all_df['Clarity'] =='VS1') \\\n",
      "                     #& (all_df['Color'].isin(colors)) \\\n",
      "                     #& (all_df['Clarity'].isin(clars)) \\\n",
      "                     & (all_df['Fluor'].isin(fluor_none)) \\\n",
      "                     ]\n",
      "\n",
      "temps = temps.reset_index()\n",
      "temps['CertNum'] = temps['CertNum'].str.replace('*', '')\n",
      "temps = temps.set_index(['Owner','CertNum'])\n",
      "\n",
      "print len(temps)\n",
      "\n",
      "groupies = temps.groupby(level = ['Owner','CertNum'])\n",
      "\n",
      "temps.to_csv('/home/oliver/Dropbox/whitepine/groupies.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "141\n"
       ]
      }
     ],
     "prompt_number": 321
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 1 - 1.5ct round sells\n",
      "\n",
      "import pandas as pd\n",
      "from os import path\n",
      "import glob\n",
      "import re\n",
      "from datetime import datetime,date,timedelta\n",
      "from pandas.io.parsers import read_csv\n",
      "import numpy as np\n",
      "from itertools import repeat\n",
      "import sys\n",
      "import traceback\n",
      "import gc\n",
      "from pandas.io.pytables import HDFStore\n",
      "import shutil\n",
      "from scipy import stats\n",
      "\n",
      "fluors = [fluor_none, fluor_faint, fluor_medium, fluor_strong]\n",
      "fluor_tags = ['None', 'Faint', 'Medium', 'Strong and VST']\n",
      "\n",
      "nowstart = datetime.now()\n",
      "sell_lag = 30\n",
      "start_date = datetime(2013, 3, 3)\n",
      "\n",
      "def get_first(grp):\n",
      "    grp.sort(columns='event_day', inplace=True, ascending = False)\n",
      "    return grp.iloc[-1]\n",
      "\n",
      "def get_last(grp):\n",
      "    grp.sort(columns='event_day', inplace=True, ascending = False)\n",
      "    return grp.iloc[0]\n",
      "\n",
      "def days_to_sell(row):\n",
      "    if row['event_type_first'] == 1 and row['event_type_last'] == 2 and row['event_day_last'] < (datetime.now()-timedelta(days=sell_lag)):\n",
      "        return (row['event_day_last'] - row['event_day_first']).days\n",
      "    else:\n",
      "        return np.nan\n",
      "\n",
      "def get_percentile(dframe):\n",
      "    for g in range(len(dframe)):\n",
      "        if dframe['event_type_first'].iloc[g] == 1 and dframe['event_type_last'].iloc[g] == 2 \\\n",
      "        and dframe['event_day_last'].iloc[g] < (datetime.now()-timedelta(days=sell_lag)):\n",
      "            sale_date = dframe['event_day_last'].iloc[g]\n",
      "            add_date = dframe['event_day_first'].iloc[g]\n",
      "            last_price = dframe['TotalPrice_last'].iloc[g]\n",
      "            df1 = dframe[(dframe['event_day_first'] < add_date) & (dframe['event_day_last'] < sale_date) & \\\n",
      "                         (dframe['event_type_last'].isin([1,3,4]))]\n",
      "            return stats.percentileofscore(df1['TotalPrice_last'],last_price)\n",
      "        else:\n",
      "            return np.nan\n",
      "\n",
      "carat_bins = [\n",
      "              ['GIA', 'Round', 0.23, 0.29, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.23, 0.29, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.23, 0.29, 'Good'], \\\n",
      "             ]\n",
      "\n",
      "\n",
      "groups = [\n",
      "            ['H','VS1','H Color','VS1 Clarity'],\\\n",
      "            ['H','VS2','H Color','VS2 Clarity'],\\\n",
      "            ['H','SI1','H Color','SI1 Clarity'],\\\n",
      "            ['H','SI2','H Color','SI2 Clarity'],\\\n",
      "        ]\n",
      "\n",
      "\n",
      "#filtered_reset = filtered_df.reset_index(level=['event_type', 'event_day'])\n",
      "#last_entry = filtered_reset.groupby(level=['Owner','CertNum']).apply(get_last)\n",
      "#first_entry = filtered_reset.groupby(level=['Owner','CertNum']).apply(get_first)\n",
      "#prev_removals = first_entry.join(last_entry, lsuffix='_first', rsuffix='_last')\n",
      "#prev_removals['days_to_sell'] = np.nan\n",
      "#prev_removals['days_to_sell'] = prev_removals.apply(days_to_sell, axis = 1)\n",
      "\n",
      "sells = [] \n",
      "\n",
      "output = {\\\n",
      "            'Lab' : [], \\\n",
      "            'Color' : [], \\\n",
      "            'Clarity' : [], \\\n",
      "            'Location' : [], \\\n",
      "            'WeightMin' : [], \\\n",
      "            'WeightMax' : [], \\\n",
      "            'GroupColor' : [], \\\n",
      "            'GroupClarity' : [], \\\n",
      "            'Cut' : [], \\\n",
      "            'Fluor' : [], \\\n",
      "            'NumSales' : [], \\\n",
      "            'TotalStonesInDB': [],\\\n",
      "            'AvgTimeToSell' : [], \\\n",
      "            'MedianTimeToSell' : [], \\\n",
      "            'StdDevTimeToSell' : [], \\\n",
      "            #'NumInventory' : [], \\\n",
      "            #'AvgInventoryAge' : [], \\\n",
      "            #'MedianInventoryAge' : [], \\\n",
      "            #'StdInventoryAge' : [], \\\n",
      "            'AveragePercentileActiveListings' : [], \\\n",
      "            'AveragePercentileAllListings' : [], \\\n",
      "            'DailyAverageInventoryNumStone' : [], \\\n",
      "            'DailyAverageInventoryValue' : [], \\\n",
      "            'AnnualInventoryTurn' : [], \\\n",
      "            }\n",
      "\n",
      "for zz in range(len(fluors)):\n",
      "    fluor = fluors[zz]\n",
      "    fluor_tag = fluor_tags[zz]\n",
      "    for i in range(len(carat_bins)):\n",
      "        lab = carat_bins[i][0]\n",
      "        shape = carat_bins[i][1]\n",
      "        min_ct = carat_bins[i][2]\n",
      "        max_ct = carat_bins[i][3]\n",
      "        cut = carat_bins[i][4]\n",
      "        for j in range(len(groups)):\n",
      "            color = groups[j][0]\n",
      "            clar = groups[j][1]\n",
      "            colortag = groups[j][2]\n",
      "            clartag = groups[j][3]\n",
      "            #print \"BREAK\"\n",
      "            #print 'min %s - max %s - color %s - clar %s - cut %s - fluor %s' %(min_ct, max_ct, color, clar, cut, fluor)\n",
      "            df_filt = filtered_df[ \\\n",
      "                        #(prev_removals['Lab_F'] == lab) \\ - Do not remove... not currently necessary b/c prefiltering for these\n",
      "                         (filtered_df['Carat'] >= min_ct) \\\n",
      "                        & (filtered_df['Carat'] <= max_ct) \\\n",
      "                        & (filtered_df['Color']== color) \\\n",
      "                        & (filtered_df['Clarity']== clar) \\\n",
      "                        & (filtered_df['Cut Grade'] == cut) \\\n",
      "                        & (filtered_df['TotalPrice'] > 1) \\\n",
      "                        & (filtered_df['Fluor'].isin(fluor)) \\\n",
      "                        #& (prev_removals['Country_F'] == 'USA') \\\n",
      "                        #& (prev_removals['EventDate_F'] <= (datetime.now()-timedelta(days=30))) \\\n",
      "                        ]\n",
      "            \n",
      "            \n",
      "            last_entry = df_filt.groupby(level=['Owner','CertNum']).apply(get_last)\n",
      "            first_entry = df_filt.groupby(level=['Owner','CertNum']).apply(get_first)\n",
      "            df_temp = first_entry.join(last_entry, lsuffix='_first', rsuffix='_last')\n",
      "                        \n",
      "            df_temp['days_to_sell'] = np.nan\n",
      "            df_temp['days_to_sell'] = df_temp.apply(days_to_sell, axis = 1)\n",
      "            df_temp['PercentileActive'] = np.nan\n",
      "            df_temp['PercentileAll'] = np.nan\n",
      "            df_temp['InventoryUponSale'] = np.nan\n",
      "            \n",
      "            if len(df_temp):\n",
      "                for g in range(len(df_temp)):\n",
      "                    if df_temp['days_to_sell'].iloc[g] != np.nan:\n",
      "                        sale_date = df_temp['event_day_last'].iloc[g]\n",
      "                        add_date = df_temp['event_day_first'].iloc[g]\n",
      "                        last_price = df_temp['TotalPrice_last'].iloc[g]\n",
      "                        df_active_comps = df_temp[df_temp.apply(lambda x: ((x['event_day_last'] <= sale_date) & (x['event_type_last'] != 2)) \\\n",
      "                                                       or ((x['event_day_last'] >= sale_date) & (x['event_day_first'] <= sale_date)), axis=1)]\n",
      "                        last_prices = df_filt[df_filt['event_day'] <= sale_date].groupby(level=['Owner','CertNum']).apply(get_last)\n",
      "                        df_active_prices  = df_active_comps.join(last_prices)\n",
      "                        df_temp['PercentileActive'].iloc[g] = stats.percentileofscore(df_active_prices['TotalPrice'],last_price)-100/len(df_active_prices)\n",
      "                        df_temp['PercentileAll'] = stats.percentileofscore(df_temp['TotalPrice_last'],last_price)-100/len(df_temp)\n",
      "                        df_temp['InventoryUponSale'] = len(df_active_prices)\n",
      "                        sells.append(df_temp.iloc[g])\n",
      "                    else:\n",
      "                        pass\n",
      "\n",
      "                inv_num_stones = []\n",
      "                inv_total_value = []\n",
      "                for d in range((datetime.now() - start_date - timedelta(days=sell_lag)).days):\n",
      "                    date = start_date + timedelta(days = d)\n",
      "                    df_inv = df_temp[df_temp.apply(lambda x: ((x['event_day_last'] <= date) & (x['event_type_last'] != 2)) \\\n",
      "                                                       or ((x['event_day_last'] >= date) & (x['event_day_first'] <= date)), axis=1)]\n",
      "                    inv_num_stones.append(len(df_inv))\n",
      "                    inv_total_value.append(np.sum(df_inv['TotalPrice_last']))\n",
      "            else:\n",
      "                pass\n",
      "                        \n",
      "            if df_temp['days_to_sell'].count() > 1:\n",
      "                avgtimetosell = np.mean(df_temp['days_to_sell'])\n",
      "                medtimetosell = stats.nanmedian(df_temp['days_to_sell'])\n",
      "                stdevtimetosell = np.std(df_temp['days_to_sell'])\n",
      "                avgpileactive = np.mean(df_temp['PercentileActive'])\n",
      "                avgpileall = np.mean(df_temp['PercentileAll'])\n",
      "                inv = np.mean(df_temp['InventoryUponSale'])\n",
      "                totalstones = len(df_temp)\n",
      "                numsales = df_temp['days_to_sell'].count()\n",
      "                #avg_sale_value\n",
      "                #avg_sale_value = df_temp.apply(lambda x: if x['days_to_sell'] >= 1, avg_sale_valu, axis=1)\n",
      "                #avg_num_stones = float(inv_num_stones/(datetime.now() - start_date - timedelta(days=sell_lag)).days)\n",
      "                #avg_total_value = inv_total_value/(datetime.now() - start_date - timedelta(days=sell_lag)).days\n",
      "                avg_num_stones = np.mean(inv_num_stones)\n",
      "                avg_daily_inv_value = np.mean(inv_total_value)\n",
      "                tot_sale_value = np.sum(df_temp['TotalPrice_last'][df_temp.apply(lambda x: x['days_to_sell'] >= 1,axis =1)])\n",
      "                turns = 365*(tot_sale_value/(datetime.now() - start_date - timedelta(days=sell_lag)).days)/avg_daily_inv_value\n",
      "                           \n",
      "                output['Lab'].append('GIA')\n",
      "                output['Color'].append(color)    \n",
      "                output['Clarity'].append(clar)\n",
      "                output['Location'].append('USA')\n",
      "                output['WeightMin'].append(min_ct)\n",
      "                output['WeightMax'].append(max_ct)\n",
      "                output['GroupColor'].append(colortag)        \n",
      "                output['GroupClarity'].append(clartag)                    \n",
      "                output['Cut'].append(cut)\n",
      "                output['Fluor'].append(fluor_tag)            \n",
      "                output['NumSales'].append(numsales)\n",
      "                output['TotalStonesInDB'].append(totalstones)            \n",
      "                output['AvgTimeToSell'].append(avgtimetosell)\n",
      "                output['MedianTimeToSell'].append(medtimetosell)\n",
      "                output['StdDevTimeToSell'].append(stdevtimetosell)\n",
      "                output['AveragePercentileActiveListings'].append(avgpileactive)\n",
      "                output['AveragePercentileAllListings'].append(avgpileall)     \n",
      "                output['DailyAverageInventoryNumStone'].append(avg_num_stones)\n",
      "                output['DailyAverageInventoryValue'].append(avg_daily_inv_value)\n",
      "                output['AnnualInventoryTurn'].append(turns)\n",
      "            else:\n",
      "                totalstones = len(df_temp)\n",
      "                numsales = df_temp['days_to_sell'].count()\n",
      "                avg_num_stones = np.nan\n",
      "                avg_daily_inv_value = np.nan\n",
      "                tot_sale_value = np.nan\n",
      "                turns = np.nan\n",
      "                \n",
      "                output['Lab'].append('GIA')\n",
      "                output['Color'].append(color)    \n",
      "                output['Clarity'].append(clar)            \n",
      "                output['Location'].append('USA')\n",
      "                output['WeightMin'].append(min_ct)\n",
      "                output['WeightMax'].append(max_ct)\n",
      "                output['GroupColor'].append(colortag)        \n",
      "                output['GroupClarity'].append(clartag)      \n",
      "                output['Cut'].append(cut)\n",
      "                output['Fluor'].append(fluor_tag)\n",
      "                output['NumSales'].append(numsales)\n",
      "                output['TotalStonesInDB'].append(totalstones)\n",
      "                output['AvgTimeToSell'].append(np.nan)\n",
      "                output['MedianTimeToSell'].append(np.nan)\n",
      "                output['StdDevTimeToSell'].append(np.nan)\n",
      "                output['AveragePercentileActiveListings'].append(np.nan)              \n",
      "                output['AveragePercentileAllListings'].append(np.nan)                     \n",
      "                output['DailyAverageInventoryNumStone'].append(avg_num_stones)\n",
      "                output['DailyAverageInventoryValue'].append(avg_daily_inv_value)\n",
      "                output['AnnualInventoryTurn'].append(turns)\n",
      "                \n",
      "       \n",
      "df_hold_per = pd.DataFrame(output, columns = ['Lab', \\\n",
      "                                              'Color', \\\n",
      "                                              'Clarity', \\\n",
      "                                              'WeightMin', \\\n",
      "                                              'WeightMax', \\\n",
      "                                              'GroupColor', \\\n",
      "                                              'GroupClarity', \\\n",
      "                                              'Cut', \\\n",
      "                                              'Fluor', \\\n",
      "                                              'NumSales', \\\n",
      "                                              'TotalStonesInDB', \\\n",
      "                                              'AvgTimeToSell', \\\n",
      "                                              'MedianTimeToSell', \\\n",
      "                                              'StdDevTimeToSell', \\\n",
      "                                              'AveragePercentileActiveListings', \\\n",
      "                                              'AveragePercentileAllListings', \\\n",
      "                                              'DailyAverageInventoryNumStone', \\\n",
      "                                              'DailyAverageInventoryValue', \\\n",
      "                                              'AnnualInventoryTurn', \\\n",
      "                                              ])\n",
      "\n",
      "df_hold_per.to_csv('/home/oliver/Dropbox/whitepine/avg_holding_period.csv')\n",
      "pd.DataFrame(sells).to_csv('/home/oliver/Dropbox/whitepine/test.csv')\n",
      "\n",
      "print datetime.now() - nowstart\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0:00:07.317361\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_hold_per = pd.DataFrame(output, columns = ['Lab', \\\n",
      "                                              'Color', \\\n",
      "                                              'Clarity', \\\n",
      "                                              'WeightMin', \\\n",
      "                                              'WeightMax', \\\n",
      "                                              'GroupColor', \\\n",
      "                                              'GroupClarity', \\\n",
      "                                              'Cut', \\\n",
      "                                              'Fluor', \\\n",
      "                                              'NumSales', \\\n",
      "                                              'TotalStonesInDB', \\\n",
      "                                              'AvgTimeToSell', \\\n",
      "                                              'MedianTimeToSell', \\\n",
      "                                              'StdDevTimeToSell', \\\n",
      "                                              'AveragePercentileActiveListings', \\\n",
      "                                              'AveragePercentileAllListings', \\\n",
      "                                              'DailyAverageInventoryNumStone', \\\n",
      "                                              'DailyAverageInventoryValue', \\\n",
      "                                              'AnnualInventoryTurn', \\\n",
      "                                              ])\n",
      "\n",
      "df_hold_per.to_csv('/home/oliver/Dropbox/whitepine/avg_holding_period.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 251
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "super_groups = [\n",
      "            [['D','E','F','G','H','I','J'], ['IF','VVS1','VVS2','VS1','VS2','SI1','SI2'], 'D to J Color','IF to SI2 Clarity'], \\\n",
      "            [['F','G','H','I','J'], ['VS1','VS2','SI1','SI2'], 'Coffee Pot Colors', 'Coffee Pots Clars'], \\\n",
      "            [['D'], ['IF','VVS1','VVS2','VS1','VS2','SI1','SI2'], 'D Color', 'IF to SI2 Clarity'], \\\n",
      "            [['E'], ['IF','VVS1','VVS2','VS1','VS2','SI1','SI2'], 'E Color', 'IF to SI2 Clarity'], \\\n",
      "            [['F'], ['IF','VVS1','VVS2','VS1','VS2','SI1','SI2'], 'F Color', 'IF to SI2 Clarity'], \\\n",
      "            [['G'], ['IF','VVS1','VVS2','VS1','VS2','SI1','SI2'], 'G Color', 'IF to SI2 Clarity'], \\\n",
      "            [['H'], ['IF','VVS1','VVS2','VS1','VS2','SI1','SI2'], 'H Color', 'IF to SI2 Clarity'], \\\n",
      "            [['I'], ['IF','VVS1','VVS2','VS1','VS2','SI1','SI2'], 'I Color', 'IF to SI2 Clarity'], \\\n",
      "            [['J'], ['IF','VVS1','VVS2','VS1','VS2','SI1','SI2'], 'J Color', 'IF to SI2 Clarity'], \\\n",
      "            [['D','E','F','G','H','I','J'], ['IF'], 'D to J Color','IF Clarity'], \\\n",
      "            [['D','E','F','G','H','I','J'], ['VVS1'], 'D to J Color','VVS1 Clarity'], \\\n",
      "            [['D','E','F','G','H','I','J'], ['VVS2'], 'D to J Color','VVS2 Clarity'], \\\n",
      "            [['D','E','F','G','H','I','J'], ['VS1'], 'D to J Color','VS1 Clarity'], \\\n",
      "            [['D','E','F','G','H','I','J'], ['VS2'], 'D to J Color','VS2 Clarity'], \\\n",
      "            [['D','E','F','G','H','I','J'], ['SI1'], 'D to J Color','SI1 Clarity'], \\\n",
      "            [['D','E','F','G','H','I','J'], ['SI2'], 'D to J Color','SI2 Clarity'], \\\n",
      "            ]\n",
      "\n",
      "df_hold_temp = df_hold_per.copy()\n",
      "\n",
      "\"\"\"\n",
      "for i in range(len(df_hold_temp)):\n",
      "    if len(df_hold_temp['Color'].iloc[i]) == 1:\n",
      "        df_hold_temp['Color'].iloc[i] = df_hold_temp['Color'].iloc[i][0]\n",
      "    else:\n",
      "        df_hold_temp['Color'].iloc[i] = \"emptyset\"\n",
      "    if len(df_hold_temp['Clarity'].iloc[i]) == 1:\n",
      "        df_hold_temp['Clarity'].iloc[i] = df_hold_temp['Clarity'].iloc[i][0]\n",
      "    else:\n",
      "        df_hold_temp['Clarity'].iloc[i] = \"emptyset\"\n",
      "\"\"\"     \n",
      "\n",
      "#df_hold_temp['Color'] = df_hold_temp['Color'][0]\n",
      "#df_hold_temp['Color'] = df_hold_temp['Color'][0]\n",
      "#df_hold_temp['Color'] = df_hold_temp['Color'][0]\n",
      "#df_hold_temp['Clarity'] = df_hold_temp['Clarity'][0]\n",
      "#df_hold_temp['Clarity'] = df_hold_temp['Clarity'][0]\n",
      "#df_hold_temp['Clarity'] = df_hold_temp['Clarity'].str.replace(\"'\", '')\n",
      "\n",
      "\n",
      "output2 = {\\\n",
      "            'Lab' : [], \\\n",
      "            'Color' : [], \\\n",
      "            'Clarity' : [], \\\n",
      "            'WeightMin' : [], \\\n",
      "            'WeightMax' : [], \\\n",
      "            'GroupColor' : [], \\\n",
      "            'GroupClarity' : [], \\\n",
      "            'Cut' : [], \\\n",
      "            'Fluor' : [], \\\n",
      "            'NumSales' : [], \\\n",
      "            'TotalStonesInDB': [],\\\n",
      "            'AvgTimeToSell' : [], \\\n",
      "            'MedianTimeToSell' : [], \\\n",
      "            'AveragePercentileActiveListings' : [], \\\n",
      "            'AveragePercentileAllListings' : [], \\\n",
      "            'DailyAverageInventoryNumStone' : [], \\\n",
      "            'DailyAverageInventoryValue' : [], \\\n",
      "            'AnnualInventoryTurn' : [], \\\n",
      "            }\n",
      "for zz in range(len(fluors)):\n",
      "    fluor = fluors[zz]\n",
      "    fluor_tag = fluor_tags[zz]\n",
      "    for i in range(len(carat_bins)):\n",
      "        lab = carat_bins[i][0]\n",
      "        shape = carat_bins[i][1]\n",
      "        min_ct = carat_bins[i][2]\n",
      "        max_ct = carat_bins[i][3]\n",
      "        cut = carat_bins[i][4]\n",
      "        for j in range(len(super_groups)):\n",
      "            color = super_groups[j][0]\n",
      "            clar = super_groups[j][1]\n",
      "            colortag = super_groups[j][2]\n",
      "            clartag = super_groups[j][3]\n",
      "            \n",
      "            df_temp = df_hold_temp[ \\\n",
      "                        (df_hold_temp['WeightMin'] == min_ct) \\\n",
      "                        & (df_hold_temp['WeightMax'] == max_ct) \\\n",
      "                        & (df_hold_temp['Color'].isin(color)) \\\n",
      "                        & (df_hold_temp['Clarity'].isin(clar)) \\\n",
      "                        & (df_hold_temp ['Cut'] == cut) \n",
      "                        & (df_hold_temp['NumSales'] > 6) \\\n",
      "                        & (df_hold_temp['Fluor'] == fluor_tag) \\\n",
      "                        #& (prev_removals['Country_F'] == 'USA') \\\n",
      "                        #& (prev_removals['EventDate_F'] <= (datetime.now()-timedelta(days=30))) \\\n",
      "                        ]\n",
      "            \n",
      "            if len(df_temp) > 0:   \n",
      "                output2['Lab'].append('GIA')\n",
      "                output2['Color'].append(color)    \n",
      "                output2['Clarity'].append(clar)\n",
      "                output2['WeightMin'].append(min_ct)\n",
      "                output2['WeightMax'].append(max_ct)\n",
      "                output2['GroupColor'].append(colortag)        \n",
      "                output2['GroupClarity'].append(clartag)                    \n",
      "                output2['Cut'].append(cut)\n",
      "                output2['Fluor'].append(fluor_tag)\n",
      "                output2['NumSales'].append(np.mean(df_temp['NumSales']))\n",
      "                output2['TotalStonesInDB'].append(np.mean(df_temp['TotalStonesInDB']))\n",
      "                output2['AvgTimeToSell'].append(np.mean(df_temp['AvgTimeToSell']))\n",
      "                output2['MedianTimeToSell'].append(np.mean(df_temp['MedianTimeToSell']))\n",
      "                output2['AveragePercentileActiveListings'].append(np.mean(df_temp['AveragePercentileActiveListings']))\n",
      "                output2['AveragePercentileAllListings'].append(np.nan)\n",
      "                output2['DailyAverageInventoryNumStone'].append(np.mean(df_temp['DailyAverageInventoryNumStone']))\n",
      "                output2['DailyAverageInventoryValue'].append(np.nan)\n",
      "                output2['AnnualInventoryTurn'].append(np.mean(df_temp['AnnualInventoryTurn']))\n",
      "            else:\n",
      "                output2['Lab'].append('GIA')\n",
      "                output2['Color'].append(color)    \n",
      "                output2['Clarity'].append(clar)            \n",
      "                output2['WeightMin'].append(min_ct)\n",
      "                output2['WeightMax'].append(max_ct)\n",
      "                output2['GroupColor'].append(colortag)        \n",
      "                output2['GroupClarity'].append(clartag)      \n",
      "                output2['Cut'].append(cut)\n",
      "                output2['Fluor'].append(fluor_tag)\n",
      "                output2['NumSales'].append(0)\n",
      "                output2['TotalStonesInDB'].append(0)\n",
      "                output2['AvgTimeToSell'].append(np.nan)\n",
      "                output2['MedianTimeToSell'].append(np.nan)\n",
      "                output2['AveragePercentileActiveListings'].append(np.nan)              \n",
      "                output2['AveragePercentileAllListings'].append(np.nan)                     \n",
      "                output2['DailyAverageInventoryNumStone'].append(np.nan) \n",
      "                output2['DailyAverageInventoryValue'].append(np.nan) \n",
      "                output2['AnnualInventoryTurn'].append(np.nan)\n",
      "\n",
      "a = pd.DataFrame(output2, columns = ['Lab', \\\n",
      "                                            'Color', \\\n",
      "                                            'Clarity', \\\n",
      "                                            'WeightMin', \\\n",
      "                                            'WeightMax', \\\n",
      "                                            'GroupColor', \\\n",
      "                                            'GroupClarity', \\\n",
      "                                            'Cut', \\\n",
      "                                            'Fluor', \\\n",
      "                                            'NumSales', \\\n",
      "                                            'TotalStonesInDB', \\\n",
      "                                            'AvgTimeToSell', \\\n",
      "                                            'MedianTimeToSell', \\\n",
      "                                            'AveragePercentileActiveListings', \\\n",
      "                                            'AveragePercentileAllListings', \\\n",
      "                                            'DailyAverageInventoryNumStone', \\\n",
      "                                            'DailyAverageInventoryValue', \\\n",
      "                                            'AnnualInventoryTurn', \\\n",
      "                                            ])\n",
      "\n",
      "\n",
      "#df_hold_temp = pd.concat([df_hold_temp ,a],ignore_index=True)\n",
      "\n",
      "a.to_csv('/home/oliver/Dropbox/whitepine/super_groups_hold_per.csv')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 342
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print sales\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#['GIA', 'Round', 0.23, 0.29, 'Excellent'], \\\n",
      "#['GIA', 'Round', 0.30, 0.34, 'Excellent'], \\\n",
      "\n",
      "grouped = df_hold_per.groupby(['WeightMin', 'WeightMax', 'Cut'])\n",
      "\n",
      "#df_hold_temp = df_hold_per\n",
      "\n",
      "count = 0 \n",
      "a= {}\n",
      "\n",
      "for (wtmin, wtmax, cut), group in grouped:\n",
      "    if len(group() == 1 and len(wtmax) == 1:\n",
      "        count += 1\n",
      "        a.update({count: ['GIA','All Colors','All Clars', wtmin, wtmax, 'All-All',cut, np.sum(group['NumSales']), np.sum(group['TotalStonesInDB']),\\\n",
      "        np.mean(group['AvgTimeToSell']),'',np.mean(group['AveragePercentileActiveListings']),np.mean(group['AveragePercentileAllListings']),\\\n",
      "        np.sum(group['DailyAverageInventoryNumStone']),'',np.mean(group['AnnualInventoryTurn']),'']})\n",
      "\n",
      "a = pd.DataFrame(a).T\n",
      "a.columns = ['Lab', 'Color', 'Clarity', 'WeightMin', 'WeightMax', 'Group', 'Cut', 'NumSales', 'TotalStonesInDB', \\\n",
      "                    'AvgTimeToSell', 'MedianTimeToSell', 'AveragePercentileActiveListings', 'AveragePercentileAllListings', \\\n",
      "                    'DailyAverageInventoryNumStone', 'DailyAverageInventoryValue', 'AnnualInventoryTurn', 'PlotLoc']\n",
      "\n",
      "#df_hold_per = pd.concat([df_hold_per ,a],ignore_index=True)\n",
      "\n",
      "#df_hold_per.to_csv('/home/oliver/Dropbox/whitepine/test.csv')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "invalid syntax (<ipython-input-54-5a971198d2f6>, line 12)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-54-5a971198d2f6>\"\u001b[1;36m, line \u001b[1;32m12\u001b[0m\n\u001b[1;33m    if len(group() == 1 and len(wtmax) == 1:\u001b[0m\n\u001b[1;37m                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_hold_temp = a.copy()\n",
      "\n",
      "#df_hold_temp.to_csv('/home/oliver/Dropbox/whitepine/test.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 343
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "################### PLOTS HOLDING PERIODS ONLY\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.axes as plax\n",
      "from matplotlib.backends.backend_pdf import PdfPages\n",
      "from scipy.optimize import curve_fit\n",
      "import numpy as np\n",
      "\n",
      "nowstart = datetime.now()\n",
      "\n",
      "line_colors = ['b', 'y', 'r']\n",
      "\n",
      "ticks_pre = []\n",
      "for i in range(len(carat_bins)):\n",
      "    ticks_pre.append(carat_bins[i][2])\n",
      "ticks_pre.append(carat_bins[-1][3]+.01)\n",
      "ticks = []\n",
      "[ticks.append(x) for x in ticks_pre if x not in ticks]\n",
      "\n",
      "plot_linspace = np.linspace(min(ticks), max(ticks), 200)\n",
      "\n",
      "df_hold_temp['PlotLoc'] = (df_hold_temp['WeightMin']+df_hold_temp['WeightMax']+.01)/2\n",
      "\n",
      "grouped = df_hold_temp.groupby(by=['GroupColor','GroupClarity','Fluor'])\n",
      "\n",
      "\n",
      "\n",
      "plot_vars =  [\\\n",
      "            ['AvgTimeToSell','Average Holding Period Before Sale (days)', 0, 150, 2],\\\n",
      "            ['MedianTimeToSell','Median Holding Period Before Sale (days)', 0, 150, 2],\\\n",
      "            ['AveragePercentileActiveListings','Average Price Percentile upon Sale', 0, 100, 2],\\\n",
      "            ['AnnualInventoryTurn','Annual Inventory Turn', 0, 15, 2]\\\n",
      "             ]\n",
      "\n",
      "def bool_mask(x, y):\n",
      "    xvals = []\n",
      "    yvals = []\n",
      "    for g in range(len(y)):\n",
      "        if y.iloc[g] > 0:\n",
      "            xvals.append(x.iloc[g])\n",
      "            yvals.append(y.iloc[g])\n",
      "    return xvals, yvals\n",
      "\n",
      "for kk in range(len(plot_vars)):\n",
      "    var = plot_vars[kk][0]\n",
      "    tag = plot_vars[kk][1]\n",
      "    ymin = plot_vars[kk][2]\n",
      "    ymax = plot_vars[kk][3]\n",
      "    degree = plot_vars[kk][4]\n",
      "    \n",
      "     \n",
      "    for name, group in grouped:\n",
      "        rcParams['figure.figsize'] = 9, 5\n",
      "        plt.ylim(ymin,ymax)\n",
      "        plt.ylabel(tag, fontsize = 16)\n",
      "        plt.grid(alpha=.5)\n",
      "        subgrouped = group.groupby(['Cut', 'Fluor'])\n",
      "        fit_params = np.poly1d(np.polyfit(subgroup['PlotLoc'],subgroup[var], 2, full=False))\n",
      "        for (cut, fluor), subgroup in subgrouped:\n",
      "            #xvals, yvals = bool_mask(subgroup['PlotLoc'], subgroup[var])\n",
      "            pp = matplotlib.backends.backend_pdf.PdfPages('/home/oliver/Dropbox/whitepine/supergroups-%s-%s-%s.pdf' %(var,min(ticks),max(ticks)))\n",
      "            if fluor == 'None':\n",
      "                if cut == 'Excellent':\n",
      "                    c, ax1marker, ax2marker = 'b', '--bo', '--rD'\n",
      "                    plot(subgroup['PlotLoc'], subgroup[var], ax1marker, markersize = 10, alpha=.7)\n",
      "                    #xvals, yvals = bool_mask(subgroup['PlotLoc'], subgroup[var])\n",
      "                    #if len(xvals) > 4: \n",
      "                    #    fit_params = np.polyfit(xvals, yvals, degree, full=False)\n",
      "                    #    plot(plot_linspace,  np.polyval(fit_params, plot_linspace), color = c) \n",
      "                elif subname == 'Very Good' and fluor == 'None':\n",
      "                    c, ax1marker, ax2marker = 'r', '--ro', '--rD'\n",
      "                    plot(subgroup['PlotLoc'], subgroup[var], ax1marker, markersize = 10, alpha=.7)\n",
      "                    #xvals, yvals = bool_mask(subgroup['PlotLoc'], subgroup[var])\n",
      "                    #if len(xvals) > 4: \n",
      "                    #    fit_params = np.polyfit(xvals, yvals, degree, full=False)\n",
      "                    #    plot(plot_linspace,  np.polyval(fit_params, plot_linspace), color = c) \n",
      "                elif subname == 'Good'  and fluor == 'None':\n",
      "                    c, ax1marker, ax2marker = 'y', '--yo', '--yD'\n",
      "                    plot(subgroup['PlotLoc'], subgroup[var], ax1marker, markersize = 10, alpha=.7)\n",
      "                #elif subname == 'Strong and VST':\n",
      "                    #c, ax1marker, ax2marker = 'm', '--mo', '--mD'\n",
      "                    #plot(subgroup['PlotLoc'], subgroup[var], ax1marker, markersize = 10, alpha=.7)                \n",
      "                    #xvals, yvals = bool_mask(subgroup['PlotLoc'], subgroup[var])\n",
      "                    #if len(xvals) > 4: \n",
      "                    #    fit_params = np.polyfit(xvals, yvals, degree, full=False)\n",
      "                    #    plot(plot_linspace,  np.polyval(fit_params, plot_linspace), color = c) \n",
      "    \n",
      "            #print fit_params\n",
      "            \n",
      "                plt.title('GIA, No Fluor, Rounds - %s-%s Ct - %s - %s' %(min(ticks),max(ticks),name[0],name[1]),fontsize = 16)\n",
      "                plt.xlabel('Weight Bin', fontsize = 16) \n",
      "                #plt.xlim(.23,1)    \n",
      "                plt.xlim(min(ticks),max(ticks))\n",
      "                plt.xticks(ticks, rotation=45)\n",
      "                plt.annotate(\"EX Cut = Blue, VG = Red, GD = Yellow\", xy=(1, 0), xycoords='axes fraction', fontsize=12, xytext=(-5, 5), textcoords='offset points', ha='right', va='bottom')\n",
      "                #plt.savefig('/home/oliver/Dropbox/whitepine/%s-%s-%s-%sct-%sct.png' %(var,name[0],name[1],min(ticks),max(ticks)))\n",
      "                plt.savefig(pp, format='pdf') \n",
      "                plt.clf()\n",
      "            else:\n",
      "                pass\n",
      "    pp.close()  \n",
      "\n",
      "nowstop = datetime.now()\n",
      "\n",
      "print nowstop\n",
      "print nowstop - nowstart\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'module' object has no attribute 'now'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-1-f7e5686b6859>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mnowstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mline_colors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mAttributeError\u001b[0m: 'module' object has no attribute 'now'"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 305
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 305
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "#def get_last(grp):\n",
      "#    grp.sort(columns='event_day', inplace=True, ascending = False)\n",
      "#    return grp.iloc[0]\n",
      "#last_entry = filtered_reset.groupby(level=['Owner','CertNum']).apply(get_last)\n",
      "#print last_entry\n",
      "\n",
      "carat_bins = [\n",
      "              ['GIA', 'Round', 0.23, 0.29, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.30, 0.34, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.35, 0.39, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.40, 0.44, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.45, 0.49, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.50, 0.54, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.55, 0.59, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.60, 0.64, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.65, 0.69, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.70, 0.74, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.75, 0.79, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.80, 0.84, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.85, 0.89, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.90, 0.94, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.95, 0.99, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.00, 1.00, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.01, 1.01, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.02, 1.02, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.03, 1.03, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.04, 1.04, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.05, 1.09, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.10, 1.14, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.15, 1.19, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.20, 1.24, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.25, 1.29, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.30, 1.34, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.35, 1.39, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.40, 1.44, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.45, 1.49, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.50, 1.59, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.60, 1.74, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 1.75, 1.99, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 2.00, 2.24, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 2.25, 2.49, 'Excellent'], \\\n",
      "              ['GIA', 'Round', 0.23, 0.29, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.30, 0.34, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.35, 0.39, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.40, 0.44, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.45, 0.49, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.50, 0.54, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.55, 0.59, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.60, 0.64, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.65, 0.69, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.70, 0.74, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.75, 0.79, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.80, 0.84, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.85, 0.89, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.90, 0.94, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.95, 0.99, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.00, 1.00, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.01, 1.01, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.02, 1.02, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.03, 1.03, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.04, 1.04, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.05, 1.09, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.10, 1.14, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.15, 1.19, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.20, 1.24, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.25, 1.29, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.30, 1.34, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.35, 1.39, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.40, 1.44, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.45, 1.49, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.50, 1.59, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.60, 1.74, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 1.75, 1.99, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 2.00, 2.24, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 2.25, 2.49, 'Very Good'], \\\n",
      "              ['GIA', 'Round', 0.23, 0.29, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.30, 0.34, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.35, 0.39, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.40, 0.44, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.45, 0.49, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.50, 0.54, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.55, 0.59, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.60, 0.64, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.65, 0.69, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.70, 0.74, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.75, 0.79, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.80, 0.84, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.85, 0.89, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.90, 0.94, 'Good'], \\\n",
      "              ['GIA', 'Round', 0.95, 0.99, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.00, 1.00, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.01, 1.01, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.02, 1.02, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.03, 1.03, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.04, 1.04, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.05, 1.09, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.10, 1.14, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.15, 1.19, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.20, 1.24, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.25, 1.29, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.30, 1.34, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.35, 1.39, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.40, 1.44, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.45, 1.49, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.50, 1.59, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.60, 1.74, 'Good'], \\\n",
      "              ['GIA', 'Round', 1.75, 1.99, 'Good'], \\\n",
      "              ['GIA', 'Round', 2.00, 2.24, 'Good'], \\\n",
      "              ['GIA', 'Round', 2.25, 2.49, 'Good'], \\\n",
      "             ]\n",
      "\n",
      "\n",
      "groups = [\n",
      "            ['D','IF','D Color','IF Clarity'],\\\n",
      "            ['D','VVS1','D Color','VVS1 Clarity'],\\\n",
      "            ['D','VVS2','D Color','VVS2 Clarity'],\\\n",
      "            ['D','VS1','D Color','VS1 Clarity'],\\\n",
      "            ['D','VS2','D Color','VS2 Clarity'],\\\n",
      "            ['D','SI1','D Color','SI1 Clarity'],\\\n",
      "            ['D','SI2','D Color','SI2 Clarity'],\\\n",
      "            ['E','IF','E Color','IF Clarity'],\\\n",
      "            ['E','VVS1','E Color','VVS1 Clarity'],\\\n",
      "            ['E','VVS2','E Color','VVS2 Clarity'],\\\n",
      "            ['E','VS1','E Color','VS1 Clarity'],\\\n",
      "            ['E','VS2','E Color','VS2 Clarity'],\\\n",
      "            ['E','SI1','E Color','SI1 Clarity'],\\\n",
      "            ['E','SI2','E Color','SI2 Clarity'],\\\n",
      "            ['F','IF','F Color','IF Clarity'],\\\n",
      "            ['F','VVS1','F Color','VVS1 Clarity'],\\\n",
      "            ['F','VVS2','F Color','VVS2 Clarity'],\\\n",
      "            ['F','VS1','F Color','VS1 Clarity'],\\\n",
      "            ['F','VS2','F Color','VS2 Clarity'],\\\n",
      "            ['F','SI1','F Color','SI1 Clarity'],\\\n",
      "            ['F','SI2','F Color','SI2 Clarity'],\\\n",
      "            ['G','IF','G Color','IF Clarity'],\\\n",
      "            ['G','VVS1','G Color','VVS1 Clarity'],\\\n",
      "            ['G','VVS2','G Color','VVS2 Clarity'],\\\n",
      "            ['G','VS1','G Color','VS1 Clarity'],\\\n",
      "            ['G','VS2','G Color','VS2 Clarity'],\\\n",
      "            ['G','SI1','G Color','SI1 Clarity'],\\\n",
      "            ['G','SI2','G Color','SI2 Clarity'],\\\n",
      "            ['H','IF','H Color','IF Clarity'],\\\n",
      "            ['H','VVS1','H Color','VVS1 Clarity'],\\\n",
      "            ['H','VVS2','H Color','VVS2 Clarity'],\\\n",
      "            ['H','VS1','H Color','VS1 Clarity'],\\\n",
      "            ['H','VS2','H Color','VS2 Clarity'],\\\n",
      "            ['H','SI1','H Color','SI1 Clarity'],\\\n",
      "            ['H','SI2','H Color','SI2 Clarity'],\\\n",
      "            ['I','IF','I Color','IF Clarity'],\\\n",
      "            ['I','VVS1','I Color','VVS1 Clarity'],\\\n",
      "            ['I','VVS2','I Color','VVS2 Clarity'],\\\n",
      "            ['I','VS1','I Color','VS1 Clarity'],\\\n",
      "            ['I','VS2','I Color','VS2 Clarity'],\\\n",
      "            ['I','SI1','I Color','SI1 Clarity'],\\\n",
      "            ['I','SI2','I Color','SI2 Clarity'],\\\n",
      "            ['J','IF','J Color','IF Clarity'],\\\n",
      "            ['J','VVS1','J Color','VVS1 Clarity'],\\\n",
      "            ['J','VVS2','J Color','VVS2 Clarity'],\\\n",
      "            ['J','VS1','J Color','VS1 Clarity'],\\\n",
      "            ['J','VS2','J Color','VS2 Clarity'],\\\n",
      "            ['J','SI1','J Color','SI1 Clarity'],\\\n",
      "            ['J','SI2','J Color','SI2 Clarity']\\\n",
      "        ]\n",
      "\n",
      "\n",
      "#from datetime import datetime,date,timedelta\n",
      "\n",
      "#start_date = datetime(2013, 3, 3)\n",
      "#sell_lag = 32\n",
      "\n",
      "#for d in range((datetime.now() - datetime(2013, 3, 3) - timedelta(days=sell_lag)).days):\n",
      "#    date = start_date + timedelta(days = d)\n",
      "#    print date\n",
      "\n",
      "#adds = filtered_df.reset_index(level=['event_type', 'event_day']).groupby(level=['Owner','CertNum']).apply(get_first)\n",
      "\n",
      "#adds.to_csv('/home/oliver/Dropbox/whitepine/adds.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 338
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#test = all_df.xs((rl.ADD,'2013-09-10'), level=['event_type','event_day']).groupby(level=['Owner','CertNum']).apply(rl.get_latest)\n",
      "#\n",
      "#prev_removals = pd.concat([removals,adds], axis=1, join='inner', join_axes=[removals.index])\n",
      "#\n",
      "#latest.head(20).to_csv('/home/oliver/Dropbox/whitepine/price_curve_params.csv')\n",
      "\n",
      "#sale_dates = pd.date_range(start='2013-03-03',end=(datetime.now()-timedelta(days=30)),freq='1D')\n",
      "#latest = latest.reset_index(level=['event_type','event_day'])\n",
      "#adds = adds.reset_index(level=['event_type','event_day'])\n",
      "#print prev_removals"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "nowstart = datetime.now()\n",
      "\n",
      "\n",
      "grouped = filtered_df.reset_index(level=['event_type', 'event_day']).groupby(level=['Owner','CertNum'])\n",
      "\n",
      "out = []\n",
      "\n",
      "for name, group in grouped:\n",
      "    for i in range(len(group)):\n",
      "        group.sort(columns='event_day',ascending=True)\n",
      "        if group['event_type'].iloc[i] == 3:\n",
      "            if (group['event_day'].iloc[i] < group['event_day'].iloc[i-1]):\n",
      "                print group\n",
      "            else:\n",
      "                pass\n",
      "            out.append((group['event_day'].iloc[i]-group['event_day'].iloc[i-1]).days)\n",
      "        else:\n",
      "            pass\n",
      "        \n",
      "nowstop = datetime.now()\n",
      "\n",
      "print nowstop - nowstart\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 319,
       "text": [
        "\"\\nnowstart = datetime.now()\\n\\n\\ngrouped = filtered_df.reset_index(level=['event_type', 'event_day']).groupby(level=['Owner','CertNum'])\\n\\nout = []\\n\\nfor name, group in grouped:\\n    for i in range(len(group)):\\n        group.sort(columns='event_day',ascending=True)\\n        if group['event_type'].iloc[i] == 3:\\n            if (group['event_day'].iloc[i] < group['event_day'].iloc[i-1]):\\n                print group\\n            else:\\n                pass\\n            out.append((group['event_day'].iloc[i]-group['event_day'].iloc[i-1]).days)\\n        else:\\n            pass\\n        \\nnowstop = datetime.now()\\n\\nprint nowstop - nowstart\\n\""
       ]
      }
     ],
     "prompt_number": 319
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "temp = all_df.reset_index()\n",
      "temp['CertNum'] = temp['CertNum'].str.replace('*', '')\n",
      "temp = temp.set_index(['CertNum'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print max(temp['event_day'])\n",
      "\n",
      "#temp2 = temp[(temp['Shape'] == 'Emerald') & (temp['Carat'] == 4.04)]\n",
      "\n",
      "#print len(temp2)\n",
      "\n",
      "\n",
      "\n",
      "#print temp['event_day'].ix['1163129301']\n",
      "#print temp['event_type'].ix['1163129301']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-01-31 00:00:00\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print temp2['Owner'] \n",
      "print temp2['event_day']\n",
      "print temp2['event_type']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CertNum\n",
        "2507100924      ADAMCO\n",
        "1106175027     DYNASTY\n",
        "2135138040       RIVER\n",
        "3325456432         mid\n",
        "2135138040       RIVER\n",
        "2135138040       RIVER\n",
        "15320165       IDSTRAD\n",
        "17465211      SS-STERN\n",
        "17465211      SS-STERN\n",
        "2135138040       RIVER\n",
        "2135138040       RIVER\n",
        "2135138040       RIVER\n",
        "2135138040       RIVER\n",
        "2135138040       RIVER\n",
        "3325456432         MID\n",
        "3325456432         mid\n",
        "2135138040       RIVER\n",
        "2135138040       RIVER\n",
        "2135138040       RIVER\n",
        "2141515108     BELGIUM\n",
        "2141515108     BELGIUM\n",
        "Name: Owner, dtype: object\n",
        "CertNum\n",
        "2507100924   2013-10-02 00:00:00\n",
        "1106175027   2013-10-02 00:00:00\n",
        "2135138040   2013-10-02 00:00:00\n",
        "3325456432   2013-10-02 00:00:00\n",
        "2135138040   2013-10-03 00:00:00\n",
        "2135138040   2013-10-09 00:00:00\n",
        "15320165     2013-11-06 00:00:00\n",
        "17465211     2013-11-12 00:00:00\n",
        "17465211     2013-11-18 00:00:00\n",
        "2135138040   2013-11-22 00:00:00\n",
        "2135138040   2013-12-04 00:00:00\n",
        "2135138040   2013-12-10 00:00:00\n",
        "2135138040   2013-12-19 00:00:00\n",
        "2135138040   2013-12-23 00:00:00\n",
        "3325456432   2013-12-26 00:00:00\n",
        "3325456432   2013-12-26 00:00:00\n",
        "2135138040   2014-01-01 00:00:00\n",
        "2135138040   2014-01-08 00:00:00\n",
        "2135138040   2014-01-16 00:00:00\n",
        "2141515108   2014-01-16 00:00:00\n",
        "2141515108   2014-01-30 00:00:00\n",
        "Name: event_day, dtype: datetime64[ns]\n",
        "CertNum\n",
        "2507100924    1\n",
        "1106175027    1\n",
        "2135138040    1\n",
        "3325456432    1\n",
        "2135138040    2\n",
        "2135138040    3\n",
        "15320165      1\n",
        "17465211      1\n",
        "17465211      2\n",
        "2135138040    2\n",
        "2135138040    3\n",
        "2135138040    2\n",
        "2135138040    3\n",
        "2135138040    2\n",
        "3325456432    1\n",
        "3325456432    2\n",
        "2135138040    3\n",
        "2135138040    2\n",
        "2135138040    3\n",
        "2141515108    4\n",
        "2141515108    2\n",
        "Name: event_type, dtype: int64\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}