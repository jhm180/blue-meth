{
 "metadata": {
  "name": "",
  "signature": "sha256:9d2723413943e770629306fb272979486bfefe4ebb911fa7bc8df1700ca8f312"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load /home/oliver/Dropbox/whitepine/lib/cron.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this file gets run nightly after the rapnet_import script\n",
      "# any printed output of this script will be sent to Ollie's email, so try not to use print much\n",
      "\n",
      "###################\n",
      "##### LOAD ACTIVE LISTINGS FROM SQL DATABASE & DEFINE SOME GLOBAL VARIABLES\n",
      "###################\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import pandas.io.sql as psql\n",
      "import matplotlib\n",
      "# Force matplotlib to not use any Xwindows backend.\n",
      "matplotlib.use('Agg')\n",
      "import matplotlib.pyplot as plt\n",
      "import pylab as pl\n",
      "from scipy.optimize import curve_fit\n",
      "from matplotlib.backends.backend_pdf import PdfPages\n",
      "import math\n",
      "import sys\n",
      "sys.path.insert(0, '/home/oliver/src/blue-meth/ipynb')\n",
      "import rapnet_loader as rl\n",
      "\n",
      "all_df, current_df, file_date = rl.load_cache()\n",
      "\n",
      "df = current_df[current_df['Cert'] == 'GIA']\n",
      "\n",
      "df['TotalPrice'] = df['Price'] * df['Carat'] #l.Price represents price per carat\n",
      "\n",
      "all_countries = ['USA', 'Canada', 'United Kingdom', 'Hong Kong', 'India', 'Belgium', 'Israel', 'Sri Lanka', 'Germany', \\\n",
      "            'Thailand', 'UAE', 'China', 'South Africa', 'New Zealand', 'Australia', 'France', 'Singapore', 'Italy', 'Uzbekistan', 'Uganda'] \n",
      "usa_only = ['USA']\n",
      "\n",
      "colors = ['D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M']\n",
      "clars = ['IF', 'VVS1', 'VVS2', 'VS1', 'VS2', 'SI1', 'SI2', 'SI3', 'I1', 'I2', 'I3']\n",
      "colors_plot = ['D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M']\n",
      "clars_plot = ['IF', 'VVS1', 'VVS2', 'VS1', 'VS2', 'SI1', 'SI2', 'I1']\n",
      "coffee_pot_colors = ['F', 'G', 'H', 'I', 'J']\n",
      "coffee_pot_clars = ['VS1', 'VS2', 'SI1', 'SI2']\n",
      "\n",
      "fluor_faint = ['Faint ', 'Faint Blue', 'Slight', 'Very Slight ', 'Slight Blue', 'Very Slight Blue'] #Do NOT delete spaces at end of items in this list\n",
      "fluor_none = ['None '] #Do NOT delete spaces at end of items in this list\n",
      "fluor_medium = ['Medium ', 'Medium Blue', 'Medium Yellow'] #Do NOT delete spaces at end of items in this list\n",
      "fluor_strong = ['Strong ', 'Strong Blue', 'Very Strong Blue', 'Very Strong '] #Do NOT delete spaces at end of items in this list\n",
      "fluors = ['Faint ', 'Faint Blue', 'Slight', 'Very Slight ', 'Slight Blue', 'Very Slight Blue', 'None ']\n",
      "fluor_none_and_faint = ['None ', 'Faint ', 'Faint Blue', 'Slight', 'Very Slight ', 'Slight Blue', 'Very Slight Blue']\n",
      "\n",
      "clar_line_colors = {'IF' : 'r' , 'VVS1' : 'g', 'VVS2' : 'b', 'VS1' :'c', 'VS2' : 'm', 'SI1': 'y', 'SI2': 'k', 'I1': 'r', 'I2' : 'g'}\n",
      "color_line_colors = {'D' : 'r' , 'E' : 'g', 'F' : 'b', 'G' :'c', 'H' : 'm', 'I' : 'y', 'J': 'k', 'K': 'r', 'L' : 'g', 'M' : 'b'}\n",
      "\n",
      "\n",
      "###################\n",
      "##### EMBIGGEN DF - ADD NEW COLUMN WITH A KEY, LOAD RAP PRICE LIST, THEN ADD NEW COLUMN AND POUPLATE COLUMN WITH RAP PRICE USING KEY \n",
      "###################\n",
      "\n",
      "df['RapPriceKey'] = 0\n",
      "df['RapShapeKey'] = 0\n",
      "df['ShapeDiscKey'] = 0\n",
      "#Create a new column that will be used as a key when looking up listed rap price\n",
      "def rap_price_key(wt):\n",
      "    if wt >= 0.01 and wt <= 0.03:\n",
      "        return 0.01\n",
      "    elif wt >= 0.04 and wt <= 0.07:\n",
      "        return 0.07\n",
      "    elif wt >= 0.08 and wt <= 0.14:\n",
      "        return 0.08\n",
      "    elif wt >= 0.15 and wt <= 0.17:\n",
      "        return 0.15\n",
      "    elif wt >= 0.18 and wt <= 0.22:\n",
      "        return 0.18\n",
      "    elif wt >= 0.23 and wt <= 0.29:\n",
      "        return 0.23    \n",
      "    elif wt >= 0.30 and wt <= 0.39:\n",
      "        return 0.30\n",
      "    elif wt >= 0.40 and wt <= 0.49:\n",
      "        return 0.40\n",
      "    elif wt >= 0.50 and wt <= 0.69:\n",
      "        return 0.50\n",
      "    elif 0.70 <= wt and wt <= 0.89:\n",
      "        return 0.70\n",
      "    elif 0.90 <= wt and wt <= 0.99:\n",
      "        return 0.90\n",
      "    elif 1.00 <= wt and wt <= 1.49:\n",
      "        return 1.00\n",
      "    elif 1.50 <= wt and wt <= 1.99:\n",
      "        return 1.50\n",
      "    elif 2.00 <= wt and wt <= 2.99:\n",
      "        return 2.00\n",
      "    elif 3.00 <= wt and wt <= 3.99:\n",
      "        return 3.00        \n",
      "    elif 4.00 <= wt and wt <= 4.99:\n",
      "        return 4.00        \n",
      "    elif 5.00 <= wt and wt <= 9.99:\n",
      "        return 5.00\n",
      "    elif 10.00 <= wt:\n",
      "        return 10.00\n",
      "    else:\n",
      "        return -999999.0\n",
      "\n",
      "def shape_disc_key(wt):\n",
      "    if wt >= 0.01 and wt <= 0.03:\n",
      "        return 0.01\n",
      "    elif wt >= 0.04 and wt <= 0.07:\n",
      "        return 0.04\n",
      "    elif wt >= 0.08 and wt <= 0.14:\n",
      "        return 0.08\n",
      "    elif wt >= 0.15 and wt <= 0.17:\n",
      "        return 0.15\n",
      "    elif wt >= 0.18 and wt <= 0.22:\n",
      "        return 0.18\n",
      "    elif wt >= 0.23 and wt <= 0.29:\n",
      "        return 0.23    \n",
      "    elif wt >= 0.30 and wt <= 0.39:\n",
      "        return 0.30\n",
      "    elif wt >= 0.40 and wt <= 0.49:\n",
      "        return 0.40\n",
      "    elif wt >= 0.50 and wt <= 0.59:\n",
      "        return 0.50\n",
      "    elif wt >= 0.60 and wt <= 0.69:\n",
      "        return 0.60\n",
      "    elif 0.70 <= wt and wt <= 0.79:\n",
      "        return 0.70\n",
      "    elif 0.80 <= wt and wt <= 0.89:\n",
      "        return 0.80\n",
      "    elif 0.90 <= wt and wt <= 0.99:\n",
      "        return 0.90\n",
      "    elif 1.00 <= wt and wt <= 1.24:\n",
      "        return 1.00\n",
      "    elif 1.25 <= wt and wt <= 1.49:\n",
      "        return 1.25\n",
      "    elif 1.50 <= wt and wt <= 1.74:\n",
      "        return 1.50\n",
      "    elif 1.75 <= wt and wt <= 1.99:\n",
      "        return 1.75\n",
      "    elif 2.00 <= wt and wt <= 2.49:\n",
      "        return 2.00\n",
      "    elif 2.50 <= wt and wt <= 2.99:\n",
      "        return 2.50\n",
      "    elif 3.00 <= wt and wt <= 3.99:\n",
      "        return 3.00        \n",
      "    elif 4.00 <= wt and wt <= 4.99:\n",
      "        return 4.00        \n",
      "    elif 5.00 <= wt and wt <= 9.99:\n",
      "        return 5.00\n",
      "    elif 10.00 <= wt:\n",
      "        return 10.00\n",
      "    else:\n",
      "        return -999999.0\n",
      "\n",
      "def rap_shape_key(shape):\n",
      "    if shape == 'Round':\n",
      "        return 'BR'\n",
      "    else:\n",
      "        return 'PS'\n",
      "    \n",
      "def discount_shape_key(shape):\n",
      "    if shape == 'Round':\n",
      "        return 'RB'\n",
      "    elif shape == 'Princess':\n",
      "        return 'PR'\n",
      "    else:\n",
      "        return 'NA'\n",
      "\n",
      "df['RapPriceKey'] = df['Carat'].apply(rap_price_key)\n",
      "\n",
      "df['RapShapeKey'] = df['Shape'].apply(rap_shape_key)    \n",
      "\n",
      "df['ShapeDiscKey'] = df['Carat'].apply(shape_disc_key)    \n",
      "\n",
      "df['DiscountShapeKey'] = df['Shape'].apply(discount_shape_key)    \n",
      "    \n",
      "df['RapPricePerCarat'] = 0\n",
      "\n",
      "#import rappaport price list\n",
      "df_rap_price_list =  pd.read_csv('/home/oliver/Dropbox/whitepine/Rapnet Price List.csv', sep=',', header=0,\\\n",
      "names = ['Shape','Clarity','Color','MinCarat','MaxCarat','PricePerCar','Date'], index_col=[0,2,1,3])\n",
      "\n",
      "groups = []\n",
      "# split into groups, where each row in a subgroup has the same Color, Clarity, and RapPriceKey\n",
      "for (shape, color, clarity, rapPriceKey), group in df.groupby(['RapShapeKey','Color','Clarity','RapPriceKey']):\n",
      "    # using boolean indexing to select the matching price per carat from the df_rap_price_list\n",
      "    # df_rap_price_list.index is a multiindex; map() is a way of applying a function to each item in a sequence \n",
      "    # (in this case, each multiindex object in the df_rap_price_list frame)\n",
      "    # lambda idx: ... is a shorthand way of defining a function; could also do:\n",
      "    ppc = df_rap_price_list[df_rap_price_list.index.map(lambda idx: idx[0] == shape and idx[1] == color and idx[2] == clarity and idx[3] == rapPriceKey)]\n",
      "    if len(ppc):\n",
      "        px = ppc['PricePerCar'].iloc[0]\n",
      "        group['RapPricePerCarat'] = px\n",
      "    else:\n",
      "        group['RapPricePerCarat'] = -999999\n",
      "    groups.append(group) # add each subgroup to a python list\n",
      "\n",
      "# re-merge all the subgroups back into a single dataframe\n",
      "# generally a good idea to not overwrite the original df object here, so you can play with intermediate results without losing\n",
      "# the initial df, but in this case we already know it's what we want\n",
      "df = pd.concat(groups)\n",
      "\n",
      "df['ExactPctRap'] = (df['Price']-df['RapPricePerCarat'])/df['RapPricePerCarat']\n",
      "\n",
      "###################\n",
      "##### EMBIGGEN DF - ADD DATA FOR PRINCESS CUT PRICE CALCULATION\n",
      "###################\n",
      "\n",
      "def ratio(measurement):\n",
      "    if pd.isnull(measurement):\n",
      "        return -999999\n",
      "    else:\n",
      "        measurementx = (measurement.replace('-','x'))\n",
      "        dims = (measurementx.split('x'))\n",
      "        side1 = float(dims[0])\n",
      "        side2 = float(dims[1])       \n",
      "        if side1 == 0 or side2 == 0:\n",
      "            return -999999\n",
      "        else: \n",
      "            return max(side1/side2, side2/side1)\n",
      "\n",
      "    \n",
      "df['Ratio'] = df['Meas'].apply(ratio)\n",
      "\n",
      "def depth_diff(depth):\n",
      "    if depth >= 72.0:\n",
      "        return depth - 72.0\n",
      "    elif depth < 64:\n",
      "        return 64 - depth\n",
      "    else:\n",
      "        return 0\n",
      "    \n",
      "df['DepthDiff'] = df['Depth'].apply(depth_diff)\n",
      "\n",
      "def ratio_diff(ratio):\n",
      "    return math.fabs(ratio - 1)\n",
      "    \n",
      "df['RatioDiff'] = df['Ratio'].apply(ratio_diff)\n",
      "\n",
      "def grade_rank(grade):\n",
      "    if grade == 'Excellent':\n",
      "        return 0\n",
      "    elif grade == 'Very Good':\n",
      "        return 1\n",
      "    elif grade == 'Good':\n",
      "        return 2\n",
      "    elif grade == 'Fair':\n",
      "        return 3\n",
      "    elif grade == 'Poor':\n",
      "        return 4\n",
      "    else:\n",
      "        return -999999\n",
      "\n",
      "df['SymRank'] = df['Sym'].apply(grade_rank)\n",
      "\n",
      "###################\n",
      "##### EMBIGGEN DF - CALCULATE A 'Cut Grade' FOR PRINCESS SHAPES\n",
      "###################\n",
      "\n",
      "def princess_cut_grade(dataframe):\n",
      "    cutgrade = dataframe['Cut Grade']\n",
      "    shape = dataframe['Shape']\n",
      "    table = dataframe['Table']\n",
      "    depth = dataframe['Depth']\n",
      "    sym = dataframe['Sym']\n",
      "    polish = dataframe['Polish']\n",
      "    ratio = dataframe['Ratio']\n",
      "    if shape != 'Princess':\n",
      "        return cutgrade\n",
      "    elif 64 <= depth <=72 and ratio <= 1.05 and sym in ['Excellent','Very Good', 'Good'] and polish in ['Excellent','Very Good', 'Good']:\n",
      "        return 'Excellent'\n",
      "    elif 62 <= depth <=75 and ratio <= 1.1 and sym in ['Excellent','Very Good', 'Good', 'Fair'] and polish in ['Excellent','Very Good', 'Good', 'Fair']:\n",
      "        return 'Very Good'\n",
      "    elif 56 <= depth <=82 and ratio <= 1.25 and sym in ['Excellent','Very Good', 'Good'] and polish in ['Excellent','Very Good', 'Good', 'Fair']:\n",
      "        return 'Good'\n",
      "    #elif 64 <= depth <=72 and 65 <=table <= 74 and ratio <= 1.05 and sym in ['Excellent','Very Good'] and polish in ['Excellent','Very Good']:\n",
      "    #    return 'Excellent'\n",
      "    #elif 62 <= depth <=75 and 59 <=table <= 78 and ratio <= 1.25 and sym in ['Excellent','Very Good', 'Good'] and polish in ['Excellent','Very Good', 'Good']:\n",
      "    #    return 'Very Good'\n",
      "    #elif 56 <= depth <=82 and 56 <=table <= 85 and ratio <= 1.25 and sym in ['Excellent','Very Good', 'Good'] and polish in ['Excellent','Very Good', 'Good']:\n",
      "    #    return 'Good'\n",
      "    else:\n",
      "        return 'Fair'\n",
      "    \n",
      "df['Cut Grade'] = df.apply(princess_cut_grade, axis=1)\n",
      "\n",
      "###################\n",
      "##### FITS POLYNOMIALS TO TOTAL PRICE DATA (X = CARAT WEIGHT, Y = TOTAL PRICE) AND EXPORTS THE FIT PARAMETERS TO EXCEL \n",
      "###################\n",
      "\n",
      "r01 = np.linspace(0.00, 0.03, 50)\n",
      "r04 = np.linspace(0.04, 0.07, 50)\n",
      "r08 = np.linspace(0.08, 0.14, 50)\n",
      "r15 = np.linspace(0.15, 0.17, 50)\n",
      "r18 = np.linspace(0.18, 0.22, 50)\n",
      "r23 = np.linspace(0.23, 0.29, 50)\n",
      "r30 = np.linspace(0.30, 0.39, 50)\n",
      "r40 = np.linspace(0.40, 0.49, 50)\n",
      "r50 = np.linspace(0.50, 0.59, 50)\n",
      "r60 = np.linspace(0.60, 0.69, 50)\n",
      "r70 = np.linspace(0.70, 0.79, 50)\n",
      "r80 = np.linspace(0.80, 0.89, 50)\n",
      "r90 = np.linspace(0.90, 0.99, 50)\n",
      "rc1 = np.linspace(1.00, 1.49, 50)\n",
      "rcr = np.linspace(1.50, 1.99, 50)\n",
      "rc2 = np.linspace(2.00, 2.99, 50)\n",
      "rc3 = np.linspace(3.00, 3.99, 50)\n",
      "rc4 = np.linspace(4.00, 4.99, 50)\n",
      "rc5 = np.linspace(5.00, 9.99, 50)\n",
      "rct = np.linspace(10.00, 29.99, 50)\n",
      "\n",
      "rc_bins = [r01, r04, r08, r15, r18, r23, r30, r40, r50, r60, r70, r80, r90, rc1, rcr, rc2, rc3, rc4, rc5, rct]\n",
      "\n",
      "carat_bins = [ \\\n",
      "              [0.00, 0.04, 0.01, 0.03, 0.01, 1, 'r01', r01],\\\n",
      "              [0.04, 0.08, 0.04, 0.07, 0.04, 1, 'r04', r04],\\\n",
      "              [0.08, 0.15, 0.08, 0.14, 0.08, 1, 'r08', r08],\\\n",
      "              [0.15, 0.18, 0.15, 0.17, 0.15, 1, 'r15', r15],\\\n",
      "              [0.18, 0.23, 0.18, 0.22, 0.18, 1, 'r18', r18],\\\n",
      "              [0.23, 0.30, 0.23, 0.29, 0.23, 1, 'r23', r23],\\\n",
      "              [0.30, 0.40, 0.30, 0.39, 0.30, 1, 'r30', r30],\\\n",
      "              [0.40, 0.50, 0.40, 0.49, 0.40, 1, 'r40', r40],\\\n",
      "              [0.50, 0.60, 0.50, 0.59, 0.50, 1, 'r50', r50],\\\n",
      "              [0.60, 0.70, 0.60, 0.69, 0.50, 1, 'r60', r60],\\\n",
      "              [0.70, 0.80, 0.70, 0.79, 0.70, 1, 'r70', r70],\\\n",
      "              [0.80, 0.90, 0.80, 0.89, 0.70, 1, 'r80', r80],\\\n",
      "              [0.90, 1.00, 0.90, 0.99, 0.90, 1, 'r90', r90],\\\n",
      "              [1.00, 1.50, 1.00, 1.49, 1.00, 2, 'rc1', rc1],\\\n",
      "              [1.50, 2.00, 1.50, 1.99, 1.50, 2, 'rcr', rcr],\\\n",
      "              [2.00, 3.00, 2.00, 2.99, 2.00, 2, 'rc2', rc2],\\\n",
      "              [3.00, 4.00, 3.00, 3.99, 3.00, 2, 'rc3', rc3],\\\n",
      "              [4.00, 5.00, 4.00, 4.99, 4.00, 2, 'rc4', rc4],\\\n",
      "              [5.00, 10.00, 5.00, 9.99, 5.00, 2, 'rc5', rc5],\\\n",
      "              [10.00, 30.00, 10.00, 29.99, 10.00, 2, 'rct', rct]\\\n",
      "              ]\n",
      "\n",
      "shapes = [ \\\n",
      "            ['Princess', ['Excellent'],  ['Excellent', 'Very Good', 'Good'],  ['Excellent', 'Very Good', 'Good'], 'PS', usa_only, 'PR'], \\\n",
      "            ['Round', ['Excellent'],  ['Excellent'],  ['Excellent'], 'BR', all_countries, 'RB'] \\\n",
      "            ]\n",
      "\n",
      "line_colors = ['r', 'g', 'b', 'c', 'm', 'y', 'k', 'r', 'g', 'b', 'c', 'm', 'y', 'k', 'r', 'g', 'b', 'c', 'm', 'y']\n",
      "\n",
      "output = {\\\n",
      "            'Shape' : [], \\\n",
      "            'Color' : [], \\\n",
      "            'Clarity' : [], \\\n",
      "            'CurveKey' : [], \\\n",
      "            'CurveRangeMin' : [], \\\n",
      "            'CurveRangeMax' : [], \\\n",
      "            'PolyDegree' : [], \\\n",
      "            'Px2' : [], \\\n",
      "            'Px1' : [], \\\n",
      "            'Px0' : [], \\\n",
      "            'StdDev' : [], \\\n",
      "            'NumStones': [], \\\n",
      "            'ResidSlope': [], \\\n",
      "            'ResidCept': [] \\\n",
      "            }\n",
      "\n",
      "def price_curve_genarator_all():\n",
      "    #initiate pdf doc to save figures into\n",
      "    ##pp = PdfPages('/home/oliver/Dropbox/whitepine/price_curves.pdf')\n",
      "    \n",
      "    for z in range(len(shapes)):\n",
      "        shape = shapes[z][0]\n",
      "        cutgrade = shapes[z][1]\n",
      "        polish = shapes[z][2]\n",
      "        sym = shapes[z][3]\n",
      "        rap_shape_key = shapes[z][4]\n",
      "        location = shapes[z][5]\n",
      "        shape_key = shapes[z][6]\n",
      "        \n",
      "        #loop through colors and clarties\n",
      "        for k in colors_plot:\n",
      "            color = k\n",
      "            for l in clars_plot:\n",
      "                clar = l\n",
      "                \n",
      "                #create a smaller dataframe with a single combination of color and clarity \n",
      "                df_temp = df[ \\\n",
      "                            (df['Shape'] == shape) \\\n",
      "                            & (df['Carat'] >= 0.23) \\\n",
      "                            & (df['Carat'] < 3.50) \\\n",
      "                            & (df['Color'] == color) \\\n",
      "                            & (df['Clarity'] == clar) \\\n",
      "                            & (df['Country'].isin(location)) \\\n",
      "                            & (df['Cut Grade'].isin(cutgrade)) \\\n",
      "                            & (df['Polish'].isin(polish)) \\\n",
      "                            & (df['Sym'].isin(sym)) \\\n",
      "                            & (df['Fluor'].isin(fluor_none)) \\\n",
      "                            & (df['Cert'] == 'GIA') \\\n",
      "                            & (df['Price'] > 0) \\\n",
      "                            ]\n",
      "                \n",
      "                #loop through carat bins that have a bunch of preset parameters\n",
      "                for i in range(len(carat_bins)):\n",
      "                    fxn_min = carat_bins[i][0]\n",
      "                    fxn_max = carat_bins[i][1]\n",
      "                    plot_min = carat_bins[i][2]\n",
      "                    plot_max = carat_bins[i][3]\n",
      "                    rap_price_key = carat_bins[i][4]\n",
      "                    degree = carat_bins[i][5]\n",
      "                    curve_key = carat_bins[i][6]\n",
      "                    plot_linspace = carat_bins[i][7]\n",
      "                    fxn_plus_min = carat_bins[i][1]\n",
      "                    fxn_plus_max = carat_bins[i][1]+.5\n",
      "                    \n",
      "                    \n",
      "                    #break up color/clarity dataframe into smaller chunks based on carat weight\n",
      "                    df_fxn_range_pre = df_temp[(df_temp['Carat'] >= fxn_min) & (df_temp['Carat'] < fxn_max)]\n",
      "                    \n",
      "                    #get cheapest two stones that weigh more than the current weight bin, append them to the smaller color/clarity dataframe\n",
      "                    df_fxn_range_plus_pre = df_temp[(df_temp['Carat'] >= fxn_plus_min) & (df_temp['Carat'] < fxn_plus_max)]\n",
      "                    df_fxn_range_plus = df_fxn_range_plus_pre.sort(['TotalPrice'],ascending=True)\n",
      "                    if degree == 2:\n",
      "                        df_fxn_range = pd.concat([df_fxn_range_pre, df_fxn_range_plus[:2]])\n",
      "                    elif degree == 1: \n",
      "                        df_fxn_range = pd.concat([df_fxn_range_pre, df_fxn_range_plus[:1]])\n",
      "                    else:\n",
      "                        pass\n",
      "                    #df_fxn_range = pd.concat([df_fxn_range_pre, df_fxn_range_plus[:2]])\n",
      "                    df_plot_range = df_temp[(df_temp['Carat'] >= plot_min) & (df_temp['Carat'] < plot_max)]\n",
      "                    \n",
      "                    \n",
      "                    #exception handling for certain criteria... exclude small and large stones, exclude lesser clarities, exclude empty categories\n",
      "                    #exclude categories with only a few stones (minimum stone limits set here are arbitrary)\n",
      "                    #create dummy entries in the output dictionary for the exlcluded categories\n",
      "                    if ( \\\n",
      "                        plot_min < .3 \\\n",
      "                        or (plot_min < .5 and shape == 'Princess')\n",
      "                        or plot_max >= 3.00 \\\n",
      "                        or clar == 'SI3' \\\n",
      "                        or clar == 'I2' \\\n",
      "                        or clar == 'I3' \\\n",
      "                        or len(df_temp) == 0 \\\n",
      "                        or (len(df_fxn_range_pre) <= 4 and degree ==1) \\\n",
      "                        or (len(df_fxn_range) <= 9 and degree ==2) \\\n",
      "                        or len(df_fxn_range) == 0\n",
      "                        or len(df_plot_range) == 0\n",
      "                        ):\n",
      "                        \n",
      "                        output['Shape'].append(shape_key)\n",
      "                        output['Color'].append(color)\n",
      "                        output['Clarity'].append(clar)\n",
      "                        output['CurveKey'].append(curve_key)\n",
      "                        output['CurveRangeMin'].append(plot_min)\n",
      "                        output['CurveRangeMax'].append(plot_max)\n",
      "                        output['PolyDegree'].append(-999999)\n",
      "                        output['Px2'].append(-999999)\n",
      "                        output['Px1'].append(-999999)\n",
      "                        output['Px0'].append(-999999)\n",
      "                        output['StdDev'].append(-999999)\n",
      "                        output['NumStones'].append(len(df_plot_range))\n",
      "                        output['ResidSlope'].append(-999999)\n",
      "                        output['ResidCept'].append(-999999)\n",
      "\n",
      "                    else:\n",
      "                        #calculate fit parameters for best fit polynomial curve \n",
      "                        fit_params = np.poly1d(np.polyfit(df_fxn_range['Carat'],df_fxn_range['TotalPrice'], degree, full=False))\n",
      "    \n",
      "                        #Calculate the standard deviation of list prices versus model projected prices in terms of pct rap (i.e., % difference of model price and listed price from rap list price)\n",
      "                        total = 0\n",
      "                        for m in range(len(df_plot_range)):\n",
      "                            total += ((np.polyval(fit_params, df_plot_range['Carat'].iloc[m]) - df_plot_range['TotalPrice'].iloc[m])/np.polyval(fit_params, df_plot_range['Carat'].iloc[m]))**2\n",
      "                        curve_shift = math.sqrt(total / len(df_plot_range))\n",
      "                     \n",
      "                        #Calculate a residual value - the % difference between predicted price and list price\n",
      "                        df_plot_range['Residual'] = (df_plot_range['TotalPrice']-np.polyval(fit_params, df_plot_range['Carat']))/df_plot_range['TotalPrice']\n",
      "                        \n",
      "                        resid_slope = np.poly1d(np.polyfit(df_plot_range['Carat'],df_plot_range['Residual'], 1, full=False))\n",
      "\n",
      "                        #Store fit parameters in a dictionary\n",
      "                        if degree == 1:\n",
      "                            output['Shape'].append(shape_key)\n",
      "                            output['Color'].append(color)\n",
      "                            output['Clarity'].append(clar)\n",
      "                            output['CurveKey'].append(curve_key)\n",
      "                            output['CurveRangeMin'].append(plot_min)\n",
      "                            output['CurveRangeMax'].append(plot_max)\n",
      "                            output['PolyDegree'].append(degree)\n",
      "                            output['Px2'].append(0)\n",
      "                            output['Px1'].append(fit_params[1])\n",
      "                            output['Px0'].append(fit_params[0])\n",
      "                            output['StdDev'].append(curve_shift)\n",
      "                            output['NumStones'].append(len(df_plot_range))\n",
      "                            output['ResidSlope'].append(resid_slope[1]*(fxn_max-fxn_min))\n",
      "                            output['ResidCept'].append(resid_slope[0])\n",
      "                        elif degree == 2:\n",
      "                            output['Shape'].append(shape_key)\n",
      "                            output['Color'].append(color)\n",
      "                            output['Clarity'].append(clar)\n",
      "                            output['CurveKey'].append(curve_key)\n",
      "                            output['CurveRangeMin'].append(plot_min)\n",
      "                            output['CurveRangeMax'].append(plot_max)                        \n",
      "                            output['PolyDegree'].append(degree)\n",
      "                            output['Px2'].append(fit_params[2])\n",
      "                            output['Px1'].append(fit_params[1])\n",
      "                            output['Px0'].append(fit_params[0])\n",
      "                            output['StdDev'].append(curve_shift)\n",
      "                            output['NumStones'].append(len(df_plot_range))\n",
      "                            output['ResidSlope'].append(resid_slope[1]*(fxn_max-fxn_min))\n",
      "                            output['ResidCept'].append(resid_slope[0])\n",
      "                        else:\n",
      "                            output['Shape'].append(shape_key)\n",
      "                            output['Color'].append(color)\n",
      "                            output['Clarity'].append(clar)\n",
      "                            output['CurveKey'].append(curve_key)\n",
      "                            output['CurveRangeMin'].append(plot_min)\n",
      "                            output['CurveRangeMax'].append(plot_max)\n",
      "                            output['PolyDegree'].append(-999999)\n",
      "                            output['Px2'].append(-999999)\n",
      "                            output['Px1'].append(-999999)\n",
      "                            output['Px0'].append(-999999)\n",
      "                            output['StdDev'].append(-999999)\n",
      "                            output['NumStones'].append(len(df_plot_range))\n",
      "                            output['ResidSlope'].append(-999999)\n",
      "                            output['ResidCept'].append(-999999)\n",
      "\n",
      "                        #load rap price for color/clarity/weight combination\n",
      "                        #rap_price = df_rap_price_list['PricePerCar'].ix[rap_shape_key].ix[color].ix[clar].ix[rap_price_key]\n",
      "                        \n",
      "                        ###plot best fit curves, best fit curve less the stdev calc, & scatter of price v weight\n",
      "                        \n",
      "                        #DEACTIVATED\n",
      "                        ##plt.subplot(2,1,1)\n",
      "                        ##plt.plot(rc_bins[i], np.polyval(fit_params, plot_linspace), color = line_colors[i])\n",
      "                        ##plt.plot(rc_bins[i], (np.polyval(fit_params, plot_linspace) - np.polyval(fit_params, plot_linspace)*curve_shift), '--', color=line_colors[i])\n",
      "                        ##plt.scatter(df_plot_range['Carat'], df_plot_range['TotalPrice'], color=line_colors[i], alpha=.7)\n",
      "                        \n",
      "                        #calculate a curve that will display on the residual chart showing the difference between the model price and the price of a stone 1 stdev away from the model price\n",
      "                        ##curve_shift_resid = -(np.polyval(fit_params, plot_linspace) - np.polyval(fit_params, plot_linspace)*(1-curve_shift))/np.polyval(fit_params, plot_linspace)\n",
      "                        \n",
      "                        #plot residuals\n",
      "                        ##plt.subplot(2,1,2)\n",
      "                        ##plt.plot(plot_linspace, curve_shift_resid, '--', color=line_colors[i])\n",
      "\n",
      "                        ##plt.scatter(df_plot_range['Carat'],df_plot_range['Residual'],color=line_colors[i],alpha=.7)\n",
      "                        ##plt.axhline(linewidth=1, color='k')\n",
      "                        \n",
      "                    \n",
      "                #set plot limits - exception handling for empty dataframes\n",
      "                \n",
      "                if len(df_temp) == 0:\n",
      "                    ymin = 0\n",
      "                    ymax = 10000\n",
      "                else:\n",
      "                    ymin = min(df_temp['TotalPrice'])*0.95\n",
      "                    ymax = max(df_temp['TotalPrice'])*1.05\n",
      "                \n",
      "                #label and format plots\n",
      "                #plt.rcParams['figure.figsize'] = 9, 9                \n",
      "                ##if clar in ['SI3', 'I2', 'I3']:\n",
      "                ##    pass\n",
      "                ##else: \n",
      "                ##    plt.rcParams['figure.figsize'] = 9, 9      \n",
      "                ##   plt.subplot(2,1,1)\n",
      "                ##    plt.title(shape+'- 0.30 - 2.99 carat - '+color+' - '+clar, fontsize = 16)\n",
      "                ##    plt.ylabel('Total Price of Stone', fontsize = 16)\n",
      "                ##    plt.ylim(ymin, ymax)\n",
      "                ##    #plt.ylim(0,10000)\n",
      "                ##    plt.annotate(\"N = %s stones\" %(len(df_temp)), xy=(1, 0), xycoords='axes fraction', fontsize=16, xytext=(-5, 5), textcoords='offset points', ha='right', va='bottom')\n",
      "                ##    plt.xlim(0.23,3.00)\n",
      "                    \n",
      "                ##    plt.subplot(2,1,2)\n",
      "                ##    plt.title('Residuals', fontsize = 16)\n",
      "                ##    plt.ylabel('% Diff Btwn Actual and Model Price', fontsize = 16)\n",
      "                ##    plt.xlabel('Carat Weight', fontsize = 16)\n",
      "                ##    plt.ylim(-.5,.5) \n",
      "                ##    plt.xlim(0.23,3.00)\n",
      "                        \n",
      "                ##plt.savefig(pp, format='pdf') #save figure to pdf\n",
      "                ##plt.clf() #clear the figure for next iteration  \n",
      "                \n",
      "    ##pp.close() #close pdf\n",
      "    \n",
      "    #create a dataframe that contains the curve fit parameters \n",
      "    arrays = [output['Shape'], output['Color'], output['Clarity'], output['CurveKey'], output['CurveRangeMin']]\n",
      "    tuples = zip(*arrays)\n",
      "    index = pd.MultiIndex.from_tuples(tuples)\n",
      "    \n",
      "    output2 = {}\n",
      "    output2 = { \\\n",
      "                'CurveRangeMax' : output['CurveRangeMax'], \\\n",
      "                'PolyDegree' : output['PolyDegree'], \\\n",
      "                'Px2': output['Px2'], \\\n",
      "                'Px1': output['Px1'], \\\n",
      "                'Px0' : output['Px0'], \\\n",
      "                'StdDev': output['StdDev'], \\\n",
      "                'NumStones': output['NumStones'], \\\n",
      "                'ResidSlope': output['ResidSlope'], \\\n",
      "                'ResidCept': output['ResidCept'] \\\n",
      "                }\n",
      "    \n",
      "    df_output = pd.DataFrame(output2, index = index, columns = ['PolyDegree', 'Px2', 'Px1', 'Px0', 'StdDev', 'NumStones', 'ResidSlope', 'ResidCept'] )\n",
      "    \n",
      "    #df_output.to_excel('/home/oliver/Dropbox/whitepine/price_curve_params.csv')\n",
      "        \n",
      "    return df_output\n",
      "    \n",
      "df_price_curves = price_curve_genarator_all()                \n",
      "       \n",
      "\n",
      "##################\n",
      "##### GO OVER PRICE PARAMETERS AND THROW OUT MISSHAPEN CURVES - NEEDS TO BE UPDATED USING GROUPBY METHODS TO IMPROVE PERFORMANCE\n",
      "###################\n",
      "\n",
      "for i in range(len(df_price_curves)):\n",
      "    if (df_price_curves['PolyDegree'].iloc[i] == 1) and (df_price_curves['Px1'].iloc[i] < 0):\n",
      "        df_price_curves['PolyDegree'].iloc[i] = 1\n",
      "        df_price_curves['Px2'].iloc[i] = -999999\n",
      "        df_price_curves['Px1'].iloc[i] = -999999\n",
      "        df_price_curves['Px0'].iloc[i] = -999999\n",
      "        df_price_curves['StdDev'].iloc[i] = -999999\n",
      "    elif (df_price_curves['PolyDegree'].iloc[i] == 2) and (df_price_curves['Px1'].iloc[i] > 80000):\n",
      "        df_price_curves['PolyDegree'].iloc[i] = 2\n",
      "        df_price_curves['Px2'].iloc[i] = -999999\n",
      "        df_price_curves['Px1'].iloc[i] = -999999\n",
      "        df_price_curves['Px0'].iloc[i] = -999999\n",
      "        df_price_curves['StdDev'].iloc[i] = -999999\n",
      "\n",
      "writer = pd.ExcelWriter('/home/oliver/Dropbox/whitepine/prdt.xlsx')\n",
      "temp = df_price_curves.reset_index()\n",
      "temp.columns = ['Shape','Color','Clarity','CurveKey','CurveRangeMin','PolyDegree','Px2','Px1','Px0','StdDev','NumStones', 'ResidSlope', 'ResidCept'] \n",
      "temp['Idx'] = temp.apply(lambda x: '%s_%s_%s_%s' %(x['Shape'], x['Color'], x['Clarity'], x['CurveKey']), axis=1)\n",
      "temp = temp.set_index(['Idx'])\n",
      "temp.to_excel(writer, 'PRICE PARAMS')\n",
      "\n",
      "##################\n",
      "##### OUTPUT SOME DISCOUNTS FOR THE DVT RANGE ESTIMATOR\n",
      "###################\n",
      "\n",
      "grouped = df[df['Fluor'].isin(fluor_none_and_faint)].groupby(['Shape', 'Color', 'Clarity', 'ShapeDiscKey'])\n",
      "\n",
      "output = []\n",
      "\n",
      "for [shape, color, clarity, shapedisckey], group in grouped:\n",
      "    output.append([\"%s_%s_%s_%s\" %(color,clarity,shapedisckey,shape),\\\n",
      "                   shape,\\\n",
      "                   color,\\\n",
      "                   clarity,\\\n",
      "                   shapedisckey,\\\n",
      "                   np.mean(group['PctRap']),\\\n",
      "                   len(group)\\\n",
      "                   ])\n",
      "\n",
      "output_df = pd.DataFrame(output, columns = ['Idx','Shape','Color','Clarity','Min Wght','Avg Discount','Num Stones']).set_index(['Idx'])\n",
      "output_df.to_excel(writer, 'SHAPE DISCS')\n",
      "\n",
      "###################\n",
      "#####  EMBIGGEN DF - ADD NEW COLUMN CONTAINING PRICE CURVE KEYS\n",
      "###################\n",
      "\n",
      "df['PriceCurveKey'] = 0\n",
      "\n",
      "def price_curve_key(wt):\n",
      "    if wt >= 0.01 and wt <= 0.03:\n",
      "        return 'r01'\n",
      "    elif wt >= 0.04 and wt <= 0.07:\n",
      "        return 'r04'\n",
      "    elif wt >= 0.08 and wt <= 0.14:\n",
      "        return 'r08'\n",
      "    elif wt >= 0.15 and wt <= 0.17:\n",
      "        return 'r15'\n",
      "    elif wt >= 0.18 and wt <= 0.22:\n",
      "        return 'r18'\n",
      "    elif wt >= 0.23 and wt <= 0.29:\n",
      "        return 'r23'   \n",
      "    elif wt >= 0.30 and wt <= 0.39:\n",
      "        return 'r30'\n",
      "    elif wt >= 0.40 and wt <= 0.49:\n",
      "        return 'r40'\n",
      "    elif wt >= 0.50 and wt <= 0.59:\n",
      "        return 'r50'\n",
      "    elif 0.60 <= wt and wt <= 0.69:\n",
      "        return 'r60'\n",
      "    elif 0.70 <= wt and wt <= 0.79:\n",
      "        return 'r70'\n",
      "    elif 0.80 <= wt and wt <= 0.89:\n",
      "        return 'r80'\n",
      "    elif 0.90 <= wt and wt <= 0.99:\n",
      "        return 'r90'\n",
      "    elif 1.00 <= wt and wt <= 1.49:\n",
      "        return 'rc1'\n",
      "    elif 1.50 <= wt and wt <= 1.99:\n",
      "        return 'rcr'\n",
      "    elif 2.00 <= wt and wt <= 2.99:\n",
      "        return 'rc2'\n",
      "    elif 3.00 <= wt and wt <= 3.99:\n",
      "        return 'rc3'       \n",
      "    elif 4.00 <= wt and wt <= 4.99:\n",
      "        return 'rc4'       \n",
      "    elif 5.00 <= wt and wt <= 9.99:\n",
      "        return 'rc5'\n",
      "    elif 10.00 <= wt:\n",
      "        return 'rct'\n",
      "    else:\n",
      "        return -999999.0\n",
      "\n",
      "df['PriceCurveKey'] = df['Carat'].apply(price_curve_key)\n",
      "\n",
      "###################\n",
      "##### EMBIGGEN DF - ADD NEW COLUMNS CONTAINING MODEL PARAMETERS AND PREDICTED PRICES\n",
      "###################\n",
      "\n",
      "groups = []\n",
      "# split into groups, where each row in a subgroup has the same Color, Clarity, and RapPriceKey\n",
      "for (discountshapekey, color, clarity, priceCurveKey), group in df.groupby(['DiscountShapeKey','Color','Clarity','PriceCurveKey']):\n",
      "    px = df_price_curves[df_price_curves.index.map(lambda idx: idx[0] == discountshapekey and idx[1] == color and idx[2] == clarity and idx[3] == priceCurveKey)]\n",
      "    if len(px):\n",
      "        group['PolyDegree'] = px['PolyDegree'].iloc[0]\n",
      "        group['Px2'] = px['Px2'].iloc[0]\n",
      "        group['Px1'] = px['Px1'].iloc[0]\n",
      "        group['Px0'] = px['Px0'].iloc[0]\n",
      "        group['StdDev'] = px['StdDev'].iloc[0]\n",
      "    else: \n",
      "        group['PolyDegree'] = px['PolyDegree']\n",
      "        group['Px2'] = -999999\n",
      "        group['Px1'] = -999999\n",
      "        group['Px0'] = -999999\n",
      "        group['StdDev'] = -999999\n",
      "    groups.append(group) # add each subgroup to a python list\n",
      "\n",
      "df = pd.concat(groups)\n",
      "\n",
      "df['PredictedPrice'] = df['Carat']**2 * df['Px2'] +  df['Carat'] * df['Px1'] + df['Px0']\n",
      "df['PredictedPricePerCarat'] = df['PredictedPrice'] / df['Carat']\n",
      "df['PredictedPctRap'] = (df['PredictedPricePerCarat'] - df['RapPricePerCarat']) / df['RapPricePerCarat']\n",
      "df['PredictedPercentDiff'] = (df['TotalPrice']-df['PredictedPrice'])/df['PredictedPrice']\n",
      "\n",
      "##########################################################################\n",
      "### DISCOUNT CALCULATION - GROUPED COLOR/CLAR VERSION - OUTPUTS RAP STYLE TABLES\n",
      "##########################################################################\n",
      "fluor_faint = ['Faint ', 'Faint Blue', 'Slight', 'Very Slight ', 'Slight Blue', 'Very Slight Blue'] #Do NOT delete spaces at end of items in this list\n",
      "fluor_none = ['None '] #Do NOT delete spaces at end of items in this list\n",
      "\n",
      "\n",
      "clars_avg = ['IF_avg', 'VVS1_avg', 'VVS2_avg', 'VS1_avg', 'VS2_avg', 'SI1_avg', 'SI2_avg', 'SI3_avg', 'I1_avg', 'I2_avg','I3_avg','Blank_Col_avg']\n",
      "clars_med = ['IF_med', 'VVS1_med', 'VVS2_med', 'VS1_med', 'VS2_med', 'SI1_med', 'SI2_med', 'SI3_med', 'I1_med', 'I2_med','I3_med','Blank_Col_med']\n",
      "clars_std = ['IF_std', 'VVS1_std', 'VVS2_std', 'VS1_std', 'VS2_std', 'SI1_std', 'SI2_std', 'SI3_std', 'I1_std', 'I2_std','I3_std','Blank_Col_std']\n",
      "clars_num = ['IF_num', 'VVS1_num', 'VVS2_num', 'VS1_num', 'VS2_num', 'SI1_num', 'SI2_num', 'SI3_num', 'I1_num', 'I2_num','I3_num']\n",
      "clars_blnk = ['IF', 'VVS1', 'VVS2', 'VS1', 'VS2', 'SI1', 'SI2', 'SI3', 'I1', 'I2', 'I3', 'Blank_Col']\n",
      "\n",
      "clars_tot = clars_avg + clars_med + clars_std + clars_num\n",
      "\n",
      "usa_only = ['USA']\n",
      "\n",
      "discount_groups = [ [['D'], ['IF', 'VVS1', 'VVS2']], \\\n",
      "                    [['E', 'F'], ['IF', 'VVS1', 'VVS2']], \\\n",
      "                    [['G', 'H', 'I', 'J'], ['IF', 'VVS1', 'VVS2']], \\\n",
      "                    [['D'], ['VS1', 'VS2', 'SI1', 'SI2']], \\\n",
      "                    #[['E', 'F', 'G', 'H', 'I', 'J'], ['VS1', 'VS2']], \\\n",
      "                    #[['E', 'F', 'G', 'H', 'I', 'J'], ['SI1', 'SI2']], \\\n",
      "                    [['E', 'F'], ['VS1', 'VS2']], \\\n",
      "                    [['G', 'H', 'I', 'J'], ['VS1', 'VS2']], \\\n",
      "                    [['E', 'F'], ['SI1', 'SI2']], \\\n",
      "                    [['G', 'H', 'I', 'J'], ['SI1', 'SI2']], \\\n",
      "                    [['K', 'L'], ['IF', 'VVS1', 'VVS2', 'VS1', 'VS2', 'SI1', 'SI2']]\\\n",
      "                    ]\n",
      "\n",
      "ex = ['Excellent']\n",
      "vg = ['Very Good']\n",
      "gd = ['Good']\n",
      "fr = ['Fair']\n",
      "\n",
      "vg_plus = ['Excellent', 'Very Good']\n",
      "gd_plus = ['Excellent', 'Very Good', 'Good']\n",
      "fr_plus = ['Excellent', 'Very Good', 'Good', 'Fair']\n",
      "tot = ['Excellent', 'Very Good', 'Good', 'Fair']\n",
      "\n",
      "# TAG , CUT , polish, sym, fluor\n",
      "\n",
      "discounts = [ \\\n",
      "            ['EX_EX_EX_NO_CPBOOST', ex, ex, ex, fluor_none, usa_only, 'Round', 'RB'], \\\n",
      "            ['EX_EX_EX_NO', ex, ex, ex, fluor_none, all_countries, 'Round', 'RB'], \\\n",
      "            ['EX_EX_EX_FNT', ex, ex, ex, fluor_faint, all_countries, 'Round', 'RB'], \\\n",
      "            ['EX_EX_EX_MED', ex, ex, ex, fluor_medium, all_countries, 'Round', 'RB'], \\\n",
      "            ['EX_EX_EX_STRONG', ex, ex, ex, fluor_strong, all_countries, 'Round', 'RB'], \\\n",
      "            ['VG_VGPLUS_VGPLUS_NO', vg, vg_plus, vg_plus, fluor_none, all_countries, 'Round', 'RB'], \\\n",
      "            ['VG_VGPLUS_VGPLUS_FNT', vg, vg_plus, vg_plus, fluor_faint, all_countries, 'Round', 'RB'], \\\n",
      "            ['VG_VGPLUS_VGPLUS_MED', vg, vg_plus, vg_plus, fluor_medium, all_countries, 'Round', 'RB'], \\\n",
      "            ['VG_VGPLUS_VGPLUS_STRONG', vg, vg_plus, vg_plus, fluor_strong, all_countries, 'Round', 'RB'], \\\n",
      "            ['GD_GDPLUS_GDPLUS_NO', gd, gd_plus, gd_plus, fluor_none, all_countries, 'Round', 'RB'], \\\n",
      "            ['GD_GDPLUS_GDPLUS_FNT', gd, gd_plus, gd_plus, fluor_faint, all_countries, 'Round', 'RB'], \\\n",
      "            ['GD_GDPLUS_GDPLUS_MED', gd, gd_plus, gd_plus, fluor_medium, all_countries, 'Round', 'RB'], \\\n",
      "            ['GD_GDPLUS_GDPLUS_STRONG', gd, gd_plus, gd_plus, fluor_strong, all_countries, 'Round', 'RB'], \\\n",
      "            ['FR_FRPLUS_FRPLUS_NO', fr, fr_plus, fr_plus, fluor_none, all_countries, 'Round', 'RB'], \\\n",
      "            ['FR_FRPLUS_FRPLUS_FNT', fr, fr_plus, fr_plus, fluor_faint, all_countries, 'Round', 'RB'], \\\n",
      "            ['FR_VGPLUS_FRPLUS_MED', fr, fr_plus, fr_plus, fluor_medium, all_countries, 'Round', 'RB'], \\\n",
      "            ['FR_FRPLUS_FRPLUS_STRONG', fr, fr_plus, fr_plus, fluor_strong, all_countries, 'Round', 'RB'], \\\n",
      "            #['EX_VG_EX_NO', ex, vg, ex, fluor_none, all_countries, 'Round'], \\\n",
      "            #['EX_EX_VG_NO', ex, ex, vg, fluor_none, all_countries, 'Round'], \\\n",
      "            #['EX_VG_VG_NO', ex, vg, vg, fluor_none, all_countries, 'Round'] \\\n",
      "            #['ANY_VGPLUS_VG_NO', gd_plus, vg_plus, vg, fluor_none, usa_only, 'Princess', 'PR'], \\\n",
      "            #['ANY_VGPLUS_VG_FNT', gd_plus, vg_plus, vg, fluor_faint, usa_only, 'Princess', 'PR'], \\\n",
      "            #['ANY_EX_EX_NO', gd_plus, ex, ex, fluor_none, usa_only, 'Princess', 'PR'], \\\n",
      "            #['ANY_EX_EX_FNT', gd_plus, ex, ex, fluor_faint, usa_only, 'Princess', 'PR'], \\\n",
      "            ['ANY_GDPLUS_GD_NO', [\"Good\", \"Very Good\"], gd_plus, gd_plus, fluor_none, usa_only, 'Princess', 'PR'], \\\n",
      "            ]\n",
      "\n",
      "#f = open(\"/home/oliver/Dropbox/whitepine/discounts_tables1.csv\", \"w\")\n",
      "#f.truncate()\n",
      "#f.close()\n",
      "\n",
      "discount_bins = [ \\\n",
      "                 [0.23, 1.00], \\\n",
      "                 [1.00, 1.50], \\\n",
      "                 [1.50, 2.99], \\\n",
      "                 ]\n",
      "\n",
      "df['PredictedPrice'] = df['Carat']**2 * df['Px2'] +  df['Carat'] * df['Px1'] + df['Px0']\n",
      "df['PredictedPricePerCarat'] = df['PredictedPrice'] / df['Carat']\n",
      "df['PredictedPctRap'] = (df['PredictedPricePerCarat'] - df['RapPricePerCarat']) / df['RapPricePerCarat']\n",
      "\n",
      "discount_output = { 'Tag' : [], 'RB Avg Discount': [], 'RB Median Discount' : [], 'RB Discount Stdev' : [], 'Num Stones' : [], \\\n",
      "                         'PR DepthDiff Coefficient' : [], 'PR Sym Rank Coefficient' : [], \\\n",
      "                         'PR DepthDiff T-Stat' : [], 'PR Sym Rank T-Stat' : []}\n",
      "\n",
      "for p in range(len(discount_bins)):\n",
      "    min_carat = discount_bins[p][0]\n",
      "    max_carat = discount_bins[p][1]\n",
      "    for i in range(len(discounts)):\n",
      "        df_discount = pd.DataFrame(0, index=colors, columns=clars_tot, dtype=np.float64) \n",
      "        df_avg_discount = pd.DataFrame(0, index=colors, columns=clars_blnk, dtype=np.float64) \n",
      "        df_med_discount = pd.DataFrame(0, index=colors, columns=clars_blnk, dtype=np.float64) \n",
      "        df_std_discount = pd.DataFrame(0, index=colors, columns=clars_blnk, dtype=np.float64)     \n",
      "        df_number_of_stones = pd.DataFrame(0, index=colors, columns=clars, dtype=np.float64) \n",
      "    \n",
      "        for m in range(len(discount_groups)):\n",
      "            color = discount_groups[m][0]\n",
      "            clar = discount_groups[m][1]\n",
      "            tag = discounts[i][0]\n",
      "            cut = discounts[i][1]\n",
      "            polish = discounts[i][2]\n",
      "            sym = discounts[i][3]\n",
      "            fluor = discounts[i][4]\n",
      "            location = discounts[i][5]\n",
      "            shape = discounts[i][6]\n",
      "            shape_tag = discounts[i][7]\n",
      "            \n",
      "            df_temp = df[ \\\n",
      "                (df['Carat'] >= min_carat) \\\n",
      "                & (df['Carat'] < max_carat) \\\n",
      "                & (df['Shape'] == shape)\n",
      "                & (df['Color'].isin(color)) \\\n",
      "                & (df['Clarity'].isin(clar)) \\\n",
      "                & (df['Country'].isin(location)) \\\n",
      "                & (df['Cut Grade'].isin(cut)) \\\n",
      "                & (df['Polish'].isin(polish)) \\\n",
      "                & (df['Sym'].isin(sym)) \\\n",
      "                & (df['Fluor'].isin(fluor)) \\\n",
      "                & (df['Px2'] != -999999)\\\n",
      "                ] #\n",
      "\n",
      "            avg_discount = np.mean(df_temp['ExactPctRap'] - df_temp['PredictedPctRap'])   \n",
      "            med_discount = np.median(df_temp['ExactPctRap'] - df_temp['PredictedPctRap'])\n",
      "            std_discount = np.std(df_temp['ExactPctRap'] - df_temp['PredictedPctRap'])\n",
      "            num_stones = len(df_temp)\n",
      "\n",
      "            if shape == 'Round':            \n",
      "                if len(df_temp) == 0:\n",
      "                    for j in discount_groups[m][0]:\n",
      "                        for k in discount_groups[m][1]:\n",
      "                            df_number_of_stones.ix[j,k] = 0\n",
      "                            df_avg_discount.ix[j,k] = -999999\n",
      "                            df_med_discount.ix[j,k] = -999999\n",
      "                            df_std_discount.ix[j,k] = -999999\n",
      "                            discount_output['Tag'].append(\"%s_%sct_%sct_%s_%s_%s\" %(shape_tag,min_carat,max_carat,j,k,tag))\n",
      "                            discount_output['RB Avg Discount'].append(-999999)\n",
      "                            discount_output['RB Median Discount'].append(-999999) \n",
      "                            discount_output['RB Discount Stdev'].append(-999999)\n",
      "                            discount_output['Num Stones'].append(0)                   \n",
      "                            #discount_output['PR Intercept Coefficient'].append(-999999)\n",
      "                            discount_output['PR DepthDiff Coefficient'].append(-999999)\n",
      "                            discount_output['PR Sym Rank Coefficient'].append(-999999)\n",
      "                            #discount_output['PR Intercept T-Stat'].append(-999999)\n",
      "                            discount_output['PR DepthDiff T-Stat'].append(-999999)\n",
      "                            discount_output['PR Sym Rank T-Stat'].append(-999999)                       \n",
      "                \n",
      "                elif len(df_temp) <= 7:\n",
      "                    for j in discount_groups[m][0]:\n",
      "                        for k in discount_groups[m][1]:\n",
      "                            df_number_of_stones.ix[j,k] = len(df_temp)\n",
      "                            df_avg_discount.ix[j,k] = -999999\n",
      "                            df_med_discount.ix[j,k] = -999999\n",
      "                            df_std_discount.ix[j,k] = -999999\n",
      "                            discount_output['Tag'].append(\"%s_%sct_%sct_%s_%s_%s\" %(shape_tag,min_carat,max_carat,j,k,tag))\n",
      "                            discount_output['RB Avg Discount'].append(-999999)\n",
      "                            discount_output['RB Median Discount'].append(-999999)\n",
      "                            discount_output['RB Discount Stdev'].append(-999999)\n",
      "                            discount_output['Num Stones'].append(len(df_temp))\n",
      "                            #discount_output['PR Intercept Coefficient'].append(-999999)\n",
      "                            discount_output['PR DepthDiff Coefficient'].append(-999999)\n",
      "                            discount_output['PR Sym Rank Coefficient'].append(-999999)\n",
      "                            #discount_output['PR Intercept T-Stat'].append(-999999)\n",
      "                            discount_output['PR DepthDiff T-Stat'].append(-999999)\n",
      "                            discount_output['PR Sym Rank T-Stat'].append(-999999)                       \n",
      "                            \n",
      "                else:    \n",
      "                    for j in discount_groups[m][0]:\n",
      "                        for k in discount_groups[m][1]:\n",
      "                            df_number_of_stones.ix[j,k] = num_stones\n",
      "                            df_avg_discount.ix[j,k] = avg_discount\n",
      "                            df_med_discount.ix[j,k] = med_discount\n",
      "                            df_std_discount.ix[j,k] = std_discount                \n",
      "                            discount_output['Tag'].append(\"%s_%sct_%sct_%s_%s_%s\" %(shape_tag,min_carat,max_carat,j,k,tag))\n",
      "                            discount_output['RB Avg Discount'].append(avg_discount)\n",
      "                            discount_output['RB Median Discount'].append(med_discount)         \n",
      "                            discount_output['RB Discount Stdev'].append(std_discount)     \n",
      "                            discount_output['Num Stones'].append(len(df_temp))\n",
      "                            #discount_output['PR Intercept Coefficient'].append(-999999)\n",
      "                            discount_output['PR DepthDiff Coefficient'].append(-999999)\n",
      "                            discount_output['PR Sym Rank Coefficient'].append(-999999)\n",
      "                            #discount_output['PR Intercept T-Stat'].append(-999999)\n",
      "                            discount_output['PR DepthDiff T-Stat'].append(-999999)\n",
      "                            discount_output['PR Sym Rank T-Stat'].append(-999999)                       \n",
      "\n",
      "            elif shape == 'Princess':               \n",
      "                if len(df_temp) == 0:\n",
      "                    for j in discount_groups[m][0]:\n",
      "                        for k in discount_groups[m][1]:\n",
      "                            df_number_of_stones.ix[j,k] = 0\n",
      "                            discount_output['Tag'].append(\"%s_%sct_%sct_%s_%s_%s\" %(shape_tag,min_carat,max_carat,j,k,tag))\n",
      "                            discount_output['RB Avg Discount'].append(-999999)\n",
      "                            discount_output['RB Median Discount'].append(-999999) \n",
      "                            discount_output['RB Discount Stdev'].append(-999999)                            \n",
      "                            #discount_output['PR Intercept Coefficient'].append(-999999)\n",
      "                            discount_output['PR DepthDiff Coefficient'].append(-999999)\n",
      "                            discount_output['PR Sym Rank Coefficient'].append(-999999)\n",
      "                            discount_output['Num Stones'].append(0)\n",
      "                            #discount_output['PR Intercept T-Stat'].append(-999999)\n",
      "                            discount_output['PR DepthDiff T-Stat'].append(-999999)\n",
      "                            discount_output['PR Sym Rank T-Stat'].append(-999999)\n",
      "                \n",
      "                elif len(df_temp) <= 12:\n",
      "                    for j in discount_groups[m][0]:\n",
      "                        for k in discount_groups[m][1]:\n",
      "                            df_number_of_stones.ix[j,k] = len(df_temp)\n",
      "                            discount_output['Tag'].append(\"%s_%sct_%sct_%s_%s_%s\" %(shape_tag,min_carat,max_carat,j,k,tag))\n",
      "                            discount_output['RB Avg Discount'].append(-999999)\n",
      "                            discount_output['RB Median Discount'].append(-999999) \n",
      "                            discount_output['RB Discount Stdev'].append(-999999)                            \n",
      "                            #discount_output['PR Intercept Coefficient'].append(-999999)\n",
      "                            discount_output['PR DepthDiff Coefficient'].append(-999999)\n",
      "                            discount_output['PR Sym Rank Coefficient'].append(-999999)\n",
      "                            discount_output['Num Stones'].append(len(df_temp))\n",
      "                            #discount_output['PR Intercept T-Stat'].append(-999999)\n",
      "                            discount_output['PR DepthDiff T-Stat'].append(-999999)\n",
      "                            discount_output['PR Sym Rank T-Stat'].append(-999999)                       \n",
      "\n",
      "                else:            \n",
      "                    df_regress_temp = df_temp[(df_temp['PredictedPercentDiff'] <= 0.1) & (df_temp['Carat'] >= .4)]\n",
      "                    df_princess_regression = pd.DataFrame([df_regress_temp['PredictedPercentDiff'],df_regress_temp['DepthDiff'],df_regress_temp['SymRank']]).transpose()\n",
      "                    #reg_results = np.poly1d(np.polyfit(, 1, full=False))\n",
      "\n",
      "                    reg_results = pd.ols(y=df_princess_regression['PredictedPercentDiff'], \\\n",
      "                                         x=df_princess_regression.drop(['PredictedPercentDiff'], axis=1),\\\n",
      "                                         intercept=False)\n",
      "                    for j in discount_groups[m][0]:\n",
      "                        for k in discount_groups[m][1]:\n",
      "                            df_number_of_stones.ix[j,k] = len(df_temp)\n",
      "                            discount_output['Tag'].append(\"%s_%sct_%sct_%s_%s_%s\" %(shape_tag,min_carat,max_carat,j,k,tag))\n",
      "                            discount_output['RB Avg Discount'].append(-999999)\n",
      "                            discount_output['RB Median Discount'].append(-999999) \n",
      "                            discount_output['RB Discount Stdev'].append(-999999)                            \n",
      "                            #discount_output['PR Intercept Coefficient'].append(reg_results.beta['intercept'])\n",
      "                            discount_output['PR DepthDiff Coefficient'].append(reg_results.beta['DepthDiff'])\n",
      "                            discount_output['PR Sym Rank Coefficient'].append(reg_results.beta['SymRank'])\n",
      "                            discount_output['Num Stones'].append(len(df_temp))\n",
      "                            #discount_output['PR Intercept T-Stat'].append(reg_results.t_stat['intercept'])\n",
      "                            discount_output['PR DepthDiff T-Stat'].append(reg_results.t_stat['DepthDiff'])\n",
      "                            discount_output['PR Sym Rank T-Stat'].append(reg_results.t_stat['SymRank'])  \n",
      "                \n",
      "                \n",
      "        #name column headers of each indiviidual dataframe and combine them into a single large dataframe that can be ouput into excel\n",
      "        df_avg_discount.columns = clars_avg \n",
      "        df_med_discount.columns = clars_med\n",
      "        df_std_discount.columns = clars_std\n",
      "        df_number_of_stones.columns = clars_num\n",
      "    \n",
      "        for z in clars_avg: \n",
      "            df_discount[z] =  df_avg_discount[z]\n",
      "        for z in clars_med: \n",
      "            df_discount[z] =  df_med_discount[z]\n",
      "        for z in clars_std: \n",
      "            df_discount[z] =  df_std_discount[z]\n",
      "        for z in clars_num: \n",
      "            df_discount[z] =  df_number_of_stones[z]\n",
      "            \n",
      "        df_discount['Blank_Col_avg'] = colors\n",
      "        df_discount['Blank_Col_med'] = colors\n",
      "        df_discount['Blank_Col_std'] = colors    \n",
      "        \n",
      "        #pd.DataFrame([\"\", \"%s ct-%s ct-%s-%s\" %(min_carat,max_carat,shape, tag)]).to_csv('/home/oliver/Dropbox/whitepine/discounts_tables1.csv', mode = 'a', header=False)\n",
      "        #pd.DataFrame(clars_tot).T.to_csv('/home/oliver/Dropbox/whitepine/discounts_tables1.csv', mode = 'a', header=False)\n",
      "        #df_discount.to_csv('/home/oliver/Dropbox/whitepine/discounts_tables1.csv', mode = 'a', header=False)\n",
      "\n",
      "#print discount_output        \n",
      "        \n",
      "arrays = [discount_output['Tag']]\n",
      "tuples = zip(*arrays)\n",
      "index = pd.MultiIndex.from_tuples(tuples)        \n",
      "        \n",
      "df_discount_output = pd.DataFrame(discount_output, index=index,  columns=['RB Avg Discount', 'RB Median Discount', 'RB Discount Stdev', \\\n",
      "                         'PR DepthDiff Coefficient', 'PR Sym Rank Coefficient', \\\n",
      "                         'PR DepthDiff T-Stat', 'PR Sym Rank T-Stat', 'Num Stones'])\n",
      "\n",
      "#g = open(\"/home/oliver/Dropbox/whitepine/discounts_list.csv\", \"w\")\n",
      "#g.truncate()\n",
      "#g.close()\n",
      "#df_discount_output.to_csv('/home/oliver/Dropbox/whitepine/discounts_list.csv')\n",
      "\n",
      "df_discount_output.to_excel(writer, 'DISCOUNTS LIST')\n",
      "temp = df_rap_price_list.reset_index()\n",
      "temp.columns = ['Shape','Color','Clarity','Min Wght','Max Wght','Price','Date']\n",
      "temp['Idx'] = temp.apply(lambda x: '%s_%s_%s_%s' %(x['Shape'], x['Color'], x['Clarity'], x['Min Wght']), axis=1)\n",
      "temp = temp.set_index(['Idx'])\n",
      "temp.to_excel(writer, 'RAP PRICE LIST')\n",
      "pd.DataFrame({}).to_excel(writer, 'sheet1')\n",
      "writer.save()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reset = all_df.reset_index()\n",
      "\n",
      "print max(reset['event_day'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-12-30 00:00:00\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reset = current_df.reset_index()\n",
      "\n",
      "reset['Owner'].to_csv('/home/oliver/Dropbox/whitepine/owners.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "quarters = current_df[(current_df['Carat'] >= .23) & (current_df['Carat'] <= .29)]# & (current_df['Shape'] == 'Round')]# &\\\n",
      "                      #(current_df['Cert'] == 'GIA')]\n",
      "\n",
      "print len(quarters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5267\n"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "print current_df['Meas'].head(10)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "#\n",
      "# Get Authentication Ticket\n",
      "#\n",
      "import httplib, urllib\n",
      "params = urllib.urlencode({'username': 'abrown', 'password': 'abrown5355'})\n",
      "headers = {\"Content-type\": \"application/x-www-form-urlencoded\", \"Accept\": \"text/plain\"}\n",
      "conn = httplib.HTTPSConnection(\"technet.rapaport.com\")\n",
      "conn.request(\"POST\", \"/HTTP/Authenticate.aspx\", params, headers)\n",
      "response = conn.getresponse()\n",
      "auth_ticket = response.read()\n",
      "conn.close()\n",
      "\n",
      "#\n",
      "# Get the download\n",
      "#\n",
      "import httplib, urllib\n",
      "try:\n",
      "    output_file = open('download.csv', 'w')\n",
      "\n",
      "    params = urllib.urlencode({ 'ticket': auth_ticket })\n",
      "\n",
      "    headers = {\"Content-type\": \"application/x-www-form-urlencoded\", \"Accept\": \"text/plain\"}\n",
      "\n",
      "    conn = httplib.HTTPConnection(\"technet.rapaport.com\")\n",
      "\n",
      "    url = \"/HTTP/DLS/GetFile.aspx\"\n",
      "\n",
      "    conn.request(\"POST\", url, params, headers)\n",
      "\n",
      "    response = conn.getresponse()\n",
      "    data = response.read()\n",
      "    output_file.write( data )\n",
      "\n",
      "    conn.close()\n",
      "    output_file.close()\n",
      "except IOError:\n",
      "    output_file = open('download.csv', 'w')\n",
      "    output_file.close() "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print current_df['Meas'].dtype()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "'numpy.dtype' object is not callable",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-14-0ac44ebd03ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mcurrent_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Meas'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mTypeError\u001b[0m: 'numpy.dtype' object is not callable"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "current_df['Meas'].to_csv('/home/oliver/Dropbox/whitepine/ratiotemp.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['Meas'] = current_df['Meas']\n",
      "\n",
      "#df['Meas'] = pd.DataFrame(df['Meas'], dtype='string')\n",
      "\n",
      "def ratio(measurement):\n",
      "    if pd.isnull(measurement):\n",
      "        return -999999\n",
      "    else:\n",
      "        measurementx = (measurement.replace('-','x'))\n",
      "        dims = (measurementx.split('x'))\n",
      "        side1 = float(dims[0])\n",
      "        side2 = float(dims[1])       \n",
      "        if side1 == 0 or side2 == 0:\n",
      "            return -999999\n",
      "        else: \n",
      "            return max(side1/side2, side2/side1)\n",
      "\n",
      "df['Ratio'] = df['Meas'].apply(ratio)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print dims.head(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'dims' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-26-f47893a6525a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'dims' is not defined"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}